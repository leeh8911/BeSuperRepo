{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:15.484775Z",
     "start_time": "2021-07-08T14:38:53.401970Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.086273Z",
     "iopub.status.busy": "2021-07-07T12:01:13.085956Z",
     "iopub.status.idle": "2021-07-07T12:01:13.101791Z",
     "shell.execute_reply": "2021-07-07T12:01:13.100287Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.086245Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:15.544774Z",
     "start_time": "2021-07-08T14:39:15.486775Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.103578Z",
     "iopub.status.busy": "2021-07-07T12:01:13.103247Z",
     "iopub.status.idle": "2021-07-07T12:01:13.115766Z",
     "shell.execute_reply": "2021-07-07T12:01:13.114970Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.103527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:15.695111Z",
     "start_time": "2021-07-08T14:39:15.546776Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:03:55.554162Z",
     "iopub.status.busy": "2021-07-07T12:03:55.553783Z",
     "iopub.status.idle": "2021-07-07T12:03:55.558107Z",
     "shell.execute_reply": "2021-07-07T12:03:55.557314Z",
     "shell.execute_reply.started": "2021-07-07T12:03:55.554125Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20cd7419798>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 19901109\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "nepochs = 10000\n",
    "max_patience_count = 100\n",
    "notebookName = \"DualEncoderAttention\"\n",
    "\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Output Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:15.710111Z",
     "start_time": "2021-07-08T14:39:15.697110Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH = Path(f\"./models/{notebookName}\")\n",
    "if os.path.isdir(PATH):\n",
    "    dir_list = os.listdir(PATH)\n",
    "    num_files = 0\n",
    "    while True:\n",
    "        if os.path.isfile(str(PATH / f\"{num_files}\")):\n",
    "            num_files += 1\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    os.mkdir(PATH)\n",
    "    num_files = 0\n",
    "num_files = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:17.456702Z",
     "start_time": "2021-07-08T14:39:15.712111Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.152611Z",
     "iopub.status.busy": "2021-07-07T12:01:13.152281Z",
     "iopub.status.idle": "2021-07-07T12:01:13.572302Z",
     "shell.execute_reply": "2021-07-07T12:01:13.571313Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.152581Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"../input/google-smartphone-decimeter-challenge/\")\n",
    "df_train_default = pd.read_pickle(str(data_dir / \"gsdc_extract_train.pkl.gzip\"))\n",
    "df_test = pd.read_pickle(str(data_dir / \"gsdc_extract_test.pkl.gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.281702Z",
     "start_time": "2021-07-08T14:39:17.457703Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.573999Z",
     "iopub.status.busy": "2021-07-07T12:01:13.573647Z",
     "iopub.status.idle": "2021-07-07T12:01:15.608460Z",
     "shell.execute_reply": "2021-07-07T12:01:15.607254Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.573969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123509, 148) (10061, 148)\n"
     ]
    }
   ],
   "source": [
    "def CustomTrainValidSplit(df:pd.DataFrame, valid_size):\n",
    "    phones = df['phone'].unique()\n",
    "    \n",
    "    valid_num = int(len(phones) * valid_size)\n",
    "    train_num = len(phones) - valid_num\n",
    "    \n",
    "    indexes = np.array(range(len(phones)))\n",
    "    indexes = np.random.choice(indexes, len(indexes))\n",
    "    \n",
    "    df_train = []\n",
    "    for phone in phones[indexes[:train_num]]:\n",
    "        df_train.append(df[df['phone'] == phone])\n",
    "    df_train = pd.concat(df_train)\n",
    "    \n",
    "    df_valid = []\n",
    "    for phone in phones[indexes[train_num:-1]]:\n",
    "        df_valid.append(df[df['phone'] == phone])\n",
    "    df_valid = pd.concat(df_valid)\n",
    "    \n",
    "    return df_train.reset_index().drop(columns = 'index'), df_valid.reset_index().drop(columns = 'index')\n",
    "    \n",
    "df_train, df_valid = CustomTrainValidSplit(df_train_default, valid_size = 0.1)\n",
    "print(df_train.shape, df_valid.shape)\n",
    "del df_train_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.296702Z",
     "start_time": "2021-07-08T14:39:18.282702Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:15.610068Z",
     "iopub.status.busy": "2021-07-07T12:01:15.609730Z",
     "iopub.status.idle": "2021-07-07T12:01:15.618404Z",
     "shell.execute_reply": "2021-07-07T12:01:15.617229Z",
     "shell.execute_reply.started": "2021-07-07T12:01:15.610038Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeSeriseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, phys_features, stat_features, labels, train = False):\n",
    "        self.phys_features = phys_features\n",
    "        self.stat_features = stat_features\n",
    "        self.labels = labels\n",
    "        self.train = train\n",
    "        self.phones =df['phone'].unique()\n",
    "        self._len = len(self.phones)\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        phys_features = self.phys_features\n",
    "        stat_features = self.stat_features\n",
    "        labels = self.labels\n",
    "        phone = self.phones[idx]\n",
    "        \n",
    "        df = self.df[self.df['phone']==phone]\n",
    "        \n",
    "        phys = torch.Tensor(df[phys_features].values)\n",
    "        stat = torch.Tensor(df[stat_features].values)\n",
    "        if self.train:\n",
    "            label = torch.Tensor(df[labels].values)\n",
    "        else:\n",
    "            label = torch.Tensor([])\n",
    "        return phys, stat, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.311702Z",
     "start_time": "2021-07-08T14:39:18.298703Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:15.622098Z",
     "iopub.status.busy": "2021-07-07T12:01:15.621813Z",
     "iopub.status.idle": "2021-07-07T12:01:15.859545Z",
     "shell.execute_reply": "2021-07-07T12:01:15.858532Z",
     "shell.execute_reply.started": "2021-07-07T12:01:15.622072Z"
    }
   },
   "outputs": [],
   "source": [
    "phys_features = [\n",
    "    'latDeg', \n",
    "    'lngDeg', \n",
    "    'heightAboveWgs84EllipsoidM',\n",
    "    'dlatDeg',\n",
    "    'dlngDeg',\n",
    "    'dheight',\n",
    "    'UncalGyroXRadPerSec',\n",
    "    'UncalGyroYRadPerSec',\n",
    "    'UncalGyroZRadPerSec',\n",
    "    'DriftXRadPerSec',\n",
    "    'DriftYRadPerSec',\n",
    "    'DriftZRadPerSec',\n",
    "    'UncalAccelXMps2',\n",
    "    'UncalAccelYMps2',\n",
    "    'UncalAccelZMps2',\n",
    "    'BiasXMps2',\n",
    "    'BiasYMps2',\n",
    "    'BiasZMps2',\n",
    "    'UncalMagXMicroT',\n",
    "    'UncalMagYMicroT',\n",
    "    'UncalMagZMicroT',\n",
    "    'BiasXMicroT',\n",
    "    'BiasYMicroT',\n",
    "    'BiasZMicroT',\n",
    "    'yawDeg',\n",
    "    'rollDeg',\n",
    "    'pitchDeg',\n",
    "]\n",
    "stat_features = [\n",
    "    'GPS_L1', \n",
    "    'GPS_L5', \n",
    "    'GAL_E1', \n",
    "    'GAL_E5A', \n",
    "    'GLO_G1', \n",
    "    'BDS_B1I', \n",
    "    'BDS_B1C', \n",
    "    'BDS_B2A', \n",
    "    'QZS_J1', \n",
    "    'QZS_J5',\n",
    "    'xSatPosM',\n",
    "    'ySatPosM',\n",
    "    'zSatPosM',\n",
    "    'xSatVelMps',\n",
    "    'ySatVelMps',\n",
    "    'zSatVelMps',\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    't_latDeg', \n",
    "    't_lngDeg', \n",
    "    't_heightAboveWgs84EllipsoidM',\n",
    "#     'courseDegree',\n",
    "#     'hDop',\n",
    "#     'vDop',\n",
    "#     'speedMps'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.341702Z",
     "start_time": "2021-07-08T14:39:18.313703Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:15.861361Z",
     "iopub.status.busy": "2021-07-07T12:01:15.861068Z",
     "iopub.status.idle": "2021-07-07T12:01:15.907026Z",
     "shell.execute_reply": "2021-07-07T12:01:15.906093Z",
     "shell.execute_reply.started": "2021-07-07T12:01:15.861334Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = TimeSeriseDataset(df_train, \n",
    "                           phys_features, stat_features, labels,\n",
    "                           train = True)\n",
    "valid_data = TimeSeriseDataset(df_valid, \n",
    "                           phys_features, stat_features, labels,\n",
    "                           train = True)\n",
    "test_data = TimeSeriseDataset(df_test, \n",
    "                           phys_features, stat_features, labels,\n",
    "                           train = False)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.356701Z",
     "start_time": "2021-07-08T14:39:18.342702Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:03:43.108868Z",
     "iopub.status.busy": "2021-07-07T12:03:43.108516Z",
     "iopub.status.idle": "2021-07-07T12:03:43.124141Z",
     "shell.execute_reply": "2021-07-07T12:03:43.122937Z",
     "shell.execute_reply.started": "2021-07-07T12:03:43.108841Z"
    }
   },
   "outputs": [],
   "source": [
    "def torch_haversine(pred, true):\n",
    "\n",
    "    lat1=pred[:,0] % 360\n",
    "    lon1=pred[:,1] % 360\n",
    "    lat2=true[:,0] % 360\n",
    "    lon2=true[:,1] % 360\n",
    "\n",
    "    lat1, lat2, lon1, lon2 = map(lambda x:x*np.pi/180, [lat1, lat2, lon1, lon2])\n",
    "\n",
    "    dlat = (lat2 - lat1)\n",
    "    dlon = (lon2 - lon1)\n",
    "\n",
    "    a = torch.sin(dlat / 2.0)**2 + torch.cos(lat1) * torch.cos(lat2) * (torch.sin(dlon / 2.0)**2)\n",
    "    c = 2 * torch.arcsin(a ** 0.5)\n",
    "\n",
    "    dist = 6_367_000 * c\n",
    "\n",
    "    return dist\n",
    "\n",
    "def quantile_mean(dist):\n",
    "    return (torch.quantile(dist, 0.5) + torch.quantile(dist, 0.95))/2\n",
    "    \n",
    "def gps_loss(predict:torch.Tensor, target:torch.Tensor):\n",
    "    dist = torch_haversine(predict, target)\n",
    "\n",
    "    loss = dist.mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def gps_score(predict:torch.Tensor, target:torch.Tensor):\n",
    "    dist = torch_haversine(predict, target)\n",
    "\n",
    "    score = quantile_mean(dist)\n",
    "\n",
    "    return score\n",
    "\n",
    "def calc_loss_and_score(predicts, grounds):\n",
    "    dist = []\n",
    "    for pred, ground in zip(predicts, grounds):\n",
    "        pred = pred.squeeze(0)\n",
    "        ground = ground.squeeze(0)\n",
    "        dist.append(torch_haversine(pred, ground))\n",
    "    dist = torch.cat(dist, axis = 0)\n",
    "    return dist.mean(), quantile_mean(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.371702Z",
     "start_time": "2021-07-08T14:39:18.357702Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_features, num_hiddens, num_layers, dropout = 0.1, device_ = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device_\n",
    "        \n",
    "        self.gru = nn.GRU(num_features, num_hiddens, num_layers, batch_first = True, dropout = dropout, bidirectional = True)\n",
    "    def forward(self, x):\n",
    "        x, h = self.gru(x)\n",
    "        h = h.to(device)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.386703Z",
     "start_time": "2021-07-08T14:39:18.372705Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttDecoder(nn.Module):\n",
    "    def __init__(self, num_features, num_hiddens, num_layers, dropout = 0.1, device_ = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device_\n",
    "        self.num_features = num_features\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.max_length = 10000\n",
    "        \n",
    "        self.attn = nn.Linear(3 + num_hiddens*2, self.max_length)\n",
    "        self.comb = nn.Linear(3 + num_hiddens*2, num_features)\n",
    "        \n",
    "        self.gru = nn.GRU(num_features, num_hiddens, num_layers, batch_first = True, dropout = dropout, bidirectional = True)\n",
    "    def forward(self, x, h0, x0):\n",
    "        hd = h0.reshape(1, 1, self.num_hiddens * 2)\n",
    "        c = torch.cat([x, hd], axis = 2).reshape(-1, 3 + self.num_hiddens * 2)\n",
    "        w = self.attn(c)\n",
    "        w = w[:,:x0.shape[1]]\n",
    "        w = F.softmax(w).unsqueeze(1)\n",
    "        applied = torch.bmm(w, x0)\n",
    "        \n",
    "        output = torch.cat([x, applied], axis = 2)\n",
    "        output = self.comb(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, h = self.gru(output, h0)\n",
    "        h = h.to(device)\n",
    "        return output, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:18.401703Z",
     "start_time": "2021-07-08T14:39:18.387703Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:03:43.313069Z",
     "iopub.status.busy": "2021-07-07T12:03:43.312697Z",
     "iopub.status.idle": "2021-07-07T12:03:43.318841Z",
     "shell.execute_reply": "2021-07-07T12:03:43.317752Z",
     "shell.execute_reply.started": "2021-07-07T12:03:43.313040Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_state, num_status, num_outputs, device_ = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device_\n",
    "        self.encoder_hidden = 16\n",
    "        \n",
    "        self.phys_encoder = Encoder(num_state, self.encoder_hidden, 1, 0.6, device_)\n",
    "        self.stat_encoder = Encoder(num_status, self.encoder_hidden, 1, 0.6, device_)\n",
    "        self.decoder = AttDecoder(num_outputs, self.encoder_hidden*2, 1, 0.3, device_)\n",
    "        \n",
    "        self.conv = nn.Conv1d(self.encoder_hidden*4, 3, 1)\n",
    "        \n",
    "    def forward(self, phys, stat):\n",
    "        phys_x, phys_h = self.phys_encoder(phys)\n",
    "        stat_x, stat_h = self.stat_encoder(stat)\n",
    "\n",
    "        h0 = torch.cat([phys_h, stat_h], axis = 2)\n",
    "        x0 = torch.cat([phys_x, stat_x], axis = 2)\n",
    "        \n",
    "        out_ = torch.zeros(phys.shape[0], phys.shape[1], self.encoder_hidden * 4).to(self.device)\n",
    "        hd = h0\n",
    "        for i in range(phys.shape[1]):\n",
    "            out_[:,i,:], hd, weights = self.decoder(phys[:,i,:3].unsqueeze(1), hd, x0)\n",
    "            \n",
    "        out = out_.transpose(1,2)\n",
    "        out = self.conv(out)\n",
    "        out = out.transpose(1,2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:21.186168Z",
     "start_time": "2021-07-08T14:39:18.403702Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:04:20.149399Z",
     "iopub.status.busy": "2021-07-07T12:04:20.149071Z",
     "iopub.status.idle": "2021-07-07T12:04:20.186262Z",
     "shell.execute_reply": "2021-07-07T12:04:20.185248Z",
     "shell.execute_reply.started": "2021-07-07T12:04:20.149372Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BaseModel(len(phys_features), len(stat_features), len(labels), device)\n",
    "model.to(device)\n",
    "# model.load_state_dict(torch.load(\"./models/DualEncoderAttention/model-2_checkpoint/model-22-6455965.0.pth\"))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                mode = 'min',\n",
    "                                                factor = 0.1,\n",
    "                                                patience = 5,\n",
    "                                                verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:21.201166Z",
     "start_time": "2021-07-08T14:39:21.187167Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:05:02.451618Z",
     "iopub.status.busy": "2021-07-07T12:05:02.451267Z",
     "iopub.status.idle": "2021-07-07T12:05:02.461439Z",
     "shell.execute_reply": "2021-07-07T12:05:02.460474Z",
     "shell.execute_reply.started": "2021-07-07T12:05:02.451589Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, progress_log):\n",
    "    model.train()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    for phys, stat, label in progress_log:\n",
    "        \n",
    "        phys = phys.to(device)\n",
    "        stat = stat.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 경사를 0으로 초기화\n",
    "        pred = model(phys, stat)  # 데이터를 입력하고 출력을 계산\n",
    "        \n",
    "        loss = gps_loss(pred, label)  # 출력과 훈련 데이터 정답 간의 오차를 계산\n",
    "        score = gps_score(pred, label)  # 출력과 훈련 데이터 정답 간의 오차를 계산\n",
    "\n",
    "        loss.backward()  # 오차를 역전파 계산\n",
    "        optimizer.step()  # 역전파 계산한 값으로 가중치를 수정\n",
    "        \n",
    "        predict.append(pred)\n",
    "        ground.append(label)\n",
    "            \n",
    "    loss, score = calc_loss_and_score(predict, ground)\n",
    "    \n",
    "    del predict, ground\n",
    "    return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:21.216167Z",
     "start_time": "2021-07-08T14:39:21.202167Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:05:02.451618Z",
     "iopub.status.busy": "2021-07-07T12:05:02.451267Z",
     "iopub.status.idle": "2021-07-07T12:05:02.461439Z",
     "shell.execute_reply": "2021-07-07T12:05:02.460474Z",
     "shell.execute_reply.started": "2021-07-07T12:05:02.451589Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid(epoch, progress_log):\n",
    "    model.eval()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for phys, stat, label in progress_log:\n",
    "\n",
    "            phys = phys.to(device)\n",
    "            stat = stat.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            pred = model(phys, stat)  # 데이터를 입력하고 출력을 계산\n",
    "\n",
    "            predict.append(pred)\n",
    "            ground.append(label)\n",
    "            \n",
    "    loss, score = calc_loss_and_score(predict, ground)\n",
    "    \n",
    "    del predict, ground\n",
    "    return loss, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-08T14:39:21.231167Z",
     "start_time": "2021-07-08T14:39:21.217168Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:05:02.451618Z",
     "iopub.status.busy": "2021-07-07T12:05:02.451267Z",
     "iopub.status.idle": "2021-07-07T12:05:02.461439Z",
     "shell.execute_reply": "2021-07-07T12:05:02.460474Z",
     "shell.execute_reply.started": "2021-07-07T12:05:02.451589Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch, progress_log):\n",
    "    model.eval()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for phys, stat, _ in progress_log:\n",
    "\n",
    "            phys = phys.to(device)\n",
    "            stat = stat.to(device)\n",
    "\n",
    "            pred = model(phys, stat)  # 데이터를 입력하고 출력을 계산\n",
    "\n",
    "            predict.append(pred.cpu())\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-08T14:38:53.491Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6adfe5cdf4440598637a1ba60c3f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EPOCH:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VALID:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "|EPOCH: 1/10000\n",
      "|TRAIN: loss=12628969.000000,  score=12702318.000000|\n",
      "|VALID: loss=12467236.000000,  score=12474848.000000|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VALID:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "|EPOCH: 2/10000\n",
      "|TRAIN: loss=12279160.000000,  score=12367746.000000|\n",
      "|VALID: loss=12051693.000000,  score=12060961.000000|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VALID:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------\n",
      "|EPOCH: 3/10000\n",
      "|TRAIN: loss=11837885.000000,  score=11940806.000000|\n",
      "|VALID: loss=11579855.000000,  score=11592094.000000|\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7766ff4f6d46f59b484fdf1b6a41c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260c9c309610464598ba962e591d64e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VALID:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_score_list = []\n",
    "valid_loss_list = []\n",
    "valid_score_list = []\n",
    "\n",
    "patience_count = 0\n",
    "min_valid_score = np.inf\n",
    "checkpoint_name = \"\"\n",
    "\n",
    "if not os.path.isdir(f\"./models/{notebookName}/model-{num_files}_checkpoint/\"):\n",
    "    os.mkdir(f\"./models/{notebookName}/model-{num_files}_checkpoint/\")\n",
    "    \n",
    "prog_epoch = tqdm(range(0, nepochs), position = 0, desc = 'EPOCH')\n",
    "for epoch in prog_epoch:\n",
    "    prog_train = tqdm(train_loader, desc = 'TRAIN', leave = False)\n",
    "    prog_valid = tqdm(valid_loader, desc = 'VALID', leave = False)\n",
    "    \n",
    "    train_loss, train_score = train(epoch, prog_train)\n",
    "    valid_loss, valid_score = valid(epoch, prog_valid)\n",
    "    \n",
    "    scheduler.step(valid_score)\n",
    "    \n",
    "    if min_valid_score > valid_score:\n",
    "        min_valid_score = valid_score\n",
    "        checkpoint_name = f\"./models/{notebookName}/model-{num_files}_checkpoint/model-{epoch}-{valid_score}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_name)\n",
    "    else:\n",
    "        patience_count+=1\n",
    "        if(patience_count > max_patience_count):\n",
    "            break\n",
    "        \n",
    "    train_loss_list.append(train_loss)\n",
    "    train_score_list.append(train_score)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_score_list.append(valid_score)\n",
    "    \n",
    "    print( \"-------------------------------------------------------\")\n",
    "    print(f\"|EPOCH: {epoch+1}/{nepochs}\")\n",
    "    print(f\"|TRAIN: loss={train_loss:.6f},  score={train_score:.6f}|\")\n",
    "    print(f\"|VALID: loss={valid_loss:.6f},  score={valid_score:.6f}|\")\n",
    "    \n",
    "    \n",
    "history = dict()\n",
    "history['train_loss'] = train_loss_list\n",
    "history['train_score'] = train_score_list\n",
    "history['valid_loss'] = valid_loss_list\n",
    "history['valid_score'] = valid_score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-08T14:38:53.495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load submission sample\n",
    "submission = pd.read_csv(str(data_dir / \"sample_submission.csv\"))\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-08T14:38:53.497Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(checkpoint_name))\n",
    "torch.save(model.state_dict(), f\"./models/{notebookName}/model-{min_valid_score}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-08T14:38:53.499Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = test(0, tqdm(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-08T14:38:53.501Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = torch.cat(predict, axis = 1).squeeze(0)\n",
    "submission['latDeg'] = predict[:,0]\n",
    "submission['lngDeg'] = predict[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-08T14:38:53.502Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f\"./models/{notebookName}/result-{num_files}-{min_valid_score}.csv\", index = False)\n",
    "pd.DataFrame([]).to_csv(PATH / f\"{num_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "1. [pytorch tutorial-seq2seq_translation](https://tutorials.pytorch.kr/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

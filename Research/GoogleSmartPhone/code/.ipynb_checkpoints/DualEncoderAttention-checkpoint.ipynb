{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:40.323591Z",
     "start_time": "2021-07-07T15:54:37.387581Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.086273Z",
     "iopub.status.busy": "2021-07-07T12:01:13.085956Z",
     "iopub.status.idle": "2021-07-07T12:01:13.101791Z",
     "shell.execute_reply": "2021-07-07T12:01:13.100287Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.086245Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchsummary\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:40.368580Z",
     "start_time": "2021-07-07T15:54:40.324591Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.103578Z",
     "iopub.status.busy": "2021-07-07T12:01:13.103247Z",
     "iopub.status.idle": "2021-07-07T12:01:13.115766Z",
     "shell.execute_reply": "2021-07-07T12:01:13.114970Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.103527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:40.383580Z",
     "start_time": "2021-07-07T15:54:40.370581Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:03:55.554162Z",
     "iopub.status.busy": "2021-07-07T12:03:55.553783Z",
     "iopub.status.idle": "2021-07-07T12:03:55.558107Z",
     "shell.execute_reply": "2021-07-07T12:03:55.557314Z",
     "shell.execute_reply.started": "2021-07-07T12:03:55.554125Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 19901109\n",
    "batch_size = 1\n",
    "learning_rate = 0.001\n",
    "nepochs = 10\n",
    "max_patience_count = 100\n",
    "notebookName = \"DualEncoderAttention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:40.398580Z",
     "start_time": "2021-07-07T15:54:40.385582Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH = Path(f\"./models/{notebookName}\")\n",
    "if os.path.isdir(PATH):\n",
    "    dir_list = os.listdir(PATH)\n",
    "    num_files = 0\n",
    "    while True:\n",
    "        if os.path.isfile(str(PATH / f\"{num_files}\")):\n",
    "            print(num_files)\n",
    "            num_files += 1\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    os.mkdir(PATH)\n",
    "    num_files = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:40.413580Z",
     "start_time": "2021-07-07T15:54:40.400582Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.133248Z",
     "iopub.status.busy": "2021-07-07T12:01:13.132945Z",
     "iopub.status.idle": "2021-07-07T12:01:13.150499Z",
     "shell.execute_reply": "2021-07-07T12:01:13.149500Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.133220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x23209526d80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:40.578580Z",
     "start_time": "2021-07-07T15:54:40.414581Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.152611Z",
     "iopub.status.busy": "2021-07-07T12:01:13.152281Z",
     "iopub.status.idle": "2021-07-07T12:01:13.572302Z",
     "shell.execute_reply": "2021-07-07T12:01:13.571313Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.152581Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"../input/google-smartphone-decimeter-challenge/\")\n",
    "df_train_default = pd.read_pickle(str(data_dir / \"gsdc_extract_train.pkl.gzip\"))\n",
    "df_test = pd.read_pickle(str(data_dir / \"gsdc_extract_test.pkl.gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:41.418580Z",
     "start_time": "2021-07-07T15:54:40.579581Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:13.573999Z",
     "iopub.status.busy": "2021-07-07T12:01:13.573647Z",
     "iopub.status.idle": "2021-07-07T12:01:15.608460Z",
     "shell.execute_reply": "2021-07-07T12:01:15.607254Z",
     "shell.execute_reply.started": "2021-07-07T12:01:13.573969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120224, 148) (11504, 148)\n"
     ]
    }
   ],
   "source": [
    "def CustomTrainValidSplit(df:pd.DataFrame, valid_size):\n",
    "    phones = df['phone'].unique()\n",
    "    \n",
    "    valid_num = int(len(phones) * valid_size)\n",
    "    train_num = len(phones) - valid_num\n",
    "    \n",
    "    indexes = np.array(range(len(phones)))\n",
    "    indexes = np.random.choice(indexes, len(indexes))\n",
    "    \n",
    "    df_train = []\n",
    "    for phone in phones[indexes[:train_num]]:\n",
    "        df_train.append(df[df['phone'] == phone])\n",
    "    df_train = pd.concat(df_train)\n",
    "    \n",
    "    df_valid = []\n",
    "    for phone in phones[indexes[train_num:-1]]:\n",
    "        df_valid.append(df[df['phone'] == phone])\n",
    "    df_valid = pd.concat(df_valid)\n",
    "    \n",
    "    return df_train.reset_index().drop(columns = 'index'), df_valid.reset_index().drop(columns = 'index')\n",
    "    \n",
    "df_train, df_valid = CustomTrainValidSplit(df_train_default, valid_size = 0.1)\n",
    "print(df_train.shape, df_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:00:47.813085Z",
     "start_time": "2021-07-07T16:00:47.807084Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:15.610068Z",
     "iopub.status.busy": "2021-07-07T12:01:15.609730Z",
     "iopub.status.idle": "2021-07-07T12:01:15.618404Z",
     "shell.execute_reply": "2021-07-07T12:01:15.617229Z",
     "shell.execute_reply.started": "2021-07-07T12:01:15.610038Z"
    }
   },
   "outputs": [],
   "source": [
    "class TimeSeriseDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, phys_features, stat_features, labels, train = False):\n",
    "        self.phys_features = phys_features\n",
    "        self.stat_features = stat_features\n",
    "        self.labels = labels\n",
    "        self.train = train\n",
    "        self.phones =df['phone'].unique()\n",
    "        self._len = len(self.phones)\n",
    "        \n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        phys_features = self.phys_features\n",
    "        stat_features = self.stat_features\n",
    "        labels = self.labels\n",
    "        phone = self.phones[idx]\n",
    "        \n",
    "        df = self.df[self.df['phone']==phone]\n",
    "        \n",
    "        \n",
    "        phys = torch.Tensor(df[phys_features].values)\n",
    "        stat = torch.Tensor(df[stat_features].values)\n",
    "        if self.train:\n",
    "            label = torch.Tensor(df[labels].values)\n",
    "        else:\n",
    "            label = torch.Tensor([])\n",
    "        return phys, stat, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:00:52.898081Z",
     "start_time": "2021-07-07T16:00:52.884082Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:15.622098Z",
     "iopub.status.busy": "2021-07-07T12:01:15.621813Z",
     "iopub.status.idle": "2021-07-07T12:01:15.859545Z",
     "shell.execute_reply": "2021-07-07T12:01:15.858532Z",
     "shell.execute_reply.started": "2021-07-07T12:01:15.622072Z"
    }
   },
   "outputs": [],
   "source": [
    "phys_features = [\n",
    "    'latDeg', \n",
    "    'lngDeg', \n",
    "    'heightAboveWgs84EllipsoidM',\n",
    "    'dlatDeg',\n",
    "    'dlngDeg',\n",
    "    'dheight',\n",
    "    'UncalGyroXRadPerSec',\n",
    "    'UncalGyroYRadPerSec',\n",
    "    'UncalGyroZRadPerSec',\n",
    "    'DriftXRadPerSec',\n",
    "    'DriftYRadPerSec',\n",
    "    'DriftZRadPerSec',\n",
    "    'UncalAccelXMps2',\n",
    "    'UncalAccelYMps2',\n",
    "    'UncalAccelZMps2',\n",
    "    'BiasXMps2',\n",
    "    'BiasYMps2',\n",
    "    'BiasZMps2',\n",
    "    'UncalMagXMicroT',\n",
    "    'UncalMagYMicroT',\n",
    "    'UncalMagZMicroT',\n",
    "    'BiasXMicroT',\n",
    "    'BiasYMicroT',\n",
    "    'BiasZMicroT',\n",
    "    'yawDeg',\n",
    "    'rollDeg',\n",
    "    'pitchDeg',\n",
    "]\n",
    "stat_features = [\n",
    "    'GPS_L1', \n",
    "    'GPS_L5', \n",
    "    'GAL_E1', \n",
    "    'GAL_E5A', \n",
    "    'GLO_G1', \n",
    "    'BDS_B1I', \n",
    "    'BDS_B1C', \n",
    "    'BDS_B2A', \n",
    "    'QZS_J1', \n",
    "    'QZS_J5',\n",
    "    'xSatPosM',\n",
    "    'ySatPosM',\n",
    "    'zSatPosM',\n",
    "    'xSatVelMps',\n",
    "    'ySatVelMps',\n",
    "    'zSatVelMps',\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    't_latDeg', \n",
    "    't_lngDeg', \n",
    "    't_heightAboveWgs84EllipsoidM',\n",
    "#     'courseDegree',\n",
    "#     'hDop',\n",
    "#     'vDop',\n",
    "#     'speedMps'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:00:57.848081Z",
     "start_time": "2021-07-07T16:00:57.819081Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:01:15.861361Z",
     "iopub.status.busy": "2021-07-07T12:01:15.861068Z",
     "iopub.status.idle": "2021-07-07T12:01:15.907026Z",
     "shell.execute_reply": "2021-07-07T12:01:15.906093Z",
     "shell.execute_reply.started": "2021-07-07T12:01:15.861334Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = TimeSeriseDataset(df_train, \n",
    "                           phys_features, stat_features, labels,\n",
    "                           train = True)\n",
    "valid_data = TimeSeriseDataset(df_valid, \n",
    "                           phys_features, stat_features, labels,\n",
    "                           train = True)\n",
    "test_data = TimeSeriseDataset(df_test, \n",
    "                           phys_features, stat_features, labels,\n",
    "                           train = False)\n",
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:01:02.963138Z",
     "start_time": "2021-07-07T16:01:02.949138Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:03:43.108868Z",
     "iopub.status.busy": "2021-07-07T12:03:43.108516Z",
     "iopub.status.idle": "2021-07-07T12:03:43.124141Z",
     "shell.execute_reply": "2021-07-07T12:03:43.122937Z",
     "shell.execute_reply.started": "2021-07-07T12:03:43.108841Z"
    }
   },
   "outputs": [],
   "source": [
    "def torch_haversine(pred, true):\n",
    "\n",
    "    lat1=pred[:,0] % 360\n",
    "    lon1=pred[:,1] % 360\n",
    "    lat2=true[:,0] % 360\n",
    "    lon2=true[:,1] % 360\n",
    "\n",
    "    lat1, lat2, lon1, lon2 = map(lambda x:x*np.pi/180, [lat1, lat2, lon1, lon2])\n",
    "\n",
    "    dlat = (lat2 - lat1)\n",
    "    dlon = (lon2 - lon1)\n",
    "\n",
    "    a = torch.sin(dlat / 2.0)**2 + torch.cos(lat1) * torch.cos(lat2) * (torch.sin(dlon / 2.0)**2)\n",
    "    c = 2 * torch.arcsin(a ** 0.5)\n",
    "\n",
    "    dist = 6_367_000 * c\n",
    "\n",
    "    return dist\n",
    "\n",
    "def quantile_mean(dist):\n",
    "    return (torch.quantile(dist, 0.5) + torch.quantile(dist, 0.95))/2\n",
    "    \n",
    "def gps_loss(predict:torch.Tensor, target:torch.Tensor):\n",
    "    dist = torch_haversine(predict, target)\n",
    "\n",
    "    loss = dist.mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def gps_score(predict:torch.Tensor, target:torch.Tensor):\n",
    "    dist = torch_haversine(predict, target)\n",
    "\n",
    "    score = quantile_mean(dist)\n",
    "\n",
    "    return score\n",
    "\n",
    "def calc_loss_and_score(predicts, grounds):\n",
    "    dist = []\n",
    "    for pred, ground in zip(predicts, grounds):\n",
    "        pred = pred.squeeze(0)\n",
    "        ground = ground.squeeze(0)\n",
    "        dist.append(torch_haversine(pred, ground))\n",
    "    dist = torch.cat(dist, axis = 0)\n",
    "    return dist.mean(), quantile_mean(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:01:08.003152Z",
     "start_time": "2021-07-07T16:01:07.989153Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_features, num_hiddens, num_layers, dropout = 0.1, device_ = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device_\n",
    "        \n",
    "        self.gru = nn.GRU(num_features, num_hiddens, num_layers, batch_first = True, dropout = dropout, bidirectional = True)\n",
    "    def forward(self, x):\n",
    "        x, h = self.gru(x)\n",
    "        h = h.to(device)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:41.523580Z",
     "start_time": "2021-07-07T15:54:41.510581Z"
    }
   },
   "outputs": [],
   "source": [
    "class AttDecoder(nn.Module):\n",
    "    def __init__(self, num_features, num_hiddens, num_layers, dropout = 0.1, device_ = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device_\n",
    "        self.num_features = num_features\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.max_length = 10000\n",
    "        \n",
    "        self.attn = nn.Linear(3 + num_hiddens*2, self.max_length)\n",
    "        self.comb = nn.Linear(3 + num_hiddens*2, num_features)\n",
    "        \n",
    "        self.gru = nn.GRU(num_features, num_hiddens, num_layers, batch_first = True, dropout = dropout, bidirectional = True)\n",
    "    def forward(self, x, h0, x0):\n",
    "        hd = h0.reshape(1, 1, self.num_hiddens * 2)\n",
    "        c = torch.cat([x, hd], axis = 2).reshape(-1, 3 + self.num_hiddens * 2)\n",
    "        w = self.attn(c)\n",
    "        w = w[:,:x0.shape[1]]\n",
    "        w = F.softmax(w).unsqueeze(1)\n",
    "        applied = torch.bmm(w, x0)\n",
    "        \n",
    "        output = torch.cat([x, applied], axis = 2)\n",
    "        output = self.comb(output)\n",
    "        output = F.relu(output)\n",
    "        \n",
    "        output, h = self.gru(output, h0)\n",
    "        h = h.to(device)\n",
    "        return output, h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:41.538580Z",
     "start_time": "2021-07-07T15:54:41.524581Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:03:43.313069Z",
     "iopub.status.busy": "2021-07-07T12:03:43.312697Z",
     "iopub.status.idle": "2021-07-07T12:03:43.318841Z",
     "shell.execute_reply": "2021-07-07T12:03:43.317752Z",
     "shell.execute_reply.started": "2021-07-07T12:03:43.313040Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, num_state, num_status, num_outputs, device_ = 'cpu'):\n",
    "        super().__init__()\n",
    "        self.device = device_\n",
    "        self.encoder_hidden = 16\n",
    "        \n",
    "        self.phys_encoder = Encoder(num_state, self.encoder_hidden, 1, 0.6, device_)\n",
    "        self.stat_encoder = Encoder(num_status, self.encoder_hidden, 1, 0.6, device_)\n",
    "        self.decoder = AttDecoder(num_outputs, self.encoder_hidden*2, 1, 0.3, device_)\n",
    "        \n",
    "        self.conv = nn.Conv1d(self.encoder_hidden*4, 3, 1)\n",
    "        \n",
    "    def forward(self, phys, stat):\n",
    "        phys_x, phys_h = self.phys_encoder(phys)\n",
    "        stat_x, stat_h = self.stat_encoder(stat)\n",
    "\n",
    "        h0 = torch.cat([phys_h, stat_h], axis = 2)\n",
    "        x0 = torch.cat([phys_x, stat_x], axis = 2)\n",
    "        \n",
    "        out_ = torch.zeros(phys.shape[0], phys.shape[1], self.encoder_hidden * 4).to(self.device)\n",
    "        hd = h0\n",
    "        for i in range(phys.shape[1]):\n",
    "            out_[:,i,:], hd, weights = self.decoder(phys[:,i,:3].unsqueeze(1), hd, x0)\n",
    "            \n",
    "        out = out_.transpose(1,2)\n",
    "        out = self.conv(out)\n",
    "        out = out.transpose(1,2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:43.698994Z",
     "start_time": "2021-07-07T15:54:41.539582Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:04:20.149399Z",
     "iopub.status.busy": "2021-07-07T12:04:20.149071Z",
     "iopub.status.idle": "2021-07-07T12:04:20.186262Z",
     "shell.execute_reply": "2021-07-07T12:04:20.185248Z",
     "shell.execute_reply.started": "2021-07-07T12:04:20.149372Z"
    }
   },
   "outputs": [],
   "source": [
    "model = BaseModel(len(phys_features), len(stat_features), len(labels), device)\n",
    "model.to(device)\n",
    "# model.load_state_dict(torch.load(\"./models/Baseline3/model-4.pth\"))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer,\n",
    "                                                mode = 'min',\n",
    "                                                factor = 0.1,\n",
    "                                                patience = 5,\n",
    "                                                verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:43.713995Z",
     "start_time": "2021-07-07T15:54:43.699996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModel(\n",
       "  (phys_encoder): Encoder(\n",
       "    (gru): GRU(27, 16, batch_first=True, dropout=0.6, bidirectional=True)\n",
       "  )\n",
       "  (stat_encoder): Encoder(\n",
       "    (gru): GRU(16, 16, batch_first=True, dropout=0.6, bidirectional=True)\n",
       "  )\n",
       "  (decoder): AttDecoder(\n",
       "    (attn): Linear(in_features=67, out_features=10000, bias=True)\n",
       "    (comb): Linear(in_features=67, out_features=3, bias=True)\n",
       "    (gru): GRU(3, 32, batch_first=True, dropout=0.3, bidirectional=True)\n",
       "  )\n",
       "  (conv): Conv1d(64, 3, kernel_size=(1,), stride=(1,))\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function MmBackward returned an invalid gradient at index 0 - got [1, 35] but expected shape compatible with [1, 67]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:43.728994Z",
     "start_time": "2021-07-07T15:54:43.715994Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:05:02.451618Z",
     "iopub.status.busy": "2021-07-07T12:05:02.451267Z",
     "iopub.status.idle": "2021-07-07T12:05:02.461439Z",
     "shell.execute_reply": "2021-07-07T12:05:02.460474Z",
     "shell.execute_reply.started": "2021-07-07T12:05:02.451589Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, progress_log):\n",
    "    model.train()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    for phys, stat, label in progress_log:\n",
    "        \n",
    "        phys = phys.to(device)\n",
    "        stat = stat.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 경사를 0으로 초기화\n",
    "        pred = model(phys, stat)  # 데이터를 입력하고 출력을 계산\n",
    "        \n",
    "        loss = gps_loss(pred, label)  # 출력과 훈련 데이터 정답 간의 오차를 계산\n",
    "        score = gps_score(pred, label)  # 출력과 훈련 데이터 정답 간의 오차를 계산\n",
    "\n",
    "        loss.backward()  # 오차를 역전파 계산\n",
    "        optimizer.step()  # 역전파 계산한 값으로 가중치를 수정\n",
    "        \n",
    "        predict.append(pred.cpu())\n",
    "        ground.append(label.cpu())\n",
    "    \n",
    "    return predict, ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:43.743995Z",
     "start_time": "2021-07-07T15:54:43.730996Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:05:02.451618Z",
     "iopub.status.busy": "2021-07-07T12:05:02.451267Z",
     "iopub.status.idle": "2021-07-07T12:05:02.461439Z",
     "shell.execute_reply": "2021-07-07T12:05:02.460474Z",
     "shell.execute_reply.started": "2021-07-07T12:05:02.451589Z"
    }
   },
   "outputs": [],
   "source": [
    "def valid(epoch, progress_log):\n",
    "    model.eval()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for phys, stat, label in progress_log:\n",
    "\n",
    "            phys = phys.to(device)\n",
    "            stat = stat.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            pred = model(phys, stat)  # 데이터를 입력하고 출력을 계산\n",
    "\n",
    "            predict.append(pred.cpu())\n",
    "            ground.append(label.cpu())\n",
    "    \n",
    "    return predict, ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:54:43.758997Z",
     "start_time": "2021-07-07T15:54:43.744996Z"
    },
    "execution": {
     "iopub.execute_input": "2021-07-07T12:05:02.451618Z",
     "iopub.status.busy": "2021-07-07T12:05:02.451267Z",
     "iopub.status.idle": "2021-07-07T12:05:02.461439Z",
     "shell.execute_reply": "2021-07-07T12:05:02.460474Z",
     "shell.execute_reply.started": "2021-07-07T12:05:02.451589Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch, progress_log):\n",
    "    model.eval()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for phys, stat, _ in progress_log:\n",
    "\n",
    "            phys = phys.to(device)\n",
    "            stat = stat.to(device)\n",
    "\n",
    "            pred = model(phys, stat)  # 데이터를 입력하고 출력을 계산\n",
    "\n",
    "            predict.append(pred.cpu())\n",
    "    \n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:57:43.378059Z",
     "start_time": "2021-07-07T15:54:56.876443Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80026a3c2dd4959ac149bc5f0984d78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "EPOCH:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "TRAIN:   0%|          | 0/45 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VALID:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'min_valid_meas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e2b6d853234f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmin_valid_score\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mvalid_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mmin_valid_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mcheckpoint_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"./models/{notebookName}/model-{num_files}_checkpoint/model-{epoch}-{min_valid_meas}.pth\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'min_valid_meas' is not defined"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "train_meas_list = []\n",
    "valid_loss_list = []\n",
    "valid_meas_list = []\n",
    "\n",
    "patience_count = 0\n",
    "min_valid_score = np.inf\n",
    "checkpoint_name = \"\"\n",
    "\n",
    "if not os.path.isdir(f\"./models/{notebookName}/model-{num_files}_checkpoint/\"):\n",
    "    os.mkdir(f\"./models/{notebookName}/model-{num_files}_checkpoint/\")\n",
    "    \n",
    "prog_epoch = tqdm(range(nepochs), position = 0, desc = 'EPOCH')\n",
    "for epoch in prog_epoch:\n",
    "    prog_train = tqdm(train_loader, desc = 'TRAIN', leave = False)\n",
    "    prog_valid = tqdm(valid_loader, desc = 'VALID', leave = False)\n",
    "    \n",
    "    train_predict, train_ground = train(epoch, prog_train)\n",
    "    valid_predict, valid_ground = valid(epoch, prog_valid)\n",
    "    \n",
    "    train_loss, train_score = calc_loss_and_score(train_predict, train_ground)\n",
    "    valid_loss, valid_score = calc_loss_and_score(valid_predict, valid_ground)\n",
    "    \n",
    "    scheduler.step(valid_score)\n",
    "    \n",
    "    if min_valid_score > valid_score:\n",
    "        min_valid_score = valid_score\n",
    "        checkpoint_name = f\"./models/{notebookName}/model-{num_files}_checkpoint/model-{epoch}-{valid_score}.pth\"\n",
    "        torch.save(model.state_dict(), checkpoint_name)\n",
    "    else:\n",
    "        patience_count+=1\n",
    "        if(patience_count > max_patience_count):\n",
    "            break\n",
    "        \n",
    "    train_loss_list.append(train_loss)\n",
    "    train_meas_list.append(train_meas)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "    valid_meas_list.append(valid_meas)\n",
    "    \n",
    "    print( \"-------------------------------------------------------\")\n",
    "    print(f\"|EPOCH: {epoch+1}/{nepochs}\")\n",
    "    print(f\"|TRAIN: loss={train_loss:.6f},  score={train_score:.6f}|\")\n",
    "    print(f\"|VALID: loss={valid_loss:.6f},  score={valid_score:.6f}|\")\n",
    "    \n",
    "    \n",
    "history = dict()\n",
    "history['train_loss'] = train_loss_list\n",
    "history['train_meas'] = train_meas_list\n",
    "history['valid_loss'] = valid_loss_list\n",
    "history['valid_meas'] = valid_meas_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:58:08.034727Z",
     "start_time": "2021-07-07T15:58:07.915732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91486, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phone</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1273608785432</td>\n",
       "      <td>37.904611</td>\n",
       "      <td>-86.481078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1273608786432</td>\n",
       "      <td>37.904611</td>\n",
       "      <td>-86.481078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1273608787432</td>\n",
       "      <td>37.904611</td>\n",
       "      <td>-86.481078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1273608788432</td>\n",
       "      <td>37.904611</td>\n",
       "      <td>-86.481078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4</td>\n",
       "      <td>1273608789432</td>\n",
       "      <td>37.904611</td>\n",
       "      <td>-86.481078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        phone  millisSinceGpsEpoch     latDeg     lngDeg\n",
       "0  2020-05-15-US-MTV-1_Pixel4        1273608785432  37.904611 -86.481078\n",
       "1  2020-05-15-US-MTV-1_Pixel4        1273608786432  37.904611 -86.481078\n",
       "2  2020-05-15-US-MTV-1_Pixel4        1273608787432  37.904611 -86.481078\n",
       "3  2020-05-15-US-MTV-1_Pixel4        1273608788432  37.904611 -86.481078\n",
       "4  2020-05-15-US-MTV-1_Pixel4        1273608789432  37.904611 -86.481078"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load submission sample\n",
    "submission = pd.read_csv(str(data_dir / \"sample_submission.csv\"))\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T15:58:52.583376Z",
     "start_time": "2021-07-07T15:58:52.564376Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(checkpoint_name))\n",
    "torch.save(model.state_dict(), f\"./models/{notebookName}/model-{min_valid_score}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:01:55.868155Z",
     "start_time": "2021-07-07T16:01:12.954155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa09a0437d224b8ebbaf5a2ed58dec5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict = test(0, tqdm(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:04:45.907644Z",
     "start_time": "2021-07-07T16:04:45.538654Z"
    }
   },
   "outputs": [],
   "source": [
    "predict = torch.cat(predict, axis = 1).squeeze(0)\n",
    "submission['latDeg'] = predict[:,0]\n",
    "submission['lngDeg'] = predict[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-07T16:04:57.809125Z",
     "start_time": "2021-07-07T16:04:57.497125Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f\"./models/{notebookName}/result-{num_files}-{min_valid_score}.csv\", index = False)\n",
    "pd.DataFrame([]).to_csv(PATH / f\"{num_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

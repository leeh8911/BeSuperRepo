{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# references\n",
    "1. https://www.kaggle.com/columbia2131/device-eda-interpolate-by-removing-device-en-ja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.520698Z",
     "start_time": "2021-06-23T08:31:56.570569Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.595700Z",
     "start_time": "2021-06-23T08:31:59.522700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.610751Z",
     "start_time": "2021-06-23T08:31:59.597698Z"
    }
   },
   "outputs": [],
   "source": [
    "notebookName = 'Baseline'\n",
    "PATH = Path(f\"./models/{notebookName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.625700Z",
     "start_time": "2021-06-23T08:31:59.612700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(PATH):\n",
    "    dir_list = os.listdir(PATH)\n",
    "    num_files = 0\n",
    "    while True:\n",
    "        if os.path.isfile(str(PATH / f\"{num_files}\")):\n",
    "            print(num_files)\n",
    "            num_files += 1\n",
    "        else:\n",
    "            break\n",
    "else:\n",
    "    os.mkdir(PATH)\n",
    "    num_files = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.640699Z",
     "start_time": "2021-06-23T08:31:59.626699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.655700Z",
     "start_time": "2021-06-23T08:31:59.642699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('models\\\\Baseline\\\\model - 5.pth',\n",
       " 'models\\\\Baseline\\\\param - 5.pth',\n",
       " 'models\\\\Baseline\\\\result - 5.csv')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_STATE = 42\n",
    "lr = 0.001\n",
    "batch_size = 4\n",
    "EPOCH_NUM = 1000\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "\n",
    "experience_name = f\"{num_files}\"\n",
    "checkpoint_name = \"check_point\"\n",
    "model_name = str(\"model - \" + experience_name)\n",
    "param_name = str(\"param - \" + experience_name)\n",
    "result_name = str(\"result - \" + experience_name)\n",
    "\n",
    "dummy_path = str(PATH / f\"{num_files}\")\n",
    "checkpoint_path = str(PATH / f\"{checkpoint_name}.pth\")\n",
    "model_path = str(PATH / f\"{model_name}.pth\")\n",
    "param_path = str(PATH / f\"{param_name}.pth\")\n",
    "result_path = str(PATH / f\"{result_name}.csv\")\n",
    "model_path, param_path, result_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.670699Z",
     "start_time": "2021-06-23T08:31:59.657700Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    dlat = (lat2 - lat1) % 360\n",
    "    dlon = (lon2 - lon1) % 360 \n",
    "    \n",
    "    dlat, dlon = map(np.radians, [dlat, dlon])\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(a ** 0.5)\n",
    "    c = c + np.isnan(c) * ((a > 1) * np.pi/2 + (a < -1) * (-1 * np.pi / 2))\n",
    "        \n",
    "    dist = 6_367_000 * c\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.685699Z",
     "start_time": "2021-06-23T08:31:59.673698Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_score(input_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    output_df = input_df.copy()\n",
    "    \n",
    "    output_df['meter'] = input_df.apply(\n",
    "        lambda r: calc_haversine(\n",
    "            r.latDeg, r.lngDeg, r.t_latDeg, r.t_lngDeg\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    meter_score = output_df['meter'].mean()\n",
    "    print(f'error meter: {meter_score}')\n",
    "\n",
    "    scores = []\n",
    "    for phone in output_df['phone'].unique():\n",
    "        _index = output_df['phone']==phone\n",
    "        p_50 = np.percentile(output_df.loc[_index, 'meter'], 50)\n",
    "        p_95 = np.percentile(output_df.loc[_index, 'meter'], 95)\n",
    "        scores.append(p_50)\n",
    "        scores.append(p_95)\n",
    "\n",
    "    score = sum(scores) / len(scores)\n",
    "    print(f'score: {score}')\n",
    "    \n",
    "    return output_df, meter_score , score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.700698Z",
     "start_time": "2021-06-23T08:31:59.687700Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_score_np(predict:torch.Tensor, target:torch.Tensor):\n",
    "    m = []\n",
    "    predict = predict.detach().numpy()\n",
    "    target = target.detach().numpy()\n",
    "    for i in range(predict.shape[0]):\n",
    "        temp = calc_haversine(predict[i,0], predict[i,1], target[i,0], target[i,1])\n",
    "        m.append(temp)\n",
    "    \n",
    "    m = np.array(m)\n",
    "    score = (np.percentile(m, 50) + np.percentile(m, 95))/2\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:31:59.790701Z",
     "start_time": "2021-06-23T08:31:59.702700Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = Path(\"../input/google-smartphone-decimeter-challenge\")\n",
    "df_train = pd.read_pickle(str(data_dir / \"gsdc_train.pkl.gzip\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:10.597261Z",
     "start_time": "2021-06-23T08:31:59.792699Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error meter: 4.261468362435763\n",
      "score: 5.812326742270749\n"
     ]
    }
   ],
   "source": [
    "# check score\n",
    "df_train, default_loss, default_meas = check_score(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "## Simple view, what is in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:10.627261Z",
     "start_time": "2021-06-23T08:32:10.598260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131342, 111)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>phoneName</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "      <th>heightAboveWgs84EllipsoidM</th>\n",
       "      <th>phone</th>\n",
       "      <th>utcTimeMillis_x</th>\n",
       "      <th>elapsedRealtimeNanos_x</th>\n",
       "      <th>UncalGyroXRadPerSec</th>\n",
       "      <th>...</th>\n",
       "      <th>ySatVelMps</th>\n",
       "      <th>zSatVelMps</th>\n",
       "      <th>satClkBiasM</th>\n",
       "      <th>satClkDriftMps</th>\n",
       "      <th>rawPrM</th>\n",
       "      <th>rawPrUncM</th>\n",
       "      <th>isrbM</th>\n",
       "      <th>ionoDelayM</th>\n",
       "      <th>tropoDelayM</th>\n",
       "      <th>meter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529463442</td>\n",
       "      <td>37.423575</td>\n",
       "      <td>-122.094091</td>\n",
       "      <td>-34.06</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1.589494e+12</td>\n",
       "      <td>1.965654e+13</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>...</td>\n",
       "      <td>156.040</td>\n",
       "      <td>3559.757</td>\n",
       "      <td>-468.084</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.379498e+07</td>\n",
       "      <td>11.992</td>\n",
       "      <td>1134.758</td>\n",
       "      <td>10.866</td>\n",
       "      <td>16.647</td>\n",
       "      <td>4.345847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529464442</td>\n",
       "      <td>37.423578</td>\n",
       "      <td>-122.094101</td>\n",
       "      <td>-33.29</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1.589494e+12</td>\n",
       "      <td>1.965754e+13</td>\n",
       "      <td>-0.003537</td>\n",
       "      <td>...</td>\n",
       "      <td>411.162</td>\n",
       "      <td>-3013.649</td>\n",
       "      <td>65954.431</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.592442e+07</td>\n",
       "      <td>3.897</td>\n",
       "      <td>-222.675</td>\n",
       "      <td>7.111</td>\n",
       "      <td>5.174</td>\n",
       "      <td>3.324526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529465442</td>\n",
       "      <td>37.423573</td>\n",
       "      <td>-122.094111</td>\n",
       "      <td>-30.99</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1.589494e+12</td>\n",
       "      <td>1.965854e+13</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>...</td>\n",
       "      <td>-2776.605</td>\n",
       "      <td>-434.445</td>\n",
       "      <td>1223.261</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.131445e+07</td>\n",
       "      <td>1.499</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.777</td>\n",
       "      <td>3.371</td>\n",
       "      <td>2.279173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529466442</td>\n",
       "      <td>37.423583</td>\n",
       "      <td>-122.094121</td>\n",
       "      <td>-32.83</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4</td>\n",
       "      <td>1.589494e+12</td>\n",
       "      <td>1.965954e+13</td>\n",
       "      <td>-0.015753</td>\n",
       "      <td>...</td>\n",
       "      <td>411.755</td>\n",
       "      <td>-3013.528</td>\n",
       "      <td>65954.426</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.592544e+07</td>\n",
       "      <td>3.598</td>\n",
       "      <td>-220.611</td>\n",
       "      <td>7.113</td>\n",
       "      <td>5.183</td>\n",
       "      <td>1.381411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4XLModded</td>\n",
       "      <td>1273529466449</td>\n",
       "      <td>37.423574</td>\n",
       "      <td>-122.094137</td>\n",
       "      <td>-33.20</td>\n",
       "      <td>2020-05-14-US-MTV-1_Pixel4XLModded</td>\n",
       "      <td>1.589494e+12</td>\n",
       "      <td>1.734189e+13</td>\n",
       "      <td>0.875268</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.334</td>\n",
       "      <td>-3057.885</td>\n",
       "      <td>-3909.257</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.318871e+07</td>\n",
       "      <td>10.493</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7.313</td>\n",
       "      <td>5.311</td>\n",
       "      <td>0.794351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        collectionName       phoneName  millisSinceGpsEpoch     latDeg  \\\n",
       "0  2020-05-14-US-MTV-1          Pixel4        1273529463442  37.423575   \n",
       "1  2020-05-14-US-MTV-1          Pixel4        1273529464442  37.423578   \n",
       "2  2020-05-14-US-MTV-1          Pixel4        1273529465442  37.423573   \n",
       "3  2020-05-14-US-MTV-1          Pixel4        1273529466442  37.423583   \n",
       "4  2020-05-14-US-MTV-1  Pixel4XLModded        1273529466449  37.423574   \n",
       "\n",
       "       lngDeg  heightAboveWgs84EllipsoidM                               phone  \\\n",
       "0 -122.094091                      -34.06          2020-05-14-US-MTV-1_Pixel4   \n",
       "1 -122.094101                      -33.29          2020-05-14-US-MTV-1_Pixel4   \n",
       "2 -122.094111                      -30.99          2020-05-14-US-MTV-1_Pixel4   \n",
       "3 -122.094121                      -32.83          2020-05-14-US-MTV-1_Pixel4   \n",
       "4 -122.094137                      -33.20  2020-05-14-US-MTV-1_Pixel4XLModded   \n",
       "\n",
       "   utcTimeMillis_x  elapsedRealtimeNanos_x  UncalGyroXRadPerSec  ...  \\\n",
       "0     1.589494e+12            1.965654e+13            -0.000502  ...   \n",
       "1     1.589494e+12            1.965754e+13            -0.003537  ...   \n",
       "2     1.589494e+12            1.965854e+13             0.002028  ...   \n",
       "3     1.589494e+12            1.965954e+13            -0.015753  ...   \n",
       "4     1.589494e+12            1.734189e+13             0.875268  ...   \n",
       "\n",
       "   ySatVelMps  zSatVelMps  satClkBiasM  satClkDriftMps        rawPrM  \\\n",
       "0     156.040    3559.757     -468.084           0.001  2.379498e+07   \n",
       "1     411.162   -3013.649    65954.431          -0.002  2.592442e+07   \n",
       "2   -2776.605    -434.445     1223.261           0.000  2.131445e+07   \n",
       "3     411.755   -3013.528    65954.426          -0.002  2.592544e+07   \n",
       "4     -81.334   -3057.885    -3909.257           0.001  2.318871e+07   \n",
       "\n",
       "   rawPrUncM     isrbM  ionoDelayM  tropoDelayM     meter  \n",
       "0     11.992  1134.758      10.866       16.647  4.345847  \n",
       "1      3.897  -222.675       7.111        5.174  3.324526  \n",
       "2      1.499     0.000       4.777        3.371  2.279173  \n",
       "3      3.598  -220.611       7.113        5.183  1.381411  \n",
       "4     10.493     0.000       7.313        5.311  0.794351  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:11.602260Z",
     "start_time": "2021-06-23T08:32:10.628260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectionName\n",
      "count                  131342\n",
      "unique                     29\n",
      "top       2021-01-04-US-RWC-1\n",
      "freq                     8293\n",
      "Name: collectionName, dtype: object\n",
      "\n",
      "phoneName\n",
      "count     131342\n",
      "unique         7\n",
      "top       Pixel4\n",
      "freq       48153\n",
      "Name: phoneName, dtype: object\n",
      "\n",
      "millisSinceGpsEpoch\n",
      "count    1.313420e+05\n",
      "mean     1.287913e+12\n",
      "std      1.162110e+10\n",
      "min      1.273529e+12\n",
      "25%      1.275424e+12\n",
      "50%      1.283279e+12\n",
      "75%      1.302558e+12\n",
      "max      1.303771e+12\n",
      "Name: millisSinceGpsEpoch, dtype: float64\n",
      "\n",
      "latDeg\n",
      "count    131342.000000\n",
      "mean         37.435206\n",
      "std           0.082712\n",
      "min          37.321683\n",
      "25%          37.371575\n",
      "50%          37.424360\n",
      "75%          37.469109\n",
      "max          37.690836\n",
      "Name: latDeg, dtype: float64\n",
      "\n",
      "lngDeg\n",
      "count    131342.000000\n",
      "mean       -122.154925\n",
      "std           0.145974\n",
      "min        -122.472214\n",
      "25%        -122.275109\n",
      "50%        -122.118311\n",
      "75%        -122.069091\n",
      "max        -121.881855\n",
      "Name: lngDeg, dtype: float64\n",
      "\n",
      "heightAboveWgs84EllipsoidM\n",
      "count    131342.000000\n",
      "mean         23.832922\n",
      "std          72.589312\n",
      "min       -6157.470000\n",
      "25%         -26.790000\n",
      "50%           3.230000\n",
      "75%          59.410000\n",
      "max       13701.980000\n",
      "Name: heightAboveWgs84EllipsoidM, dtype: float64\n",
      "\n",
      "phone\n",
      "count                         131342\n",
      "unique                            73\n",
      "top       2021-04-22-US-SJC-1_Pixel4\n",
      "freq                            2890\n",
      "Name: phone, dtype: object\n",
      "\n",
      "utcTimeMillis_x\n",
      "       utcTimeMillis_x  utcTimeMillis_x  utcTimeMillis_x\n",
      "count     1.137980e+05     1.313420e+05     3.658900e+04\n",
      "mean      1.604680e+12     1.603878e+12     1.619017e+12\n",
      "std       1.209329e+10     1.162110e+10     1.172510e+09\n",
      "min       1.589494e+12     1.589494e+12     1.615418e+12\n",
      "25%       1.591379e+12     1.591389e+12     1.618523e+12\n",
      "50%       1.609798e+12     1.599243e+12     1.619641e+12\n",
      "75%       1.618523e+12     1.618522e+12     1.619723e+12\n",
      "max       1.619735e+12     1.619735e+12     1.619735e+12\n",
      "\n",
      "elapsedRealtimeNanos_x\n",
      "       elapsedRealtimeNanos_x  elapsedRealtimeNanos_x\n",
      "count            1.137980e+05            1.137980e+05\n",
      "mean             4.735094e+13            4.735094e+13\n",
      "std              1.075541e+14            1.075541e+14\n",
      "min              2.282485e+11            2.282544e+11\n",
      "25%              8.036286e+12            8.036287e+12\n",
      "50%              1.387414e+13            1.387414e+13\n",
      "75%              6.816902e+13            6.816902e+13\n",
      "max              6.041912e+14            6.041912e+14\n",
      "\n",
      "UncalGyroXRadPerSec\n",
      "count    113798.000000\n",
      "mean          0.000923\n",
      "std           0.084996\n",
      "min          -1.824679\n",
      "25%          -0.025551\n",
      "50%           0.000916\n",
      "75%           0.027488\n",
      "max           1.769790\n",
      "Name: UncalGyroXRadPerSec, dtype: float64\n",
      "\n",
      "UncalGyroYRadPerSec\n",
      "count    113798.000000\n",
      "mean         -0.001575\n",
      "std           0.092559\n",
      "min          -3.528166\n",
      "25%          -0.019481\n",
      "50%           0.000799\n",
      "75%           0.018816\n",
      "max           1.880860\n",
      "Name: UncalGyroYRadPerSec, dtype: float64\n",
      "\n",
      "UncalGyroZRadPerSec\n",
      "count    113798.000000\n",
      "mean          0.000977\n",
      "std           0.050096\n",
      "min          -2.436228\n",
      "25%          -0.011459\n",
      "50%           0.001222\n",
      "75%           0.014946\n",
      "max           2.277408\n",
      "Name: UncalGyroZRadPerSec, dtype: float64\n",
      "\n",
      "DriftXRadPerSec\n",
      "count    74725.000000\n",
      "mean         0.000195\n",
      "std          0.001996\n",
      "min         -0.004125\n",
      "25%         -0.000503\n",
      "50%          0.000009\n",
      "75%          0.000837\n",
      "max          0.009721\n",
      "Name: DriftXRadPerSec, dtype: float64\n",
      "\n",
      "DriftYRadPerSec\n",
      "count    74725.000000\n",
      "mean         0.002355\n",
      "std          0.004949\n",
      "min         -0.002094\n",
      "25%         -0.000251\n",
      "50%          0.000075\n",
      "75%          0.000577\n",
      "max          0.015419\n",
      "Name: DriftYRadPerSec, dtype: float64\n",
      "\n",
      "DriftZRadPerSec\n",
      "count    74725.000000\n",
      "mean         0.002363\n",
      "std          0.005364\n",
      "min         -0.005965\n",
      "25%         -0.001627\n",
      "50%          0.000601\n",
      "75%          0.004007\n",
      "max          0.014271\n",
      "Name: DriftZRadPerSec, dtype: float64\n",
      "\n",
      "utcTimeMillis_y\n",
      "       utcTimeMillis_y  utcTimeMillis_y  utcTimeMillis_y\n",
      "count     1.137980e+05     1.137980e+05     1.117910e+05\n",
      "mean      1.604680e+12     1.604680e+12     1.603703e+12\n",
      "std       1.209329e+10     1.209329e+10     1.186885e+10\n",
      "min       1.589494e+12     1.589494e+12     1.589494e+12\n",
      "25%       1.591379e+12     1.591379e+12     1.591379e+12\n",
      "50%       1.609798e+12     1.609798e+12     1.599244e+12\n",
      "75%       1.618523e+12     1.618523e+12     1.618522e+12\n",
      "max       1.619735e+12     1.619735e+12     1.619735e+12\n",
      "\n",
      "elapsedRealtimeNanos_y\n",
      "       elapsedRealtimeNanos_y  elapsedRealtimeNanos_y\n",
      "count            1.137980e+05            3.658900e+04\n",
      "mean             4.734853e+13            3.053199e+13\n",
      "std              1.075550e+14            2.743854e+13\n",
      "min              1.000000e+00            4.003852e+12\n",
      "25%              8.034477e+12            1.176684e+13\n",
      "50%              1.386814e+13            1.740758e+13\n",
      "75%              6.816902e+13            6.710127e+13\n",
      "max              6.041912e+14            8.309815e+13\n",
      "\n",
      "UncalMagXMicroT\n",
      "count    113780.000000\n",
      "mean         29.201133\n",
      "std          39.605883\n",
      "min        -116.700000\n",
      "25%           4.980000\n",
      "50%          28.740000\n",
      "75%          48.731492\n",
      "max         157.912500\n",
      "Name: UncalMagXMicroT, dtype: float64\n",
      "\n",
      "UncalMagYMicroT\n",
      "count    113780.000000\n",
      "mean        -52.356617\n",
      "std          37.173081\n",
      "min        -188.475000\n",
      "25%         -57.937500\n",
      "50%         -43.409250\n",
      "75%         -34.369005\n",
      "max         126.753975\n",
      "Name: UncalMagYMicroT, dtype: float64\n",
      "\n",
      "UncalMagZMicroT\n",
      "count    113762.000000\n",
      "mean          4.066886\n",
      "std          67.743703\n",
      "min        -218.495760\n",
      "25%         -24.240000\n",
      "50%           0.803906\n",
      "75%          20.510125\n",
      "max         260.025000\n",
      "Name: UncalMagZMicroT, dtype: float64\n",
      "\n",
      "BiasXMicroT\n",
      "count    74693.000000\n",
      "mean        16.093315\n",
      "std         42.486049\n",
      "min       -117.600000\n",
      "25%         -4.390179\n",
      "50%         13.256575\n",
      "75%         30.476776\n",
      "max        135.506530\n",
      "Name: BiasXMicroT, dtype: float64\n",
      "\n",
      "BiasYMicroT\n",
      "count    74693.000000\n",
      "mean       -14.527748\n",
      "std         55.477841\n",
      "min       -123.855360\n",
      "25%        -42.649117\n",
      "50%         -9.150366\n",
      "75%          3.924739\n",
      "max        202.620000\n",
      "Name: BiasYMicroT, dtype: float64\n",
      "\n",
      "BiasZMicroT\n",
      "count    74675.000000\n",
      "mean        15.456419\n",
      "std         80.564831\n",
      "min       -217.118040\n",
      "25%        -37.862960\n",
      "50%          2.663509\n",
      "75%         35.045803\n",
      "max        234.596240\n",
      "Name: BiasZMicroT, dtype: float64\n",
      "\n",
      "utcTimeMillis_x\n",
      "       utcTimeMillis_x  utcTimeMillis_x  utcTimeMillis_x\n",
      "count     1.137980e+05     1.313420e+05     3.658900e+04\n",
      "mean      1.604680e+12     1.603878e+12     1.619017e+12\n",
      "std       1.209329e+10     1.162110e+10     1.172510e+09\n",
      "min       1.589494e+12     1.589494e+12     1.615418e+12\n",
      "25%       1.591379e+12     1.591389e+12     1.618523e+12\n",
      "50%       1.609798e+12     1.599243e+12     1.619641e+12\n",
      "75%       1.618523e+12     1.618522e+12     1.619723e+12\n",
      "max       1.619735e+12     1.619735e+12     1.619735e+12\n",
      "\n",
      "TimeNanos\n",
      "count    1.313420e+05\n",
      "mean     1.871161e+14\n",
      "std      7.720866e+14\n",
      "min      4.993900e+10\n",
      "25%      2.326058e+12\n",
      "50%      1.078879e+13\n",
      "75%      3.760431e+13\n",
      "max      4.261706e+15\n",
      "Name: TimeNanos, dtype: float64\n",
      "\n",
      "LeapSecond\n",
      "count    45928.0\n",
      "mean        18.0\n",
      "std          0.0\n",
      "min         18.0\n",
      "25%         18.0\n",
      "50%         18.0\n",
      "75%         18.0\n",
      "max         18.0\n",
      "Name: LeapSecond, dtype: float64\n",
      "\n",
      "TimeUncertaintyNanos\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: TimeUncertaintyNanos, dtype: float64\n",
      "\n",
      "FullBiasNanos\n",
      "count    1.313420e+05\n",
      "mean    -1.287726e+18\n",
      "std      1.153714e+16\n",
      "min     -1.303769e+18\n",
      "25%     -1.299453e+18\n",
      "50%     -1.283273e+18\n",
      "75%     -1.275339e+18\n",
      "max     -1.273508e+18\n",
      "Name: FullBiasNanos, dtype: float64\n",
      "\n",
      "BiasNanos\n",
      "count    131342.000000\n",
      "mean         -0.034683\n",
      "std           0.509370\n",
      "min          -0.999985\n",
      "25%          -0.413013\n",
      "50%           0.000000\n",
      "75%           0.297781\n",
      "max           0.999979\n",
      "Name: BiasNanos, dtype: float64\n",
      "\n",
      "BiasUncertaintyNanos\n",
      "count    131342.000000\n",
      "mean        138.882081\n",
      "std         323.337851\n",
      "min           4.410778\n",
      "25%          14.575101\n",
      "50%          17.903321\n",
      "75%          24.439189\n",
      "max        1010.203618\n",
      "Name: BiasUncertaintyNanos, dtype: float64\n",
      "\n",
      "DriftNanosPerSecond\n",
      "count    117173.000000\n",
      "mean         45.715046\n",
      "std         139.770830\n",
      "min        -133.764974\n",
      "25%         -15.050240\n",
      "50%          -1.192627\n",
      "75%          16.070364\n",
      "max         445.000000\n",
      "Name: DriftNanosPerSecond, dtype: float64\n",
      "\n",
      "DriftUncertaintyNanosPerSecond\n",
      "count    117173.000000\n",
      "mean          9.264991\n",
      "std           3.707014\n",
      "min           0.743675\n",
      "25%           8.952852\n",
      "50%           9.697816\n",
      "75%          10.821678\n",
      "max          41.865084\n",
      "Name: DriftUncertaintyNanosPerSecond, dtype: float64\n",
      "\n",
      "HardwareClockDiscontinuityCount\n",
      "count    131342.000000\n",
      "mean        904.863547\n",
      "std        2067.940289\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           8.000000\n",
      "75%         932.000000\n",
      "max       12484.000000\n",
      "Name: HardwareClockDiscontinuityCount, dtype: float64\n",
      "\n",
      "Svid_x\n",
      "count    131342.000000\n",
      "mean         21.857091\n",
      "std          26.931186\n",
      "min           1.000000\n",
      "25%           9.000000\n",
      "50%          19.000000\n",
      "75%          27.000000\n",
      "max         195.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Svid_x, dtype: float64\n",
      "\n",
      "TimeOffsetNanos\n",
      "count    131342.0\n",
      "mean          0.0\n",
      "std           0.0\n",
      "min           0.0\n",
      "25%           0.0\n",
      "50%           0.0\n",
      "75%           0.0\n",
      "max           0.0\n",
      "Name: TimeOffsetNanos, dtype: float64\n",
      "\n",
      "State\n",
      "count    131342.000000\n",
      "mean      37819.338597\n",
      "std       27131.543312\n",
      "min           4.000000\n",
      "25%       16399.000000\n",
      "50%       23567.000000\n",
      "75%       49359.000000\n",
      "max       85034.000000\n",
      "Name: State, dtype: float64\n",
      "\n",
      "ReceivedSvTimeNanos\n",
      "count    1.313420e+05\n",
      "mean     3.121059e+14\n",
      "std      1.732955e+14\n",
      "min      1.328100e+04\n",
      "25%      1.667148e+14\n",
      "50%      4.112899e+14\n",
      "75%      4.270754e+14\n",
      "max      5.184634e+14\n",
      "Name: ReceivedSvTimeNanos, dtype: float64\n",
      "\n",
      "ReceivedSvTimeUncertaintyNanos\n",
      "count    1.313420e+05\n",
      "mean     5.091290e+07\n",
      "std      2.198207e+08\n",
      "min      2.000000e+00\n",
      "25%      7.000000e+00\n",
      "50%      1.200000e+01\n",
      "75%      2.100000e+01\n",
      "max      1.000000e+09\n",
      "Name: ReceivedSvTimeUncertaintyNanos, dtype: float64\n",
      "\n",
      "Cn0DbHz_x\n",
      "count    131342.000000\n",
      "mean         31.992947\n",
      "std           7.658805\n",
      "min           7.000000\n",
      "25%          27.300000\n",
      "50%          32.400000\n",
      "75%          37.100000\n",
      "max          56.600000\n",
      "Name: Cn0DbHz_x, dtype: float64\n",
      "\n",
      "PseudorangeRateMetersPerSecond\n",
      "count    131342.000000\n",
      "mean         26.339512\n",
      "std        3565.671982\n",
      "min     -524008.318948\n",
      "25%        -359.270341\n",
      "50%          22.610368\n",
      "75%         416.577360\n",
      "max      524170.529641\n",
      "Name: PseudorangeRateMetersPerSecond, dtype: float64\n",
      "\n",
      "PseudorangeRateUncertaintyMetersPerSecond\n",
      "count    1.313420e+05\n",
      "mean     1.525417e+07\n",
      "std      6.588192e+07\n",
      "min      9.465822e-04\n",
      "25%      3.740000e-02\n",
      "50%      6.120000e-02\n",
      "75%      3.065000e-01\n",
      "max      2.997925e+08\n",
      "Name: PseudorangeRateUncertaintyMetersPerSecond, dtype: float64\n",
      "\n",
      "AccumulatedDeltaRangeState\n",
      "count    131342.000000\n",
      "mean         20.949102\n",
      "std           6.050364\n",
      "min           1.000000\n",
      "25%          17.000000\n",
      "50%          21.000000\n",
      "75%          25.000000\n",
      "max          29.000000\n",
      "Name: AccumulatedDeltaRangeState, dtype: float64\n",
      "\n",
      "AccumulatedDeltaRangeMeters\n",
      "count    1.313420e+05\n",
      "mean    -5.972150e+03\n",
      "std      5.628474e+05\n",
      "min     -3.910771e+06\n",
      "25%     -7.343367e+04\n",
      "50%      0.000000e+00\n",
      "75%      6.822980e+04\n",
      "max      3.896353e+06\n",
      "Name: AccumulatedDeltaRangeMeters, dtype: float64\n",
      "\n",
      "AccumulatedDeltaRangeUncertaintyMeters\n",
      "count    1.313420e+05\n",
      "mean     3.680766e+37\n",
      "std      1.056895e+38\n",
      "min     -6.921125e+18\n",
      "25%      1.008556e-03\n",
      "50%      2.354611e-03\n",
      "75%      7.212130e-03\n",
      "max      3.402823e+38\n",
      "Name: AccumulatedDeltaRangeUncertaintyMeters, dtype: float64\n",
      "\n",
      "CarrierFrequencyHz_x\n",
      "count    1.313420e+05\n",
      "mean     1.484393e+09\n",
      "std      1.719319e+08\n",
      "min      1.176450e+09\n",
      "25%      1.561098e+09\n",
      "50%      1.575420e+09\n",
      "75%      1.575420e+09\n",
      "max      1.605375e+09\n",
      "Name: CarrierFrequencyHz_x, dtype: float64\n",
      "\n",
      "CarrierCycles\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: CarrierCycles, dtype: float64\n",
      "\n",
      "CarrierPhase\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: CarrierPhase, dtype: float64\n",
      "\n",
      "CarrierPhaseUncertainty\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: CarrierPhaseUncertainty, dtype: float64\n",
      "\n",
      "MultipathIndicator\n",
      "count    131342.00000\n",
      "mean          0.03133\n",
      "std           0.17421\n",
      "min           0.00000\n",
      "25%           0.00000\n",
      "50%           0.00000\n",
      "75%           0.00000\n",
      "max           1.00000\n",
      "Name: MultipathIndicator, dtype: float64\n",
      "\n",
      "SnrInDb\n",
      "count    0.0\n",
      "mean     NaN\n",
      "std      NaN\n",
      "min      NaN\n",
      "25%      NaN\n",
      "50%      NaN\n",
      "75%      NaN\n",
      "max      NaN\n",
      "Name: SnrInDb, dtype: float64\n",
      "\n",
      "ConstellationType_x\n",
      "count    131342.000000\n",
      "mean          3.337265\n",
      "std           2.166505\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           3.000000\n",
      "75%           6.000000\n",
      "max           6.000000\n",
      "Name: ConstellationType_x, dtype: float64\n",
      "\n",
      "AgcDb\n",
      "count    123464.000000\n",
      "mean         -1.916208\n",
      "std          29.264287\n",
      "min         -76.000000\n",
      "25%          -1.150000\n",
      "50%           0.380000\n",
      "75%           3.890000\n",
      "max          64.818840\n",
      "Name: AgcDb, dtype: float64\n",
      "\n",
      "BasebandCn0DbHz_x\n",
      "count    25995.000000\n",
      "mean        26.892116\n",
      "std          8.898908\n",
      "min          6.900000\n",
      "25%         21.437767\n",
      "50%         28.038876\n",
      "75%         33.668024\n",
      "max         46.022934\n",
      "Name: BasebandCn0DbHz_x, dtype: float64\n",
      "\n",
      "FullInterSignalBiasNanos\n",
      "count    25995.000000\n",
      "mean      -703.613103\n",
      "std       2609.491071\n",
      "min      -7876.281738\n",
      "25%         -6.829505\n",
      "50%          0.000000\n",
      "75%          2.379855\n",
      "max       3817.982422\n",
      "Name: FullInterSignalBiasNanos, dtype: float64\n",
      "\n",
      "FullInterSignalBiasUncertaintyNanos\n",
      "count    25995.000000\n",
      "mean         8.037853\n",
      "std        215.055299\n",
      "min          0.000000\n",
      "25%          1.000000\n",
      "50%          2.082444\n",
      "75%          6.126178\n",
      "max      20000.000000\n",
      "Name: FullInterSignalBiasUncertaintyNanos, dtype: float64\n",
      "\n",
      "SatelliteInterSignalBiasNanos\n",
      "count    14204.000000\n",
      "mean         5.548503\n",
      "std         10.726767\n",
      "min         -8.412334\n",
      "25%         -1.235865\n",
      "50%          0.000000\n",
      "75%         10.681106\n",
      "max         35.390258\n",
      "Name: SatelliteInterSignalBiasNanos, dtype: float64\n",
      "\n",
      "SatelliteInterSignalBiasUncertaintyNanos\n",
      "count    14204.000000\n",
      "mean         1.346381\n",
      "std          0.292879\n",
      "min          1.000000\n",
      "25%          1.000000\n",
      "50%          1.500000\n",
      "75%          1.500000\n",
      "max          2.000000\n",
      "Name: SatelliteInterSignalBiasUncertaintyNanos, dtype: float64\n",
      "\n",
      "CodeType\n",
      "count     83102\n",
      "unique        4\n",
      "top           C\n",
      "freq      53965\n",
      "Name: CodeType, dtype: object\n",
      "\n",
      "ChipsetElapsedRealtimeNanos\n",
      "count    4.861400e+04\n",
      "mean     3.429301e+13\n",
      "std      3.153181e+13\n",
      "min      6.236340e+12\n",
      "25%      1.136069e+13\n",
      "50%      1.715725e+13\n",
      "75%      7.316578e+13\n",
      "max      9.553389e+13\n",
      "Name: ChipsetElapsedRealtimeNanos, dtype: float64\n",
      "\n",
      "utcTimeMillis_y\n",
      "       utcTimeMillis_y  utcTimeMillis_y  utcTimeMillis_y\n",
      "count     1.137980e+05     1.137980e+05     1.117910e+05\n",
      "mean      1.604680e+12     1.604680e+12     1.603703e+12\n",
      "std       1.209329e+10     1.209329e+10     1.186885e+10\n",
      "min       1.589494e+12     1.589494e+12     1.589494e+12\n",
      "25%       1.591379e+12     1.591379e+12     1.591379e+12\n",
      "50%       1.609798e+12     1.609798e+12     1.599244e+12\n",
      "75%       1.618523e+12     1.618523e+12     1.618522e+12\n",
      "max       1.619735e+12     1.619735e+12     1.619735e+12\n",
      "\n",
      "elapsedRealtimeNanos_x\n",
      "       elapsedRealtimeNanos_x  elapsedRealtimeNanos_x\n",
      "count            1.137980e+05            1.137980e+05\n",
      "mean             4.735094e+13            4.735094e+13\n",
      "std              1.075541e+14            1.075541e+14\n",
      "min              2.282485e+11            2.282544e+11\n",
      "25%              8.036286e+12            8.036287e+12\n",
      "50%              1.387414e+13            1.387414e+13\n",
      "75%              6.816902e+13            6.816902e+13\n",
      "max              6.041912e+14            6.041912e+14\n",
      "\n",
      "UncalAccelXMps2\n",
      "count    113798.000000\n",
      "mean         -0.206611\n",
      "std           1.108711\n",
      "min         -19.929222\n",
      "25%          -0.705284\n",
      "50%          -0.244068\n",
      "75%           0.238684\n",
      "max           9.878537\n",
      "Name: UncalAccelXMps2, dtype: float64\n",
      "\n",
      "UncalAccelYMps2\n",
      "count    113798.000000\n",
      "mean          9.156857\n",
      "std           2.472644\n",
      "min          -5.511575\n",
      "25%           9.318250\n",
      "50%           9.737592\n",
      "75%          10.037734\n",
      "max          26.434612\n",
      "Name: UncalAccelYMps2, dtype: float64\n",
      "\n",
      "UncalAccelZMps2\n",
      "count    113798.000000\n",
      "mean         -0.208391\n",
      "std           2.750507\n",
      "min         -16.254417\n",
      "25%          -1.201197\n",
      "50%          -0.407976\n",
      "75%           0.822626\n",
      "max          14.864664\n",
      "Name: UncalAccelZMps2, dtype: float64\n",
      "\n",
      "BiasXMps2\n",
      "count    74725.0\n",
      "mean         0.0\n",
      "std          0.0\n",
      "min          0.0\n",
      "25%          0.0\n",
      "50%          0.0\n",
      "75%          0.0\n",
      "max          0.0\n",
      "Name: BiasXMps2, dtype: float64\n",
      "\n",
      "BiasYMps2\n",
      "count    74725.0\n",
      "mean         0.0\n",
      "std          0.0\n",
      "min          0.0\n",
      "25%          0.0\n",
      "50%          0.0\n",
      "75%          0.0\n",
      "max          0.0\n",
      "Name: BiasYMps2, dtype: float64\n",
      "\n",
      "BiasZMps2\n",
      "count    74725.000000\n",
      "mean        -0.000455\n",
      "std          0.000939\n",
      "min         -0.002394\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          0.000000\n",
      "Name: BiasZMps2, dtype: float64\n",
      "\n",
      "utcTimeMillis_x\n",
      "       utcTimeMillis_x  utcTimeMillis_x  utcTimeMillis_x\n",
      "count     1.137980e+05     1.313420e+05     3.658900e+04\n",
      "mean      1.604680e+12     1.603878e+12     1.619017e+12\n",
      "std       1.209329e+10     1.162110e+10     1.172510e+09\n",
      "min       1.589494e+12     1.589494e+12     1.615418e+12\n",
      "25%       1.591379e+12     1.591389e+12     1.618523e+12\n",
      "50%       1.609798e+12     1.599243e+12     1.619641e+12\n",
      "75%       1.618523e+12     1.618522e+12     1.619723e+12\n",
      "max       1.619735e+12     1.619735e+12     1.619735e+12\n",
      "\n",
      "elapsedRealtimeNanos_y\n",
      "       elapsedRealtimeNanos_y  elapsedRealtimeNanos_y\n",
      "count            1.137980e+05            3.658900e+04\n",
      "mean             4.734853e+13            3.053199e+13\n",
      "std              1.075550e+14            2.743854e+13\n",
      "min              1.000000e+00            4.003852e+12\n",
      "25%              8.034477e+12            1.176684e+13\n",
      "50%              1.386814e+13            1.740758e+13\n",
      "75%              6.816902e+13            6.710127e+13\n",
      "max              6.041912e+14            8.309815e+13\n",
      "\n",
      "yawDeg\n",
      "count    36589.000000\n",
      "mean       141.763891\n",
      "std         89.888553\n",
      "min          0.000000\n",
      "25%         73.000000\n",
      "50%        127.000000\n",
      "75%        180.000000\n",
      "max        359.000000\n",
      "Name: yawDeg, dtype: float64\n",
      "\n",
      "rollDeg\n",
      "count    36572.000000\n",
      "mean        44.125834\n",
      "std        152.973663\n",
      "min       -180.000000\n",
      "25%       -174.000000\n",
      "50%        146.000000\n",
      "75%        164.000000\n",
      "max        179.000000\n",
      "Name: rollDeg, dtype: float64\n",
      "\n",
      "pitchDeg\n",
      "count    36572.000000\n",
      "mean       -61.415017\n",
      "std         34.612914\n",
      "min        -89.000000\n",
      "25%        -84.000000\n",
      "50%        -81.000000\n",
      "75%        -45.000000\n",
      "max         21.000000\n",
      "Name: pitchDeg, dtype: float64\n",
      "\n",
      "timeSinceFirstFixSeconds\n",
      "count    131342.000000\n",
      "mean       1213.986316\n",
      "std         609.145524\n",
      "min          47.430000\n",
      "25%         718.430000\n",
      "50%        1174.430000\n",
      "75%        1659.440000\n",
      "max        3216.450000\n",
      "Name: timeSinceFirstFixSeconds, dtype: float64\n",
      "\n",
      "hDop\n",
      "count    131342.000000\n",
      "mean         10.146238\n",
      "std          56.707267\n",
      "min           0.000000\n",
      "25%           0.900000\n",
      "50%           1.300000\n",
      "75%           2.500000\n",
      "max         655.300000\n",
      "Name: hDop, dtype: float64\n",
      "\n",
      "vDop\n",
      "count    131342.0\n",
      "mean          0.0\n",
      "std           0.0\n",
      "min           0.0\n",
      "25%           0.0\n",
      "50%           0.0\n",
      "75%           0.0\n",
      "max           0.0\n",
      "Name: vDop, dtype: float64\n",
      "\n",
      "speedMps\n",
      "count    131342.000000\n",
      "mean         18.220691\n",
      "std          12.698756\n",
      "min           0.000000\n",
      "25%           5.260000\n",
      "50%          22.020000\n",
      "75%          29.310000\n",
      "max          45.010000\n",
      "Name: speedMps, dtype: float64\n",
      "\n",
      "courseDegree\n",
      "count    131342.000000\n",
      "mean        210.534792\n",
      "std         101.127548\n",
      "min           0.000000\n",
      "25%         129.000000\n",
      "50%         209.100000\n",
      "75%         309.600000\n",
      "max         360.000000\n",
      "Name: courseDegree, dtype: float64\n",
      "\n",
      "t_latDeg\n",
      "count    131342.000000\n",
      "mean         37.435201\n",
      "std           0.082713\n",
      "min          37.322839\n",
      "25%          37.371573\n",
      "50%          37.424355\n",
      "75%          37.469097\n",
      "max          37.690794\n",
      "Name: t_latDeg, dtype: float64\n",
      "\n",
      "t_lngDeg\n",
      "count    131342.000000\n",
      "mean       -122.154926\n",
      "std           0.145972\n",
      "min        -122.428838\n",
      "25%        -122.275114\n",
      "50%        -122.118312\n",
      "75%        -122.069092\n",
      "max        -121.881852\n",
      "Name: t_lngDeg, dtype: float64\n",
      "\n",
      "t_heightAboveWgs84EllipsoidM\n",
      "count    131342.000000\n",
      "mean         87.028847\n",
      "std          56.999876\n",
      "min          31.160000\n",
      "25%          37.160000\n",
      "50%          63.520000\n",
      "75%         122.330000\n",
      "max         247.850000\n",
      "Name: t_heightAboveWgs84EllipsoidM, dtype: float64\n",
      "\n",
      "utcTimeMillis_y\n",
      "       utcTimeMillis_y  utcTimeMillis_y  utcTimeMillis_y\n",
      "count     1.137980e+05     1.137980e+05     1.117910e+05\n",
      "mean      1.604680e+12     1.604680e+12     1.603703e+12\n",
      "std       1.209329e+10     1.209329e+10     1.186885e+10\n",
      "min       1.589494e+12     1.589494e+12     1.589494e+12\n",
      "25%       1.591379e+12     1.591379e+12     1.591379e+12\n",
      "50%       1.609798e+12     1.609798e+12     1.599244e+12\n",
      "75%       1.618523e+12     1.618523e+12     1.618522e+12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max       1.619735e+12     1.619735e+12     1.619735e+12\n",
      "\n",
      "SignalCount\n",
      "count    111791.000000\n",
      "mean         39.112460\n",
      "std           8.103215\n",
      "min           4.000000\n",
      "25%          33.000000\n",
      "50%          41.000000\n",
      "75%          45.000000\n",
      "max          56.000000\n",
      "Name: SignalCount, dtype: float64\n",
      "\n",
      "SignalIndex\n",
      "count    111791.000000\n",
      "mean         18.648827\n",
      "std          13.231969\n",
      "min           0.000000\n",
      "25%           8.000000\n",
      "50%          17.000000\n",
      "75%          28.000000\n",
      "max          55.000000\n",
      "Name: SignalIndex, dtype: float64\n",
      "\n",
      "ConstellationType_y\n",
      "count    111791.000000\n",
      "mean          3.385120\n",
      "std           2.159356\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           3.000000\n",
      "75%           6.000000\n",
      "max           6.000000\n",
      "Name: ConstellationType_y, dtype: float64\n",
      "\n",
      "Svid_y\n",
      "count    111791.000000\n",
      "mean         22.476604\n",
      "std          30.017578\n",
      "min           1.000000\n",
      "25%           8.000000\n",
      "50%          18.000000\n",
      "75%          27.000000\n",
      "max         195.000000\n",
      "Name: Svid_y, dtype: float64\n",
      "\n",
      "CarrierFrequencyHz_y\n",
      "count    1.116330e+05\n",
      "mean     1.480272e+09\n",
      "std      1.749200e+08\n",
      "min      1.176450e+09\n",
      "25%      1.561098e+09\n",
      "50%      1.575420e+09\n",
      "75%      1.575420e+09\n",
      "max      1.605375e+09\n",
      "Name: CarrierFrequencyHz_y, dtype: float64\n",
      "\n",
      "Cn0DbHz_y\n",
      "count    111791.000000\n",
      "mean         28.625575\n",
      "std          11.995357\n",
      "min           0.000000\n",
      "25%          24.050000\n",
      "50%          31.000000\n",
      "75%          36.400000\n",
      "max          55.800000\n",
      "Name: Cn0DbHz_y, dtype: float64\n",
      "\n",
      "AzimuthDegrees\n",
      "count    111791.000000\n",
      "mean        165.555903\n",
      "std         109.467490\n",
      "min           0.000000\n",
      "25%          59.000000\n",
      "50%         154.000000\n",
      "75%         274.000000\n",
      "max         359.000000\n",
      "Name: AzimuthDegrees, dtype: float64\n",
      "\n",
      "ElevationDegrees\n",
      "count    111791.000000\n",
      "mean         31.939190\n",
      "std          23.321118\n",
      "min           0.000000\n",
      "25%          11.000000\n",
      "50%          28.000000\n",
      "75%          51.000000\n",
      "max          89.000000\n",
      "Name: ElevationDegrees, dtype: float64\n",
      "\n",
      "UsedInFix\n",
      "count    111791.000000\n",
      "mean          0.619826\n",
      "std           0.485432\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max           1.000000\n",
      "Name: UsedInFix, dtype: float64\n",
      "\n",
      "HasAlmanacData\n",
      "count    111791.000000\n",
      "mean          0.976519\n",
      "std           0.151427\n",
      "min           0.000000\n",
      "25%           1.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max           1.000000\n",
      "Name: HasAlmanacData, dtype: float64\n",
      "\n",
      "HasEphemerisData\n",
      "count    111791.000000\n",
      "mean          0.620345\n",
      "std           0.485303\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           1.000000\n",
      "75%           1.000000\n",
      "max           1.000000\n",
      "Name: HasEphemerisData, dtype: float64\n",
      "\n",
      "BasebandCn0DbHz_y\n",
      "count    20262.000000\n",
      "mean        26.494277\n",
      "std         10.566247\n",
      "min          0.000000\n",
      "25%         21.722660\n",
      "50%         28.300000\n",
      "75%         34.126602\n",
      "max         46.211950\n",
      "Name: BasebandCn0DbHz_y, dtype: float64\n",
      "\n",
      "constellationType\n",
      "count    131342.000000\n",
      "mean          3.378744\n",
      "std           2.176913\n",
      "min           1.000000\n",
      "25%           1.000000\n",
      "50%           3.000000\n",
      "75%           6.000000\n",
      "max           6.000000\n",
      "Name: constellationType, dtype: float64\n",
      "\n",
      "svid\n",
      "count    131342.000000\n",
      "mean         17.188843\n",
      "std           9.761156\n",
      "min           1.000000\n",
      "25%           9.000000\n",
      "50%          17.000000\n",
      "75%          25.000000\n",
      "max          37.000000\n",
      "Name: svid, dtype: float64\n",
      "\n",
      "signalType\n",
      "count     131342\n",
      "unique         8\n",
      "top       GPS_L1\n",
      "freq       39906\n",
      "Name: signalType, dtype: object\n",
      "\n",
      "receivedSvTimeInGpsNanos\n",
      "count    1.313420e+05\n",
      "mean     1.287913e+18\n",
      "std      1.162110e+16\n",
      "min      1.273529e+18\n",
      "25%      1.275424e+18\n",
      "50%      1.283279e+18\n",
      "75%      1.302558e+18\n",
      "max      1.303771e+18\n",
      "Name: receivedSvTimeInGpsNanos, dtype: float64\n",
      "\n",
      "xSatPosM\n",
      "count    1.313420e+05\n",
      "mean    -8.429426e+06\n",
      "std      1.260199e+07\n",
      "min     -3.141789e+07\n",
      "25%     -1.805893e+07\n",
      "50%     -1.105838e+07\n",
      "75%      9.958046e+05\n",
      "max      2.314026e+07\n",
      "Name: xSatPosM, dtype: float64\n",
      "\n",
      "ySatPosM\n",
      "count    1.313420e+05\n",
      "mean    -1.240430e+07\n",
      "std      1.120919e+07\n",
      "min     -2.959319e+07\n",
      "25%     -2.090822e+07\n",
      "50%     -1.413953e+07\n",
      "75%     -6.013359e+06\n",
      "max      2.661825e+07\n",
      "Name: ySatPosM, dtype: float64\n",
      "\n",
      "zSatPosM\n",
      "count    1.313420e+05\n",
      "mean     1.258066e+07\n",
      "std      1.068349e+07\n",
      "min     -1.836208e+07\n",
      "25%      4.774167e+06\n",
      "50%      1.597202e+07\n",
      "75%      2.138985e+07\n",
      "max      3.513852e+07\n",
      "Name: zSatPosM, dtype: float64\n",
      "\n",
      "xSatVelMps\n",
      "count    131342.000000\n",
      "mean        557.524943\n",
      "std        1207.930715\n",
      "min       -3025.790000\n",
      "25%        -223.555750\n",
      "50%         408.957000\n",
      "75%        1467.172000\n",
      "max        3195.491000\n",
      "Name: xSatVelMps, dtype: float64\n",
      "\n",
      "ySatVelMps\n",
      "count    131342.000000\n",
      "mean       -330.371870\n",
      "std        1317.304775\n",
      "min       -3143.622000\n",
      "25%       -1323.738250\n",
      "50%        -258.714000\n",
      "75%         546.261250\n",
      "max        3124.382000\n",
      "Name: ySatVelMps, dtype: float64\n",
      "\n",
      "zSatVelMps\n",
      "count    131342.000000\n",
      "mean         37.523551\n",
      "std        2272.328628\n",
      "min       -3580.628000\n",
      "25%       -2253.343250\n",
      "50%          35.172000\n",
      "75%        2299.073000\n",
      "max        3617.957000\n",
      "Name: zSatVelMps, dtype: float64\n",
      "\n",
      "satClkBiasM\n",
      "count    1.313420e+05\n",
      "mean     1.061657e+05\n",
      "std      4.170421e+05\n",
      "min     -3.288018e+05\n",
      "25%     -6.885599e+04\n",
      "50%      1.668736e+03\n",
      "75%      7.918819e+04\n",
      "max      1.865378e+06\n",
      "Name: satClkBiasM, dtype: float64\n",
      "\n",
      "satClkDriftMps\n",
      "count    131342.000000\n",
      "mean          0.000092\n",
      "std           0.007456\n",
      "min          -0.014000\n",
      "25%          -0.002000\n",
      "50%          -0.000000\n",
      "75%           0.001000\n",
      "max           0.075000\n",
      "Name: satClkDriftMps, dtype: float64\n",
      "\n",
      "rawPrM\n",
      "count    1.313420e+05\n",
      "mean     2.361523e+07\n",
      "std      3.328288e+06\n",
      "min      1.907225e+07\n",
      "25%      2.180702e+07\n",
      "50%      2.337290e+07\n",
      "75%      2.458459e+07\n",
      "max      4.416339e+07\n",
      "Name: rawPrM, dtype: float64\n",
      "\n",
      "rawPrUncM\n",
      "count    131342.000000\n",
      "mean          4.881786\n",
      "std           4.913111\n",
      "min           0.600000\n",
      "25%           2.099000\n",
      "50%           3.298000\n",
      "75%           5.696000\n",
      "max         149.896000\n",
      "Name: rawPrUncM, dtype: float64\n",
      "\n",
      "isrbM\n",
      "count    131342.000000\n",
      "mean       -310.665604\n",
      "std        1056.395342\n",
      "min       -6085.269000\n",
      "25%        -228.997750\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max        9281.743000\n",
      "Name: isrbM, dtype: float64\n",
      "\n",
      "ionoDelayM\n",
      "count    131342.000000\n",
      "mean          5.713940\n",
      "std           2.862756\n",
      "min           0.000000\n",
      "25%           3.710000\n",
      "50%           4.895000\n",
      "75%           7.285000\n",
      "max          25.876000\n",
      "Name: ionoDelayM, dtype: float64\n",
      "\n",
      "tropoDelayM\n",
      "count    131342.000000\n",
      "mean          6.304804\n",
      "std           5.712669\n",
      "min           0.000000\n",
      "25%           3.029000\n",
      "50%           4.196500\n",
      "75%           7.109000\n",
      "max          47.439000\n",
      "Name: tropoDelayM, dtype: float64\n",
      "\n",
      "meter\n",
      "count    131342.000000\n",
      "mean          4.261468\n",
      "std          35.475422\n",
      "min           0.001579\n",
      "25%           1.335918\n",
      "50%           2.284470\n",
      "75%           3.944131\n",
      "max        9597.674736\n",
      "Name: meter, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in df_train.columns:\n",
    "    print(c)\n",
    "    print(df_train[c].describe())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:11.617260Z",
     "start_time": "2021-06-23T08:32:11.603262Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collectionName\n",
      "phoneName\n",
      "millisSinceGpsEpoch\n",
      "latDeg\n",
      "lngDeg\n",
      "heightAboveWgs84EllipsoidM\n",
      "phone\n",
      "utcTimeMillis_x\n",
      "elapsedRealtimeNanos_x\n",
      "UncalGyroXRadPerSec\n",
      "UncalGyroYRadPerSec\n",
      "UncalGyroZRadPerSec\n",
      "DriftXRadPerSec\n",
      "DriftYRadPerSec\n",
      "DriftZRadPerSec\n",
      "utcTimeMillis_y\n",
      "elapsedRealtimeNanos_y\n",
      "UncalMagXMicroT\n",
      "UncalMagYMicroT\n",
      "UncalMagZMicroT\n",
      "BiasXMicroT\n",
      "BiasYMicroT\n",
      "BiasZMicroT\n",
      "utcTimeMillis_x\n",
      "TimeNanos\n",
      "LeapSecond\n",
      "TimeUncertaintyNanos\n",
      "FullBiasNanos\n",
      "BiasNanos\n",
      "BiasUncertaintyNanos\n",
      "DriftNanosPerSecond\n",
      "DriftUncertaintyNanosPerSecond\n",
      "HardwareClockDiscontinuityCount\n",
      "Svid_x\n",
      "TimeOffsetNanos\n",
      "State\n",
      "ReceivedSvTimeNanos\n",
      "ReceivedSvTimeUncertaintyNanos\n",
      "Cn0DbHz_x\n",
      "PseudorangeRateMetersPerSecond\n",
      "PseudorangeRateUncertaintyMetersPerSecond\n",
      "AccumulatedDeltaRangeState\n",
      "AccumulatedDeltaRangeMeters\n",
      "AccumulatedDeltaRangeUncertaintyMeters\n",
      "CarrierFrequencyHz_x\n",
      "CarrierCycles\n",
      "CarrierPhase\n",
      "CarrierPhaseUncertainty\n",
      "MultipathIndicator\n",
      "SnrInDb\n",
      "ConstellationType_x\n",
      "AgcDb\n",
      "BasebandCn0DbHz_x\n",
      "FullInterSignalBiasNanos\n",
      "FullInterSignalBiasUncertaintyNanos\n",
      "SatelliteInterSignalBiasNanos\n",
      "SatelliteInterSignalBiasUncertaintyNanos\n",
      "CodeType\n",
      "ChipsetElapsedRealtimeNanos\n",
      "utcTimeMillis_y\n",
      "elapsedRealtimeNanos_x\n",
      "UncalAccelXMps2\n",
      "UncalAccelYMps2\n",
      "UncalAccelZMps2\n",
      "BiasXMps2\n",
      "BiasYMps2\n",
      "BiasZMps2\n",
      "utcTimeMillis_x\n",
      "elapsedRealtimeNanos_y\n",
      "yawDeg\n",
      "rollDeg\n",
      "pitchDeg\n",
      "timeSinceFirstFixSeconds\n",
      "hDop\n",
      "vDop\n",
      "speedMps\n",
      "courseDegree\n",
      "t_latDeg\n",
      "t_lngDeg\n",
      "t_heightAboveWgs84EllipsoidM\n",
      "utcTimeMillis_y\n",
      "SignalCount\n",
      "SignalIndex\n",
      "ConstellationType_y\n",
      "Svid_y\n",
      "CarrierFrequencyHz_y\n",
      "Cn0DbHz_y\n",
      "AzimuthDegrees\n",
      "ElevationDegrees\n",
      "UsedInFix\n",
      "HasAlmanacData\n",
      "HasEphemerisData\n",
      "BasebandCn0DbHz_y\n",
      "constellationType\n",
      "svid\n",
      "signalType\n",
      "receivedSvTimeInGpsNanos\n",
      "xSatPosM\n",
      "ySatPosM\n",
      "zSatPosM\n",
      "xSatVelMps\n",
      "ySatVelMps\n",
      "zSatVelMps\n",
      "satClkBiasM\n",
      "satClkDriftMps\n",
      "rawPrM\n",
      "rawPrUncM\n",
      "isrbM\n",
      "ionoDelayM\n",
      "tropoDelayM\n",
      "meter\n"
     ]
    }
   ],
   "source": [
    "for col in df_train.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:11.647772Z",
     "start_time": "2021-06-23T08:32:11.618260Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 131342 entries, 0 to 131341\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   latDeg                      131342 non-null  float64\n",
      " 1   lngDeg                      131342 non-null  float64\n",
      " 2   heightAboveWgs84EllipsoidM  131342 non-null  float64\n",
      " 3   xSatVelMps                  131342 non-null  float64\n",
      " 4   ySatVelMps                  131342 non-null  float64\n",
      " 5   zSatVelMps                  131342 non-null  float64\n",
      " 6   xSatPosM                    131342 non-null  float64\n",
      " 7   ySatPosM                    131342 non-null  float64\n",
      " 8   zSatPosM                    131342 non-null  float64\n",
      " 9   UncalGyroXRadPerSec         113798 non-null  float64\n",
      " 10  UncalGyroYRadPerSec         113798 non-null  float64\n",
      " 11  UncalGyroZRadPerSec         113798 non-null  float64\n",
      " 12  DriftXRadPerSec             74725 non-null   float64\n",
      " 13  DriftYRadPerSec             74725 non-null   float64\n",
      " 14  DriftZRadPerSec             74725 non-null   float64\n",
      " 15  UncalMagXMicroT             113780 non-null  float64\n",
      " 16  UncalMagYMicroT             113780 non-null  float64\n",
      " 17  UncalMagZMicroT             113762 non-null  float64\n",
      " 18  UncalAccelXMps2             113798 non-null  float64\n",
      " 19  UncalAccelYMps2             113798 non-null  float64\n",
      " 20  UncalAccelZMps2             113798 non-null  float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_train[['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM',\n",
    "             'xSatVelMps', 'ySatVelMps', 'zSatVelMps', \n",
    "             'xSatPosM', 'ySatPosM', 'zSatPosM',\n",
    "            'UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec',\n",
    "         'DriftXRadPerSec' , 'DriftYRadPerSec', 'DriftZRadPerSec',\n",
    "         'UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT',\n",
    "         'UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:11.797771Z",
     "start_time": "2021-06-23T08:32:11.648771Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = df_train.fillna(method = 'pad')\n",
    "df_train = df_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:12.007774Z",
     "start_time": "2021-06-23T08:32:11.798771Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "      <th>heightAboveWgs84EllipsoidM</th>\n",
       "      <th>xSatVelMps</th>\n",
       "      <th>ySatVelMps</th>\n",
       "      <th>zSatVelMps</th>\n",
       "      <th>xSatPosM</th>\n",
       "      <th>ySatPosM</th>\n",
       "      <th>zSatPosM</th>\n",
       "      <th>UncalGyroXRadPerSec</th>\n",
       "      <th>...</th>\n",
       "      <th>UncalGyroZRadPerSec</th>\n",
       "      <th>DriftXRadPerSec</th>\n",
       "      <th>DriftYRadPerSec</th>\n",
       "      <th>DriftZRadPerSec</th>\n",
       "      <th>UncalMagXMicroT</th>\n",
       "      <th>UncalMagYMicroT</th>\n",
       "      <th>UncalMagZMicroT</th>\n",
       "      <th>UncalAccelXMps2</th>\n",
       "      <th>UncalAccelYMps2</th>\n",
       "      <th>UncalAccelZMps2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>1.313420e+05</td>\n",
       "      <td>1.313420e+05</td>\n",
       "      <td>1.313420e+05</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "      <td>131342.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.435206</td>\n",
       "      <td>-122.154925</td>\n",
       "      <td>23.832922</td>\n",
       "      <td>557.524943</td>\n",
       "      <td>-330.371870</td>\n",
       "      <td>37.523551</td>\n",
       "      <td>-8.429426e+06</td>\n",
       "      <td>-1.240430e+07</td>\n",
       "      <td>1.258066e+07</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003519</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>30.100941</td>\n",
       "      <td>-49.640727</td>\n",
       "      <td>-14.971980</td>\n",
       "      <td>-0.152489</td>\n",
       "      <td>9.210476</td>\n",
       "      <td>-0.172470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.082712</td>\n",
       "      <td>0.145974</td>\n",
       "      <td>72.589312</td>\n",
       "      <td>1207.930715</td>\n",
       "      <td>1317.304775</td>\n",
       "      <td>2272.328628</td>\n",
       "      <td>1.260199e+07</td>\n",
       "      <td>1.120919e+07</td>\n",
       "      <td>1.068349e+07</td>\n",
       "      <td>0.080754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049145</td>\n",
       "      <td>0.001528</td>\n",
       "      <td>0.003905</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>38.442916</td>\n",
       "      <td>38.802910</td>\n",
       "      <td>91.740602</td>\n",
       "      <td>1.068431</td>\n",
       "      <td>2.313976</td>\n",
       "      <td>2.582447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.321683</td>\n",
       "      <td>-122.472214</td>\n",
       "      <td>-6157.470000</td>\n",
       "      <td>-3025.790000</td>\n",
       "      <td>-3143.622000</td>\n",
       "      <td>-3580.628000</td>\n",
       "      <td>-3.141789e+07</td>\n",
       "      <td>-2.959319e+07</td>\n",
       "      <td>-1.836208e+07</td>\n",
       "      <td>-1.824679</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.436228</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>-0.005965</td>\n",
       "      <td>-116.700000</td>\n",
       "      <td>-188.475000</td>\n",
       "      <td>-218.495760</td>\n",
       "      <td>-19.929222</td>\n",
       "      <td>-5.511575</td>\n",
       "      <td>-16.254417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37.371575</td>\n",
       "      <td>-122.275109</td>\n",
       "      <td>-26.790000</td>\n",
       "      <td>-223.555750</td>\n",
       "      <td>-1323.738250</td>\n",
       "      <td>-2253.343250</td>\n",
       "      <td>-1.805893e+07</td>\n",
       "      <td>-2.090822e+07</td>\n",
       "      <td>4.774167e+06</td>\n",
       "      <td>-0.020616</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018631</td>\n",
       "      <td>-0.000391</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>7.536778</td>\n",
       "      <td>-56.362500</td>\n",
       "      <td>-45.450000</td>\n",
       "      <td>-0.645714</td>\n",
       "      <td>9.351194</td>\n",
       "      <td>-1.127020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.424360</td>\n",
       "      <td>-122.118311</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>408.957000</td>\n",
       "      <td>-258.714000</td>\n",
       "      <td>35.172000</td>\n",
       "      <td>-1.105838e+07</td>\n",
       "      <td>-1.413953e+07</td>\n",
       "      <td>1.597202e+07</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.583504</td>\n",
       "      <td>-41.585327</td>\n",
       "      <td>-4.256250</td>\n",
       "      <td>-0.200438</td>\n",
       "      <td>9.701699</td>\n",
       "      <td>-0.271248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.469109</td>\n",
       "      <td>-122.069091</td>\n",
       "      <td>59.410000</td>\n",
       "      <td>1467.172000</td>\n",
       "      <td>546.261250</td>\n",
       "      <td>2299.073000</td>\n",
       "      <td>9.958046e+05</td>\n",
       "      <td>-6.013359e+06</td>\n",
       "      <td>2.138985e+07</td>\n",
       "      <td>0.025197</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013166</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>47.100000</td>\n",
       "      <td>-28.360832</td>\n",
       "      <td>18.494448</td>\n",
       "      <td>0.407807</td>\n",
       "      <td>9.984120</td>\n",
       "      <td>0.649944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>37.690836</td>\n",
       "      <td>-121.881855</td>\n",
       "      <td>13701.980000</td>\n",
       "      <td>3195.491000</td>\n",
       "      <td>3124.382000</td>\n",
       "      <td>3617.957000</td>\n",
       "      <td>2.314026e+07</td>\n",
       "      <td>2.661825e+07</td>\n",
       "      <td>3.513852e+07</td>\n",
       "      <td>1.769790</td>\n",
       "      <td>...</td>\n",
       "      <td>2.277408</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>0.015419</td>\n",
       "      <td>0.014271</td>\n",
       "      <td>157.912500</td>\n",
       "      <td>126.753975</td>\n",
       "      <td>260.025000</td>\n",
       "      <td>9.878537</td>\n",
       "      <td>26.434612</td>\n",
       "      <td>14.864664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              latDeg         lngDeg  heightAboveWgs84EllipsoidM  \\\n",
       "count  131342.000000  131342.000000               131342.000000   \n",
       "mean       37.435206    -122.154925                   23.832922   \n",
       "std         0.082712       0.145974                   72.589312   \n",
       "min        37.321683    -122.472214                -6157.470000   \n",
       "25%        37.371575    -122.275109                  -26.790000   \n",
       "50%        37.424360    -122.118311                    3.230000   \n",
       "75%        37.469109    -122.069091                   59.410000   \n",
       "max        37.690836    -121.881855                13701.980000   \n",
       "\n",
       "          xSatVelMps     ySatVelMps     zSatVelMps      xSatPosM  \\\n",
       "count  131342.000000  131342.000000  131342.000000  1.313420e+05   \n",
       "mean      557.524943    -330.371870      37.523551 -8.429426e+06   \n",
       "std      1207.930715    1317.304775    2272.328628  1.260199e+07   \n",
       "min     -3025.790000   -3143.622000   -3580.628000 -3.141789e+07   \n",
       "25%      -223.555750   -1323.738250   -2253.343250 -1.805893e+07   \n",
       "50%       408.957000    -258.714000      35.172000 -1.105838e+07   \n",
       "75%      1467.172000     546.261250    2299.073000  9.958046e+05   \n",
       "max      3195.491000    3124.382000    3617.957000  2.314026e+07   \n",
       "\n",
       "           ySatPosM      zSatPosM  UncalGyroXRadPerSec  ...  \\\n",
       "count  1.313420e+05  1.313420e+05        131342.000000  ...   \n",
       "mean  -1.240430e+07  1.258066e+07             0.000672  ...   \n",
       "std    1.120919e+07  1.068349e+07             0.080754  ...   \n",
       "min   -2.959319e+07 -1.836208e+07            -1.824679  ...   \n",
       "25%   -2.090822e+07  4.774167e+06            -0.020616  ...   \n",
       "50%   -1.413953e+07  1.597202e+07            -0.000484  ...   \n",
       "75%   -6.013359e+06  2.138985e+07             0.025197  ...   \n",
       "max    2.661825e+07  3.513852e+07             1.769790  ...   \n",
       "\n",
       "       UncalGyroZRadPerSec  DriftXRadPerSec  DriftYRadPerSec  DriftZRadPerSec  \\\n",
       "count        131342.000000    131342.000000    131342.000000    131342.000000   \n",
       "mean             -0.003519         0.000072         0.001559         0.001583   \n",
       "std               0.049145         0.001528         0.003905         0.004282   \n",
       "min              -2.436228        -0.004125        -0.002094        -0.005965   \n",
       "25%              -0.018631        -0.000391        -0.000044        -0.001070   \n",
       "50%              -0.000153         0.000000         0.000000         0.000000   \n",
       "75%               0.013166         0.000137         0.000479         0.002808   \n",
       "max               2.277408         0.009721         0.015419         0.014271   \n",
       "\n",
       "       UncalMagXMicroT  UncalMagYMicroT  UncalMagZMicroT  UncalAccelXMps2  \\\n",
       "count    131342.000000    131342.000000    131342.000000    131342.000000   \n",
       "mean         30.100941       -49.640727       -14.971980        -0.152489   \n",
       "std          38.442916        38.802910        91.740602         1.068431   \n",
       "min        -116.700000      -188.475000      -218.495760       -19.929222   \n",
       "25%           7.536778       -56.362500       -45.450000        -0.645714   \n",
       "50%          27.583504       -41.585327        -4.256250        -0.200438   \n",
       "75%          47.100000       -28.360832        18.494448         0.407807   \n",
       "max         157.912500       126.753975       260.025000         9.878537   \n",
       "\n",
       "       UncalAccelYMps2  UncalAccelZMps2  \n",
       "count    131342.000000    131342.000000  \n",
       "mean          9.210476        -0.172470  \n",
       "std           2.313976         2.582447  \n",
       "min          -5.511575       -16.254417  \n",
       "25%           9.351194        -1.127020  \n",
       "50%           9.701699        -0.271248  \n",
       "75%           9.984120         0.649944  \n",
       "max          26.434612        14.864664  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM',\n",
    "             'xSatVelMps', 'ySatVelMps', 'zSatVelMps', \n",
    "             'xSatPosM', 'ySatPosM', 'zSatPosM',\n",
    "            'UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec',\n",
    "         'DriftXRadPerSec' , 'DriftYRadPerSec', 'DriftZRadPerSec',\n",
    "         'UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT',\n",
    "         'UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:32:12.637772Z",
     "start_time": "2021-06-23T08:32:12.008772Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def data_slice_by_phone(df:pd.DataFrame, \n",
    "                        xCols = ['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM'], \n",
    "                        yCols = ['t_latDeg', 't_lngDeg', 't_heightAboveWgs84EllipsoidM', 'speedMps', 'courseDegree']):\n",
    "    indexCols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch']\n",
    "    \n",
    "    indx = []\n",
    "    data = []\n",
    "    true = []\n",
    "    for i, phone in enumerate(df['phone'].unique()):\n",
    "        temp = df[df['phone'] == phone]\n",
    "        indx.append(temp[indexCols])\n",
    "        data.append(temp[xCols])\n",
    "        true.append(temp[yCols])\n",
    "        \n",
    "    return indx, data, true\n",
    "\n",
    "def data_merge_by_index(df:pd.DataFrame, index:pd.DataFrame, src:pd.DataFrame, srcCols = ['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM']):\n",
    "    indexCols = ['collectionName', 'phoneName', 'millisSinceGpsEpoch']\n",
    "    output = df.copy()\n",
    "    \n",
    "    listFrame = []\n",
    "    for i in range(len(index)):\n",
    "        idxFrame = index[i]\n",
    "        srcFrame = src[i]\n",
    "        temp = pd.concat([idxFrame, srcFrame], axis = 1)\n",
    "        listFrame.append(temp)\n",
    "    \n",
    "    dataFrame = pd.concat(listFrame, axis = 0)\n",
    "    output = output.merge(dataFrame,\n",
    "              on=[\"collectionName\", \"phoneName\", \"millisSinceGpsEpoch\"])\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "features = ['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM',\n",
    "             'xSatVelMps', 'ySatVelMps', 'zSatVelMps', \n",
    "             'xSatPosM', 'ySatPosM', 'zSatPosM',\n",
    "            'UncalGyroXRadPerSec', 'UncalGyroYRadPerSec', 'UncalGyroZRadPerSec',\n",
    "         'DriftXRadPerSec' , 'DriftYRadPerSec', 'DriftZRadPerSec',\n",
    "         'UncalMagXMicroT', 'UncalMagYMicroT', 'UncalMagZMicroT',\n",
    "         'UncalAccelXMps2', 'UncalAccelYMps2', 'UncalAccelZMps2']\n",
    "labels = ['t_latDeg', 't_lngDeg', 't_heightAboveWgs84EllipsoidM', 'speedMps', 'courseDegree']\n",
    "\n",
    "idxFrame, dataFrame, trueFrame = data_slice_by_phone(df_train, xCols=features, yCols = labels)\n",
    "\n",
    "# data_merge_by_index(df_train[[\"collectionName\", \"phoneName\", \"millisSinceGpsEpoch\"]], idxFrame, dataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "slide window 기반은 때려치고, 데이터프레임에서 직접 읽어오는 방식으로 변경할 필요가 있음\n",
    "collectionName, phoneName기반으로 데이터를 잘라서 시계열 데이터처럼 쓸 예정 우선적으로 필요한 것은 lstm으로 돌려보기(baseline을 그렇게 하자!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:41:26.202502Z",
     "start_time": "2021-06-23T08:41:26.158503Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, input_features, output_features, kernel_size = 3):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.convK = nn.Conv1d(input_features, output_features, kernel_size = kernel_size, padding = kernel_size//2)\n",
    "        self.conv = nn.Conv1d(input_features, output_features, 1)\n",
    "        self.bn = nn.BatchNorm1d(output_features)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.convK(inputs)\n",
    "        inputs = self.conv(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        outputs = x + inputs\n",
    "        return outputs\n",
    "    \n",
    "class BigConv(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(input_size, 2*input_size)\n",
    "        self.conv2 = ConvBlock(2*input_size, 4*input_size)\n",
    "        self.conv3 = ConvBlock(4*input_size, 4*input_size)\n",
    "        self.conv4 = ConvBlock(4*input_size, 4*input_size)\n",
    "        self.conv5 = ConvBlock(4*input_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    \n",
    "class ConvolutionNetwork(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "#         self.conv = nn.Conv1d(input_size, output_size, 1)\n",
    "        self.conv1 = BigConv(input_size, 64)\n",
    "        self.conv2 = BigConv(64, 64)\n",
    "        self.conv3 = BigConv(64, 64)\n",
    "        self.conv4 = BigConv(64, output_size)\n",
    "        \n",
    "#         self.lstm = nn.LSTM(input_size = 512 + output_size, hidden_size = output_size, num_layers = 3, dropout = 0.3)\n",
    "    \n",
    "    def forward(self, x):\n",
    "#         x1 = self.conv(x)\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "#         x = torch.cat([x1, x], axis = 1)\n",
    "#         x, hidden = self.lstm(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = ConvolutionNetwork(len(features), len(labels))\n",
    "model.to(device)\n",
    "\n",
    "# loss_func = nn.SmoothL1Loss()\n",
    "loss_func = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "                                lr_lambda=lambda epoch: 0.995 ** epoch,\n",
    "                                last_epoch=-1,\n",
    "                                verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:42:37.512503Z",
     "start_time": "2021-06-23T08:42:37.498503Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataloader(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, true = None):\n",
    "        self.data = data\n",
    "        self.true = true\n",
    "        self.len = len(data)\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __shuffle__(self):\n",
    "        index = np.array(range(self.len), dtype = 'int')\n",
    "        index = np.random.permutation(index)\n",
    "        data = []\n",
    "        true = []\n",
    "        for i in range(self.len):\n",
    "            data.append(self.data[index[i]])\n",
    "            true.append(self.true[index[i]])\n",
    "            \n",
    "        self.data = data\n",
    "        self.true = true\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        if self.true is None:\n",
    "            true = []\n",
    "        else:\n",
    "            true = self.true[idx]\n",
    "            \n",
    "        data = torch.Tensor(np.expand_dims(np.array(data), 0)).transpose(2, 1)\n",
    "        true = torch.Tensor(np.expand_dims(np.array(true), 0)).transpose(2, 1)\n",
    "        \n",
    "        return data, true\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:43:48.677342Z",
     "start_time": "2021-06-23T08:43:48.663342Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(dataFrame, trueFrame, test_size = 1/10)\n",
    "\n",
    "loader_train = CustomDataloader(Xtrain, ytrain)\n",
    "loader_test = CustomDataloader(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:45:00.064867Z",
     "start_time": "2021-06-23T08:45:00.050868Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()  # 신경망을 학습 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 학습을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    \n",
    "    loader_train.__shuffle__()\n",
    "    \n",
    "    for data, targets in loader_train:\n",
    "        \n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()  # 경사를 0으로 초기화\n",
    "        outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "        loss = loss_func(outputs, targets)  # 출력과 훈련 데이터 정답 간의 오차를 계산\n",
    "        loss.backward()  # 오차를 역전파 계산\n",
    "        optimizer.step()  # 역전파 계산한 값으로 가중치를 수정\n",
    "        \n",
    "        predict.append(outputs.squeeze(dim = 0).transpose(1,0))\n",
    "        ground.append(targets.squeeze(dim = 0).transpose(1,0))\n",
    "    scheduler.step()\n",
    "\n",
    "    # 정확도 출력\n",
    "    predict = torch.cat(predict,axis = 0)\n",
    "    ground = torch.cat(ground,axis = 0)\n",
    "    \n",
    "    loss = loss_func(predict, ground)\n",
    "    meas = check_score_np(predict.to('cpu'), ground.to('cpu'))\n",
    "    return loss, meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:46:11.632348Z",
     "start_time": "2021-06-23T08:46:11.618348Z"
    }
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()  # 신경망을 추론 모드로 전환\n",
    "\n",
    "    # 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "    predict = []\n",
    "    ground = []\n",
    "    with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
    "        for data, targets in loader_test:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "            predict.append(outputs.squeeze(dim = 0).transpose(1,0))\n",
    "            ground.append(targets.squeeze(dim = 0).transpose(1,0))\n",
    "\n",
    "    # 정확도 출력\n",
    "    predict = torch.cat(predict,axis = 0)\n",
    "    ground = torch.cat(ground,axis = 0)\n",
    "    \n",
    "    loss = loss_func(predict, ground)\n",
    "    meas = check_score_np(predict.to('cpu'), ground.to('cpu'))\n",
    "    return loss, meas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:47:23.307923Z",
     "start_time": "2021-06-23T08:47:22.828921Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Sangwons_Room\\00_SoftWares\\Anaconda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "D:\\Sangwons_Room\\00_SoftWares\\Anaconda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in arcsin\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(40854880., device='cuda:0'), nan)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T09:57:57.618383Z",
     "start_time": "2021-06-23T08:48:34.442299Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Sangwons_Room\\00_SoftWares\\Anaconda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n",
      "D:\\Sangwons_Room\\00_SoftWares\\Anaconda\\envs\\torch\\lib\\site-packages\\ipykernel_launcher.py:7: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in arcsin\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*** EPOCH : 0/1000 ***/\n",
      "TRAIN - 0, 0\n",
      "TEST - 40854880.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9500e-04.\n",
      "/*** EPOCH : 1/1000 ***/\n",
      "TRAIN - 145160.84375, nan\n",
      "TEST - 6277.60107421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9003e-04.\n",
      "/*** EPOCH : 2/1000 ***/\n",
      "TRAIN - 4444.99755859375, nan\n",
      "TEST - 3813.122802734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8507e-04.\n",
      "/*** EPOCH : 3/1000 ***/\n",
      "TRAIN - 4027.653564453125, nan\n",
      "TEST - 3744.45654296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8015e-04.\n",
      "/*** EPOCH : 4/1000 ***/\n",
      "TRAIN - 3957.185791015625, nan\n",
      "TEST - 4173.123046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.7525e-04.\n",
      "/*** EPOCH : 5/1000 ***/\n",
      "TRAIN - 4031.67578125, nan\n",
      "TEST - 4911.06982421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.7037e-04.\n",
      "/*** EPOCH : 6/1000 ***/\n",
      "TRAIN - 3929.410888671875, nan\n",
      "TEST - 3427.116943359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.6552e-04.\n",
      "/*** EPOCH : 7/1000 ***/\n",
      "TRAIN - 3902.626708984375, nan\n",
      "TEST - 3904.32421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.6069e-04.\n",
      "/*** EPOCH : 8/1000 ***/\n",
      "TRAIN - 4016.85107421875, nan\n",
      "TEST - 3845.756591796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5589e-04.\n",
      "/*** EPOCH : 9/1000 ***/\n",
      "TRAIN - 3901.984130859375, nan\n",
      "TEST - 3740.0615234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5111e-04.\n",
      "/*** EPOCH : 10/1000 ***/\n",
      "TRAIN - 3914.6591796875, nan\n",
      "TEST - 3921.696044921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.4635e-04.\n",
      "/*** EPOCH : 11/1000 ***/\n",
      "TRAIN - 3863.1953125, nan\n",
      "TEST - 3781.041259765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.4162e-04.\n",
      "/*** EPOCH : 12/1000 ***/\n",
      "TRAIN - 3770.372314453125, nan\n",
      "TEST - 3178.92333984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3691e-04.\n",
      "/*** EPOCH : 13/1000 ***/\n",
      "TRAIN - 3668.961669921875, nan\n",
      "TEST - 3614.3515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3223e-04.\n",
      "/*** EPOCH : 14/1000 ***/\n",
      "TRAIN - 4088.67333984375, nan\n",
      "TEST - 4026.9638671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.2757e-04.\n",
      "/*** EPOCH : 15/1000 ***/\n",
      "TRAIN - 3684.085205078125, nan\n",
      "TEST - 3329.0712890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.2293e-04.\n",
      "/*** EPOCH : 16/1000 ***/\n",
      "TRAIN - 3899.68115234375, nan\n",
      "TEST - 3426.300048828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.1832e-04.\n",
      "/*** EPOCH : 17/1000 ***/\n",
      "TRAIN - 3797.56396484375, nan\n",
      "TEST - 3321.258544921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.1372e-04.\n",
      "/*** EPOCH : 18/1000 ***/\n",
      "TRAIN - 3657.083251953125, nan\n",
      "TEST - 3275.304443359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0916e-04.\n",
      "/*** EPOCH : 19/1000 ***/\n",
      "TRAIN - 3484.53125, nan\n",
      "TEST - 3016.76611328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0461e-04.\n",
      "/*** EPOCH : 20/1000 ***/\n",
      "TRAIN - 3440.104248046875, nan\n",
      "TEST - 3012.662353515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0009e-04.\n",
      "/*** EPOCH : 21/1000 ***/\n",
      "TRAIN - 3459.729248046875, nan\n",
      "TEST - 3140.086669921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.9559e-04.\n",
      "/*** EPOCH : 22/1000 ***/\n",
      "TRAIN - 3608.748046875, nan\n",
      "TEST - 3865.7216796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.9111e-04.\n",
      "/*** EPOCH : 23/1000 ***/\n",
      "TRAIN - 3496.07373046875, nan\n",
      "TEST - 3310.180419921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.8665e-04.\n",
      "/*** EPOCH : 24/1000 ***/\n",
      "TRAIN - 3747.932373046875, nan\n",
      "TEST - 3568.867919921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.8222e-04.\n",
      "/*** EPOCH : 25/1000 ***/\n",
      "TRAIN - 3489.030029296875, nan\n",
      "TEST - 3153.22021484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7781e-04.\n",
      "/*** EPOCH : 26/1000 ***/\n",
      "TRAIN - 3428.564697265625, nan\n",
      "TEST - 3000.140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7342e-04.\n",
      "/*** EPOCH : 27/1000 ***/\n",
      "TRAIN - 3381.256103515625, nan\n",
      "TEST - 3008.464111328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.6905e-04.\n",
      "/*** EPOCH : 28/1000 ***/\n",
      "TRAIN - 3820.66357421875, nan\n",
      "TEST - 3826.091064453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.6471e-04.\n",
      "/*** EPOCH : 29/1000 ***/\n",
      "TRAIN - 3293.433837890625, nan\n",
      "TEST - 2728.748046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.6038e-04.\n",
      "/*** EPOCH : 30/1000 ***/\n",
      "TRAIN - 3498.069580078125, nan\n",
      "TEST - 2795.643798828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5608e-04.\n",
      "/*** EPOCH : 31/1000 ***/\n",
      "TRAIN - 3212.42236328125, nan\n",
      "TEST - 2733.220947265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5180e-04.\n",
      "/*** EPOCH : 32/1000 ***/\n",
      "TRAIN - 3272.443359375, nan\n",
      "TEST - 2873.53955078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4754e-04.\n",
      "/*** EPOCH : 33/1000 ***/\n",
      "TRAIN - 3207.331787109375, nan\n",
      "TEST - 2693.81591796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4331e-04.\n",
      "/*** EPOCH : 34/1000 ***/\n",
      "TRAIN - 3165.080322265625, nan\n",
      "TEST - 2615.91015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.3909e-04.\n",
      "/*** EPOCH : 35/1000 ***/\n",
      "TRAIN - 2984.0556640625, nan\n",
      "TEST - 2592.717041015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.3489e-04.\n",
      "/*** EPOCH : 36/1000 ***/\n",
      "TRAIN - 3240.64990234375, nan\n",
      "TEST - 3001.085693359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.3072e-04.\n",
      "/*** EPOCH : 37/1000 ***/\n",
      "TRAIN - 3371.6455078125, nan\n",
      "TEST - 3226.254638671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.2657e-04.\n",
      "/*** EPOCH : 38/1000 ***/\n",
      "TRAIN - 3208.5625, nan\n",
      "TEST - 2901.961181640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.2243e-04.\n",
      "/*** EPOCH : 39/1000 ***/\n",
      "TRAIN - 3251.605224609375, nan\n",
      "TEST - 2497.547119140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1832e-04.\n",
      "/*** EPOCH : 40/1000 ***/\n",
      "TRAIN - 2959.033447265625, nan\n",
      "TEST - 2767.906982421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1423e-04.\n",
      "/*** EPOCH : 41/1000 ***/\n",
      "TRAIN - 3081.370849609375, nan\n",
      "TEST - 2534.795166015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1016e-04.\n",
      "/*** EPOCH : 42/1000 ***/\n",
      "TRAIN - 3024.457275390625, nan\n",
      "TEST - 2551.96142578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.0611e-04.\n",
      "/*** EPOCH : 43/1000 ***/\n",
      "TRAIN - 3261.082275390625, nan\n",
      "TEST - 2568.65087890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.0208e-04.\n",
      "/*** EPOCH : 44/1000 ***/\n",
      "TRAIN - 3179.466552734375, nan\n",
      "TEST - 2588.199462890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9807e-04.\n",
      "/*** EPOCH : 45/1000 ***/\n",
      "TRAIN - 3033.874755859375, nan\n",
      "TEST - 2495.895263671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9408e-04.\n",
      "/*** EPOCH : 46/1000 ***/\n",
      "TRAIN - 3114.629150390625, nan\n",
      "TEST - 2625.205322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9010e-04.\n",
      "/*** EPOCH : 47/1000 ***/\n",
      "TRAIN - 3390.505126953125, nan\n",
      "TEST - 2558.15966796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8615e-04.\n",
      "/*** EPOCH : 48/1000 ***/\n",
      "TRAIN - 3060.049072265625, nan\n",
      "TEST - 2682.58984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8222e-04.\n",
      "\n",
      "/***CHECK_POINT***/ \n",
      "TRAIN - 3245.411376953125, nan\n",
      "TEST - 2443.143310546875, 413724.1999886428\n",
      "\n",
      "/*** EPOCH : 49/1000 ***/\n",
      "TRAIN - 3245.411376953125, nan\n",
      "TEST - 2443.143310546875, 413724.1999886428\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7831e-04.\n",
      "/*** EPOCH : 50/1000 ***/\n",
      "TRAIN - 3539.6982421875, nan\n",
      "TEST - 2630.43212890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7442e-04.\n",
      "/*** EPOCH : 51/1000 ***/\n",
      "TRAIN - 3735.60400390625, nan\n",
      "TEST - 2798.927734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7055e-04.\n",
      "/*** EPOCH : 52/1000 ***/\n",
      "TRAIN - 3293.72607421875, nan\n",
      "TEST - 2876.31591796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6670e-04.\n",
      "/*** EPOCH : 53/1000 ***/\n",
      "TRAIN - 3062.273681640625, nan\n",
      "TEST - 2461.537841796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6286e-04.\n",
      "/*** EPOCH : 54/1000 ***/\n",
      "TRAIN - 3330.198974609375, nan\n",
      "TEST - 2518.327880859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.5905e-04.\n",
      "/*** EPOCH : 55/1000 ***/\n",
      "TRAIN - 3043.618896484375, nan\n",
      "TEST - 2744.344970703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.5525e-04.\n",
      "/*** EPOCH : 56/1000 ***/\n",
      "TRAIN - 3247.6162109375, nan\n",
      "TEST - 2445.494873046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.5148e-04.\n",
      "\n",
      "/***CHECK_POINT***/ \n",
      "TRAIN - 3054.4169921875, nan\n",
      "TEST - 2422.430908203125, 283713.45449485356\n",
      "\n",
      "/*** EPOCH : 57/1000 ***/\n",
      "TRAIN - 3054.4169921875, nan\n",
      "TEST - 2422.430908203125, 283713.45449485356\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4772e-04.\n",
      "/*** EPOCH : 58/1000 ***/\n",
      "TRAIN - 3077.001220703125, nan\n",
      "TEST - 2387.576416015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4398e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/***CHECK_POINT***/ \n",
      "TRAIN - 3237.6044921875, nan\n",
      "TEST - 2353.62451171875, 180479.71022667608\n",
      "\n",
      "/*** EPOCH : 59/1000 ***/\n",
      "TRAIN - 3237.6044921875, nan\n",
      "TEST - 2353.62451171875, 180479.71022667608\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4026e-04.\n",
      "/*** EPOCH : 60/1000 ***/\n",
      "TRAIN - 3011.052734375, nan\n",
      "TEST - 2419.918212890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3656e-04.\n",
      "/*** EPOCH : 61/1000 ***/\n",
      "TRAIN - 3096.487548828125, nan\n",
      "TEST - 2510.812744140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3288e-04.\n",
      "/*** EPOCH : 62/1000 ***/\n",
      "TRAIN - 3002.263427734375, nan\n",
      "TEST - 2656.12646484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.2921e-04.\n",
      "/*** EPOCH : 63/1000 ***/\n",
      "TRAIN - 3065.523681640625, nan\n",
      "TEST - 2499.677001953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.2557e-04.\n",
      "/*** EPOCH : 64/1000 ***/\n",
      "TRAIN - 2940.9638671875, nan\n",
      "TEST - 2394.292724609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.2194e-04.\n",
      "/*** EPOCH : 65/1000 ***/\n",
      "TRAIN - 3143.029052734375, nan\n",
      "TEST - 2752.81640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1833e-04.\n",
      "/*** EPOCH : 66/1000 ***/\n",
      "TRAIN - 3220.66552734375, nan\n",
      "TEST - 2489.64501953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1474e-04.\n",
      "/*** EPOCH : 67/1000 ***/\n",
      "TRAIN - 3091.911865234375, nan\n",
      "TEST - 2440.662353515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1116e-04.\n",
      "/*** EPOCH : 68/1000 ***/\n",
      "TRAIN - 3241.305908203125, nan\n",
      "TEST - 2502.298828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0761e-04.\n",
      "/*** EPOCH : 69/1000 ***/\n",
      "TRAIN - 2978.12841796875, nan\n",
      "TEST - 2390.354736328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0407e-04.\n",
      "/*** EPOCH : 70/1000 ***/\n",
      "TRAIN - 2869.876708984375, nan\n",
      "TEST - 2378.2822265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0055e-04.\n",
      "/*** EPOCH : 71/1000 ***/\n",
      "TRAIN - 2987.83251953125, nan\n",
      "TEST - 2475.782958984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9705e-04.\n",
      "/*** EPOCH : 72/1000 ***/\n",
      "TRAIN - 2952.36474609375, nan\n",
      "TEST - 2450.9677734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9356e-04.\n",
      "/*** EPOCH : 73/1000 ***/\n",
      "TRAIN - 2878.497314453125, nan\n",
      "TEST - 2472.384765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9009e-04.\n",
      "/*** EPOCH : 74/1000 ***/\n",
      "TRAIN - 2921.792236328125, nan\n",
      "TEST - 2438.601806640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.8664e-04.\n",
      "/*** EPOCH : 75/1000 ***/\n",
      "TRAIN - 2873.317626953125, nan\n",
      "TEST - 2521.01025390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.8321e-04.\n",
      "/*** EPOCH : 76/1000 ***/\n",
      "TRAIN - 2850.50390625, nan\n",
      "TEST - 2396.346923828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7979e-04.\n",
      "/*** EPOCH : 77/1000 ***/\n",
      "TRAIN - 2780.579833984375, nan\n",
      "TEST - 2376.748779296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7639e-04.\n",
      "/*** EPOCH : 78/1000 ***/\n",
      "TRAIN - 2783.842529296875, nan\n",
      "TEST - 2442.00244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7301e-04.\n",
      "/*** EPOCH : 79/1000 ***/\n",
      "TRAIN - 2958.49609375, nan\n",
      "TEST - 2355.942626953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6965e-04.\n",
      "/*** EPOCH : 80/1000 ***/\n",
      "TRAIN - 2946.0498046875, nan\n",
      "TEST - 2456.215087890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6630e-04.\n",
      "/*** EPOCH : 81/1000 ***/\n",
      "TRAIN - 2833.418701171875, nan\n",
      "TEST - 2422.031982421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6297e-04.\n",
      "/*** EPOCH : 82/1000 ***/\n",
      "TRAIN - 2809.693603515625, nan\n",
      "TEST - 2454.989990234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5965e-04.\n",
      "/*** EPOCH : 83/1000 ***/\n",
      "TRAIN - 2772.081787109375, nan\n",
      "TEST - 2423.63232421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5635e-04.\n",
      "/*** EPOCH : 84/1000 ***/\n",
      "TRAIN - 2844.060302734375, nan\n",
      "TEST - 2488.865478515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5307e-04.\n",
      "/*** EPOCH : 85/1000 ***/\n",
      "TRAIN - 2758.4033203125, nan\n",
      "TEST - 2426.418701171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.4981e-04.\n",
      "/*** EPOCH : 86/1000 ***/\n",
      "TRAIN - 2767.3046875, nan\n",
      "TEST - 2486.191162109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.4656e-04.\n",
      "/*** EPOCH : 87/1000 ***/\n",
      "TRAIN - 2729.240478515625, nan\n",
      "TEST - 2441.22607421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.4333e-04.\n",
      "/*** EPOCH : 88/1000 ***/\n",
      "TRAIN - 2813.0517578125, nan\n",
      "TEST - 2458.067138671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.4011e-04.\n",
      "/*** EPOCH : 89/1000 ***/\n",
      "TRAIN - 2745.87060546875, nan\n",
      "TEST - 2446.278076171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3691e-04.\n",
      "/*** EPOCH : 90/1000 ***/\n",
      "TRAIN - 2770.9638671875, nan\n",
      "TEST - 2449.75390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3372e-04.\n",
      "/*** EPOCH : 91/1000 ***/\n",
      "TRAIN - 2726.75634765625, nan\n",
      "TEST - 2430.648681640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3056e-04.\n",
      "/*** EPOCH : 92/1000 ***/\n",
      "TRAIN - 2854.41064453125, nan\n",
      "TEST - 2525.58984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2740e-04.\n",
      "/*** EPOCH : 93/1000 ***/\n",
      "TRAIN - 2839.067626953125, nan\n",
      "TEST - 2440.52392578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2427e-04.\n",
      "/*** EPOCH : 94/1000 ***/\n",
      "TRAIN - 2760.031494140625, nan\n",
      "TEST - 2485.14697265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2114e-04.\n",
      "/*** EPOCH : 95/1000 ***/\n",
      "TRAIN - 2758.701904296875, nan\n",
      "TEST - 2376.78369140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.1804e-04.\n",
      "/*** EPOCH : 96/1000 ***/\n",
      "TRAIN - 2728.831298828125, nan\n",
      "TEST - 2473.633544921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.1495e-04.\n",
      "/*** EPOCH : 97/1000 ***/\n",
      "TRAIN - 2745.44580078125, nan\n",
      "TEST - 2445.48486328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.1187e-04.\n",
      "/*** EPOCH : 98/1000 ***/\n",
      "TRAIN - 2744.62353515625, nan\n",
      "TEST - 2464.746337890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0881e-04.\n",
      "/*** EPOCH : 99/1000 ***/\n",
      "TRAIN - 2766.00634765625, nan\n",
      "TEST - 2441.46728515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0577e-04.\n",
      "/*** EPOCH : 100/1000 ***/\n",
      "TRAIN - 2747.901123046875, nan\n",
      "TEST - 2600.611328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0274e-04.\n",
      "/*** EPOCH : 101/1000 ***/\n",
      "TRAIN - 2813.16162109375, nan\n",
      "TEST - 2823.6337890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9973e-04.\n",
      "/*** EPOCH : 102/1000 ***/\n",
      "TRAIN - 36246200320.0, nan\n",
      "TEST - 99033792512.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9673e-04.\n",
      "/*** EPOCH : 103/1000 ***/\n",
      "TRAIN - 23568869376.0, nan\n",
      "TEST - 431104320.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9375e-04.\n",
      "/*** EPOCH : 104/1000 ***/\n",
      "TRAIN - 34591924.0, nan\n",
      "TEST - 2281280.5, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9078e-04.\n",
      "/*** EPOCH : 105/1000 ***/\n",
      "TRAIN - 1257233.375, nan\n",
      "TEST - 863891.0625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8782e-04.\n",
      "/*** EPOCH : 106/1000 ***/\n",
      "TRAIN - 669064.375, nan\n",
      "TEST - 565574.6875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8488e-04.\n",
      "/*** EPOCH : 107/1000 ***/\n",
      "TRAIN - 456933.5625, nan\n",
      "TEST - 412284.25, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8196e-04.\n",
      "/*** EPOCH : 108/1000 ***/\n",
      "TRAIN - 344583.71875, nan\n",
      "TEST - 320935.21875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7905e-04.\n",
      "/*** EPOCH : 109/1000 ***/\n",
      "TRAIN - 274117.65625, nan\n",
      "TEST - 259473.375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7615e-04.\n",
      "/*** EPOCH : 110/1000 ***/\n",
      "TRAIN - 227413.15625, nan\n",
      "TEST - 215625.140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7327e-04.\n",
      "/*** EPOCH : 111/1000 ***/\n",
      "TRAIN - 193950.1875, nan\n",
      "TEST - 185082.828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7041e-04.\n",
      "/*** EPOCH : 112/1000 ***/\n",
      "TRAIN - 169611.984375, nan\n",
      "TEST - 161208.265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6756e-04.\n",
      "/*** EPOCH : 113/1000 ***/\n",
      "TRAIN - 150972.5625, nan\n",
      "TEST - 143433.078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6472e-04.\n",
      "/*** EPOCH : 114/1000 ***/\n",
      "TRAIN - 136950.34375, nan\n",
      "TEST - 129994.7734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6189e-04.\n",
      "/*** EPOCH : 115/1000 ***/\n",
      "TRAIN - 125985.15625, nan\n",
      "TEST - 119803.4375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5908e-04.\n",
      "/*** EPOCH : 116/1000 ***/\n",
      "TRAIN - 117020.703125, nan\n",
      "TEST - 111396.109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5629e-04.\n",
      "/*** EPOCH : 117/1000 ***/\n",
      "TRAIN - 109906.828125, nan\n",
      "TEST - 105061.109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5351e-04.\n",
      "/*** EPOCH : 118/1000 ***/\n",
      "TRAIN - 104009.1171875, nan\n",
      "TEST - 99546.1484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5074e-04.\n",
      "/*** EPOCH : 119/1000 ***/\n",
      "TRAIN - 99138.9765625, nan\n",
      "TEST - 95206.7734375, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 5.4799e-04.\n",
      "/*** EPOCH : 120/1000 ***/\n",
      "TRAIN - 94842.8984375, nan\n",
      "TEST - 91384.28125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4525e-04.\n",
      "/*** EPOCH : 121/1000 ***/\n",
      "TRAIN - 91371.09375, nan\n",
      "TEST - 88396.1796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4252e-04.\n",
      "/*** EPOCH : 122/1000 ***/\n",
      "TRAIN - 87905.3671875, nan\n",
      "TEST - 85545.0234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3981e-04.\n",
      "/*** EPOCH : 123/1000 ***/\n",
      "TRAIN - 85076.078125, nan\n",
      "TEST - 83306.453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3711e-04.\n",
      "/*** EPOCH : 124/1000 ***/\n",
      "TRAIN - 82230.6875, nan\n",
      "TEST - 80428.640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3442e-04.\n",
      "/*** EPOCH : 125/1000 ***/\n",
      "TRAIN - 79638.265625, nan\n",
      "TEST - 78216.765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3175e-04.\n",
      "/*** EPOCH : 126/1000 ***/\n",
      "TRAIN - 77326.3046875, nan\n",
      "TEST - 76262.859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2909e-04.\n",
      "/*** EPOCH : 127/1000 ***/\n",
      "TRAIN - 75057.2421875, nan\n",
      "TEST - 74279.6953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2645e-04.\n",
      "/*** EPOCH : 128/1000 ***/\n",
      "TRAIN - 72858.5625, nan\n",
      "TEST - 72412.671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2381e-04.\n",
      "/*** EPOCH : 129/1000 ***/\n",
      "TRAIN - 70695.90625, nan\n",
      "TEST - 70700.8515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2120e-04.\n",
      "/*** EPOCH : 130/1000 ***/\n",
      "TRAIN - 68869.8125, nan\n",
      "TEST - 68783.3359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1859e-04.\n",
      "/*** EPOCH : 131/1000 ***/\n",
      "TRAIN - 66857.8671875, nan\n",
      "TEST - 67146.5078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1600e-04.\n",
      "/*** EPOCH : 132/1000 ***/\n",
      "TRAIN - 64870.046875, nan\n",
      "TEST - 65205.046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1342e-04.\n",
      "/*** EPOCH : 133/1000 ***/\n",
      "TRAIN - 62954.84375, nan\n",
      "TEST - 63537.515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1085e-04.\n",
      "/*** EPOCH : 134/1000 ***/\n",
      "TRAIN - 61198.609375, nan\n",
      "TEST - 62068.140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0830e-04.\n",
      "/*** EPOCH : 135/1000 ***/\n",
      "TRAIN - 59529.53125, nan\n",
      "TEST - 60615.9765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0575e-04.\n",
      "/*** EPOCH : 136/1000 ***/\n",
      "TRAIN - 57752.9453125, nan\n",
      "TEST - 58958.953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0322e-04.\n",
      "/*** EPOCH : 137/1000 ***/\n",
      "TRAIN - 56127.25, nan\n",
      "TEST - 57491.53515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0071e-04.\n",
      "/*** EPOCH : 138/1000 ***/\n",
      "TRAIN - 54551.30859375, nan\n",
      "TEST - 55923.8125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9821e-04.\n",
      "/*** EPOCH : 139/1000 ***/\n",
      "TRAIN - 52785.7265625, nan\n",
      "TEST - 54336.44140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9571e-04.\n",
      "/*** EPOCH : 140/1000 ***/\n",
      "TRAIN - 51396.8984375, nan\n",
      "TEST - 53339.4140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9324e-04.\n",
      "/*** EPOCH : 141/1000 ***/\n",
      "TRAIN - 49873.8203125, nan\n",
      "TEST - 51689.27734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9077e-04.\n",
      "/*** EPOCH : 142/1000 ***/\n",
      "TRAIN - 48422.7421875, nan\n",
      "TEST - 50178.83203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8832e-04.\n",
      "/*** EPOCH : 143/1000 ***/\n",
      "TRAIN - 47140.33984375, nan\n",
      "TEST - 49921.80078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8587e-04.\n",
      "/*** EPOCH : 144/1000 ***/\n",
      "TRAIN - 45955.10546875, nan\n",
      "TEST - 47791.859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8344e-04.\n",
      "/*** EPOCH : 145/1000 ***/\n",
      "TRAIN - 44357.8125, nan\n",
      "TEST - 46312.453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8103e-04.\n",
      "/*** EPOCH : 146/1000 ***/\n",
      "TRAIN - 43315.41015625, nan\n",
      "TEST - 45280.765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7862e-04.\n",
      "/*** EPOCH : 147/1000 ***/\n",
      "TRAIN - 41875.8828125, nan\n",
      "TEST - 43976.3828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7623e-04.\n",
      "/*** EPOCH : 148/1000 ***/\n",
      "TRAIN - 40593.77734375, nan\n",
      "TEST - 43920.796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7385e-04.\n",
      "/*** EPOCH : 149/1000 ***/\n",
      "TRAIN - 39670.73828125, nan\n",
      "TEST - 41856.16796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7148e-04.\n",
      "/*** EPOCH : 150/1000 ***/\n",
      "TRAIN - 38152.1640625, nan\n",
      "TEST - 40529.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6912e-04.\n",
      "/*** EPOCH : 151/1000 ***/\n",
      "TRAIN - 37154.16796875, nan\n",
      "TEST - 39999.73046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6678e-04.\n",
      "/*** EPOCH : 152/1000 ***/\n",
      "TRAIN - 35924.30859375, nan\n",
      "TEST - 38274.578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6444e-04.\n",
      "/*** EPOCH : 153/1000 ***/\n",
      "TRAIN - 35050.984375, nan\n",
      "TEST - 37600.76171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6212e-04.\n",
      "/*** EPOCH : 154/1000 ***/\n",
      "TRAIN - 33947.08203125, nan\n",
      "TEST - 36378.91796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5981e-04.\n",
      "/*** EPOCH : 155/1000 ***/\n",
      "TRAIN - 32934.46875, nan\n",
      "TEST - 35472.74609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5751e-04.\n",
      "/*** EPOCH : 156/1000 ***/\n",
      "TRAIN - 31855.41796875, nan\n",
      "TEST - 34881.25390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5522e-04.\n",
      "/*** EPOCH : 157/1000 ***/\n",
      "TRAIN - 30970.703125, nan\n",
      "TEST - 33940.23046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5295e-04.\n",
      "/*** EPOCH : 158/1000 ***/\n",
      "TRAIN - 29991.2890625, nan\n",
      "TEST - 32673.875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5068e-04.\n",
      "/*** EPOCH : 159/1000 ***/\n",
      "TRAIN - 29105.14453125, nan\n",
      "TEST - 32384.42578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4843e-04.\n",
      "/*** EPOCH : 160/1000 ***/\n",
      "TRAIN - 28431.39453125, nan\n",
      "TEST - 30746.349609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4619e-04.\n",
      "/*** EPOCH : 161/1000 ***/\n",
      "TRAIN - 27790.572265625, nan\n",
      "TEST - 31808.984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4396e-04.\n",
      "/*** EPOCH : 162/1000 ***/\n",
      "TRAIN - 26933.466796875, nan\n",
      "TEST - 29285.865234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4174e-04.\n",
      "/*** EPOCH : 163/1000 ***/\n",
      "TRAIN - 25874.5, nan\n",
      "TEST - 28302.03515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3953e-04.\n",
      "/*** EPOCH : 164/1000 ***/\n",
      "TRAIN - 25184.318359375, nan\n",
      "TEST - 28630.21484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3733e-04.\n",
      "/*** EPOCH : 165/1000 ***/\n",
      "TRAIN - 24098.765625, nan\n",
      "TEST - 27155.46484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3514e-04.\n",
      "/*** EPOCH : 166/1000 ***/\n",
      "TRAIN - 23706.3125, nan\n",
      "TEST - 26155.798828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3297e-04.\n",
      "/*** EPOCH : 167/1000 ***/\n",
      "TRAIN - 22939.72265625, nan\n",
      "TEST - 25408.205078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3080e-04.\n",
      "/*** EPOCH : 168/1000 ***/\n",
      "TRAIN - 22440.625, nan\n",
      "TEST - 25791.8046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2865e-04.\n",
      "/*** EPOCH : 169/1000 ***/\n",
      "TRAIN - 21469.548828125, nan\n",
      "TEST - 23936.27734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2650e-04.\n",
      "/*** EPOCH : 170/1000 ***/\n",
      "TRAIN - 22561.318359375, nan\n",
      "TEST - 28445.36328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2437e-04.\n",
      "/*** EPOCH : 171/1000 ***/\n",
      "TRAIN - 21176.69140625, nan\n",
      "TEST - 22490.064453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2225e-04.\n",
      "/*** EPOCH : 172/1000 ***/\n",
      "TRAIN - 19894.603515625, nan\n",
      "TEST - 23252.986328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2014e-04.\n",
      "/*** EPOCH : 173/1000 ***/\n",
      "TRAIN - 19203.388671875, nan\n",
      "TEST - 25981.416015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1804e-04.\n",
      "/*** EPOCH : 174/1000 ***/\n",
      "TRAIN - 20044.150390625, nan\n",
      "TEST - 20548.4140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1595e-04.\n",
      "/*** EPOCH : 175/1000 ***/\n",
      "TRAIN - 18416.255859375, nan\n",
      "TEST - 23278.25390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1387e-04.\n",
      "/*** EPOCH : 176/1000 ***/\n",
      "TRAIN - 17887.2109375, nan\n",
      "TEST - 21251.205078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1180e-04.\n",
      "/*** EPOCH : 177/1000 ***/\n",
      "TRAIN - 17316.529296875, nan\n",
      "TEST - 22950.552734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0974e-04.\n",
      "/*** EPOCH : 178/1000 ***/\n",
      "TRAIN - 16913.76953125, nan\n",
      "TEST - 19625.755859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0769e-04.\n",
      "/*** EPOCH : 179/1000 ***/\n",
      "TRAIN - 16663.578125, nan\n",
      "TEST - 22504.7109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0565e-04.\n",
      "/*** EPOCH : 180/1000 ***/\n",
      "TRAIN - 24074.8359375, nan\n",
      "TEST - 20610.365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0362e-04.\n",
      "/*** EPOCH : 181/1000 ***/\n",
      "TRAIN - 18212.267578125, nan\n",
      "TEST - 16880.423828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0161e-04.\n",
      "/*** EPOCH : 182/1000 ***/\n",
      "TRAIN - 17588.1328125, nan\n",
      "TEST - 17292.001953125, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.9960e-04.\n",
      "/*** EPOCH : 183/1000 ***/\n",
      "TRAIN - 18008.083984375, nan\n",
      "TEST - 17433.32421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9760e-04.\n",
      "/*** EPOCH : 184/1000 ***/\n",
      "TRAIN - 21158.759765625, nan\n",
      "TEST - 20224.703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9561e-04.\n",
      "/*** EPOCH : 185/1000 ***/\n",
      "TRAIN - 15206.1083984375, nan\n",
      "TEST - 25886.796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9363e-04.\n",
      "/*** EPOCH : 186/1000 ***/\n",
      "TRAIN - 1858355.5, nan\n",
      "TEST - 3532880.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9167e-04.\n",
      "/*** EPOCH : 187/1000 ***/\n",
      "TRAIN - 1671008.0, nan\n",
      "TEST - 46882.75, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8971e-04.\n",
      "/*** EPOCH : 188/1000 ***/\n",
      "TRAIN - 17856.736328125, nan\n",
      "TEST - 16073.9267578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8776e-04.\n",
      "/*** EPOCH : 189/1000 ***/\n",
      "TRAIN - 13064.6826171875, nan\n",
      "TEST - 14625.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8582e-04.\n",
      "/*** EPOCH : 190/1000 ***/\n",
      "TRAIN - 12465.490234375, nan\n",
      "TEST - 14389.947265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8389e-04.\n",
      "/*** EPOCH : 191/1000 ***/\n",
      "TRAIN - 12279.765625, nan\n",
      "TEST - 13723.5322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8197e-04.\n",
      "/*** EPOCH : 192/1000 ***/\n",
      "TRAIN - 11729.39453125, nan\n",
      "TEST - 13514.4384765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8006e-04.\n",
      "/*** EPOCH : 193/1000 ***/\n",
      "TRAIN - 11754.3701171875, nan\n",
      "TEST - 13437.5126953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7816e-04.\n",
      "/*** EPOCH : 194/1000 ***/\n",
      "TRAIN - 11084.953125, nan\n",
      "TEST - 12510.40625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7627e-04.\n",
      "/*** EPOCH : 195/1000 ***/\n",
      "TRAIN - 10981.4228515625, nan\n",
      "TEST - 14122.427734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7439e-04.\n",
      "/*** EPOCH : 196/1000 ***/\n",
      "TRAIN - 10982.4892578125, nan\n",
      "TEST - 12948.3505859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7252e-04.\n",
      "/*** EPOCH : 197/1000 ***/\n",
      "TRAIN - 11725.669921875, nan\n",
      "TEST - 11777.1328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7066e-04.\n",
      "/*** EPOCH : 198/1000 ***/\n",
      "TRAIN - 9954.0791015625, nan\n",
      "TEST - 12943.791015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6880e-04.\n",
      "/*** EPOCH : 199/1000 ***/\n",
      "TRAIN - 12119.1162109375, nan\n",
      "TEST - 11965.3232421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6696e-04.\n",
      "/*** EPOCH : 200/1000 ***/\n",
      "TRAIN - 10411.9169921875, nan\n",
      "TEST - 11844.841796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6512e-04.\n",
      "/*** EPOCH : 201/1000 ***/\n",
      "TRAIN - 10339.513671875, nan\n",
      "TEST - 11936.7822265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6330e-04.\n",
      "/*** EPOCH : 202/1000 ***/\n",
      "TRAIN - 9461.9443359375, nan\n",
      "TEST - 10214.908203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6148e-04.\n",
      "/*** EPOCH : 203/1000 ***/\n",
      "TRAIN - 9563.5126953125, nan\n",
      "TEST - 9623.236328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5967e-04.\n",
      "/*** EPOCH : 204/1000 ***/\n",
      "TRAIN - 9391.12109375, nan\n",
      "TEST - 10738.4677734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5788e-04.\n",
      "/*** EPOCH : 205/1000 ***/\n",
      "TRAIN - 11262.1953125, nan\n",
      "TEST - 13759.01171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5609e-04.\n",
      "/*** EPOCH : 206/1000 ***/\n",
      "TRAIN - 9330.7138671875, nan\n",
      "TEST - 9123.3642578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5431e-04.\n",
      "/*** EPOCH : 207/1000 ***/\n",
      "TRAIN - 10076.583984375, nan\n",
      "TEST - 8874.9208984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5253e-04.\n",
      "/*** EPOCH : 208/1000 ***/\n",
      "TRAIN - 10163.302734375, nan\n",
      "TEST - 9357.7294921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5077e-04.\n",
      "/*** EPOCH : 209/1000 ***/\n",
      "TRAIN - 9148.64453125, nan\n",
      "TEST - 11005.5361328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4902e-04.\n",
      "/*** EPOCH : 210/1000 ***/\n",
      "TRAIN - 14744.666015625, nan\n",
      "TEST - 25478.46875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4727e-04.\n",
      "/*** EPOCH : 211/1000 ***/\n",
      "TRAIN - 21815.705078125, nan\n",
      "TEST - 11978.65234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4554e-04.\n",
      "/*** EPOCH : 212/1000 ***/\n",
      "TRAIN - 41751.5, nan\n",
      "TEST - 14611.8271484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4381e-04.\n",
      "/*** EPOCH : 213/1000 ***/\n",
      "TRAIN - 21752.455078125, nan\n",
      "TEST - 95681.9140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4209e-04.\n",
      "/*** EPOCH : 214/1000 ***/\n",
      "TRAIN - 25665.833984375, nan\n",
      "TEST - 16600.48046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4038e-04.\n",
      "/*** EPOCH : 215/1000 ***/\n",
      "TRAIN - 18594.2734375, nan\n",
      "TEST - 8734.35546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3868e-04.\n",
      "/*** EPOCH : 216/1000 ***/\n",
      "TRAIN - 84815.234375, nan\n",
      "TEST - 167332.890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3698e-04.\n",
      "/*** EPOCH : 217/1000 ***/\n",
      "TRAIN - 101544.0, nan\n",
      "TEST - 74066.9453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3530e-04.\n",
      "/*** EPOCH : 218/1000 ***/\n",
      "TRAIN - 18297.376953125, nan\n",
      "TEST - 7722.68310546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3362e-04.\n",
      "/*** EPOCH : 219/1000 ***/\n",
      "TRAIN - 9751.525390625, nan\n",
      "TEST - 14625.7451171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3195e-04.\n",
      "/*** EPOCH : 220/1000 ***/\n",
      "TRAIN - 8234.7490234375, nan\n",
      "TEST - 10236.3408203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3029e-04.\n",
      "/*** EPOCH : 221/1000 ***/\n",
      "TRAIN - 53628.89453125, nan\n",
      "TEST - 52790.7734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2864e-04.\n",
      "/*** EPOCH : 222/1000 ***/\n",
      "TRAIN - 193906.859375, nan\n",
      "TEST - 78421.3359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2700e-04.\n",
      "/*** EPOCH : 223/1000 ***/\n",
      "TRAIN - 154099.171875, nan\n",
      "TEST - 9723.2421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2536e-04.\n",
      "/*** EPOCH : 224/1000 ***/\n",
      "TRAIN - 11911.86328125, nan\n",
      "TEST - 7687.25732421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2374e-04.\n",
      "/*** EPOCH : 225/1000 ***/\n",
      "TRAIN - 8095.54541015625, nan\n",
      "TEST - 6910.677734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2212e-04.\n",
      "/*** EPOCH : 226/1000 ***/\n",
      "TRAIN - 9331.517578125, nan\n",
      "TEST - 7520.06298828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2051e-04.\n",
      "/*** EPOCH : 227/1000 ***/\n",
      "TRAIN - 7507.7421875, nan\n",
      "TEST - 7372.32568359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1891e-04.\n",
      "/*** EPOCH : 228/1000 ***/\n",
      "TRAIN - 27152.0390625, nan\n",
      "TEST - 203012.28125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1731e-04.\n",
      "/*** EPOCH : 229/1000 ***/\n",
      "TRAIN - 198809.421875, nan\n",
      "TEST - 36113.3671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1572e-04.\n",
      "/*** EPOCH : 230/1000 ***/\n",
      "TRAIN - 11999.013671875, nan\n",
      "TEST - 11396.8369140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1415e-04.\n",
      "/*** EPOCH : 231/1000 ***/\n",
      "TRAIN - 9426.4501953125, nan\n",
      "TEST - 7595.75341796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1258e-04.\n",
      "/*** EPOCH : 232/1000 ***/\n",
      "TRAIN - 7335.3955078125, nan\n",
      "TEST - 10852.076171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1101e-04.\n",
      "/*** EPOCH : 233/1000 ***/\n",
      "TRAIN - 14249.0185546875, nan\n",
      "TEST - 31601.23046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0946e-04.\n",
      "/*** EPOCH : 234/1000 ***/\n",
      "TRAIN - 59696.48828125, nan\n",
      "TEST - 17656.943359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0791e-04.\n",
      "/*** EPOCH : 235/1000 ***/\n",
      "TRAIN - 177941.03125, nan\n",
      "TEST - 15530.1806640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0637e-04.\n",
      "/*** EPOCH : 236/1000 ***/\n",
      "TRAIN - 79069.2578125, nan\n",
      "TEST - 12079.8359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0484e-04.\n",
      "/*** EPOCH : 237/1000 ***/\n",
      "TRAIN - 9947.5107421875, nan\n",
      "TEST - 6403.77001953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0331e-04.\n",
      "/*** EPOCH : 238/1000 ***/\n",
      "TRAIN - 8984.89453125, nan\n",
      "TEST - 7561.32275390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0180e-04.\n",
      "/*** EPOCH : 239/1000 ***/\n",
      "TRAIN - 12325.08203125, nan\n",
      "TEST - 5810.025390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0029e-04.\n",
      "/*** EPOCH : 240/1000 ***/\n",
      "TRAIN - 9795.4072265625, nan\n",
      "TEST - 5245.10791015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9879e-04.\n",
      "/*** EPOCH : 241/1000 ***/\n",
      "TRAIN - 11059.2236328125, nan\n",
      "TEST - 33577.08203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9729e-04.\n",
      "/*** EPOCH : 242/1000 ***/\n",
      "TRAIN - 17700.638671875, nan\n",
      "TEST - 10435.353515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9581e-04.\n",
      "/*** EPOCH : 243/1000 ***/\n",
      "TRAIN - 8499.0078125, nan\n",
      "TEST - 9511.1650390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9433e-04.\n",
      "/*** EPOCH : 244/1000 ***/\n",
      "TRAIN - 10074.986328125, nan\n",
      "TEST - 6236.8994140625, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.9286e-04.\n",
      "/*** EPOCH : 245/1000 ***/\n",
      "TRAIN - 37791.73046875, nan\n",
      "TEST - 44615.7890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9139e-04.\n",
      "/*** EPOCH : 246/1000 ***/\n",
      "TRAIN - 148774.90625, nan\n",
      "TEST - 196109.96875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8994e-04.\n",
      "/*** EPOCH : 247/1000 ***/\n",
      "TRAIN - 86980.1796875, nan\n",
      "TEST - 44672.04296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8849e-04.\n",
      "/*** EPOCH : 248/1000 ***/\n",
      "TRAIN - 17915.64453125, nan\n",
      "TEST - 6683.96142578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8704e-04.\n",
      "/*** EPOCH : 249/1000 ***/\n",
      "TRAIN - 7194.23876953125, nan\n",
      "TEST - 6167.6943359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8561e-04.\n",
      "/*** EPOCH : 250/1000 ***/\n",
      "TRAIN - 8533.2607421875, nan\n",
      "TEST - 6631.68310546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8418e-04.\n",
      "/*** EPOCH : 251/1000 ***/\n",
      "TRAIN - 8560.2138671875, nan\n",
      "TEST - 21158.6875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8276e-04.\n",
      "/*** EPOCH : 252/1000 ***/\n",
      "TRAIN - 11932.16015625, nan\n",
      "TEST - 17308.056640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8135e-04.\n",
      "/*** EPOCH : 253/1000 ***/\n",
      "TRAIN - 11392.4384765625, nan\n",
      "TEST - 5939.33251953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7994e-04.\n",
      "/*** EPOCH : 254/1000 ***/\n",
      "TRAIN - 7459.04443359375, nan\n",
      "TEST - 8201.474609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7854e-04.\n",
      "/*** EPOCH : 255/1000 ***/\n",
      "TRAIN - 12376.8115234375, nan\n",
      "TEST - 16442.173828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7715e-04.\n",
      "/*** EPOCH : 256/1000 ***/\n",
      "TRAIN - 10445.1884765625, nan\n",
      "TEST - 18071.224609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7576e-04.\n",
      "/*** EPOCH : 257/1000 ***/\n",
      "TRAIN - 56436.4375, nan\n",
      "TEST - 23736.705078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7438e-04.\n",
      "/*** EPOCH : 258/1000 ***/\n",
      "TRAIN - 14221.1591796875, nan\n",
      "TEST - 46375.68359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7301e-04.\n",
      "/*** EPOCH : 259/1000 ***/\n",
      "TRAIN - 25264.3203125, nan\n",
      "TEST - 12264.376953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7164e-04.\n",
      "/*** EPOCH : 260/1000 ***/\n",
      "TRAIN - 323426.46875, nan\n",
      "TEST - 149464.3125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7029e-04.\n",
      "/*** EPOCH : 261/1000 ***/\n",
      "TRAIN - 31150.064453125, nan\n",
      "TEST - 6005.89501953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6893e-04.\n",
      "/*** EPOCH : 262/1000 ***/\n",
      "TRAIN - 6865.89453125, nan\n",
      "TEST - 5688.1767578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6759e-04.\n",
      "/*** EPOCH : 263/1000 ***/\n",
      "TRAIN - 6669.826171875, nan\n",
      "TEST - 6352.72021484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6625e-04.\n",
      "/*** EPOCH : 264/1000 ***/\n",
      "TRAIN - 6701.572265625, nan\n",
      "TEST - 5840.162109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6492e-04.\n",
      "/*** EPOCH : 265/1000 ***/\n",
      "TRAIN - 6654.248046875, nan\n",
      "TEST - 10239.9462890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6360e-04.\n",
      "/*** EPOCH : 266/1000 ***/\n",
      "TRAIN - 6683.64306640625, nan\n",
      "TEST - 4341.65087890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6228e-04.\n",
      "/*** EPOCH : 267/1000 ***/\n",
      "TRAIN - 5639.67333984375, nan\n",
      "TEST - 4901.3427734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6097e-04.\n",
      "/*** EPOCH : 268/1000 ***/\n",
      "TRAIN - 5730.2392578125, nan\n",
      "TEST - 4720.1640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5966e-04.\n",
      "/*** EPOCH : 269/1000 ***/\n",
      "TRAIN - 7633.93310546875, nan\n",
      "TEST - 9643.833984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5836e-04.\n",
      "/*** EPOCH : 270/1000 ***/\n",
      "TRAIN - 6956.32421875, nan\n",
      "TEST - 5017.74072265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5707e-04.\n",
      "/*** EPOCH : 271/1000 ***/\n",
      "TRAIN - 5948.40185546875, nan\n",
      "TEST - 6385.8818359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5579e-04.\n",
      "/*** EPOCH : 272/1000 ***/\n",
      "TRAIN - 6543.912109375, nan\n",
      "TEST - 5093.3720703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5451e-04.\n",
      "/*** EPOCH : 273/1000 ***/\n",
      "TRAIN - 7409.9228515625, nan\n",
      "TEST - 9520.6259765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5324e-04.\n",
      "/*** EPOCH : 274/1000 ***/\n",
      "TRAIN - 6513.9580078125, nan\n",
      "TEST - 11633.8515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5197e-04.\n",
      "/*** EPOCH : 275/1000 ***/\n",
      "TRAIN - 6284.9951171875, nan\n",
      "TEST - 7900.99755859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5071e-04.\n",
      "/*** EPOCH : 276/1000 ***/\n",
      "TRAIN - 7958.33740234375, nan\n",
      "TEST - 37490.0859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4946e-04.\n",
      "/*** EPOCH : 277/1000 ***/\n",
      "TRAIN - 10113.01953125, nan\n",
      "TEST - 10625.10546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4821e-04.\n",
      "/*** EPOCH : 278/1000 ***/\n",
      "TRAIN - 10817.8095703125, nan\n",
      "TEST - 3965.20166015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4697e-04.\n",
      "/*** EPOCH : 279/1000 ***/\n",
      "TRAIN - 20264.529296875, nan\n",
      "TEST - 6389.51220703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4573e-04.\n",
      "/*** EPOCH : 280/1000 ***/\n",
      "TRAIN - 18237.267578125, nan\n",
      "TEST - 12097.171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4450e-04.\n",
      "/*** EPOCH : 281/1000 ***/\n",
      "TRAIN - 13523.609375, nan\n",
      "TEST - 9974.4306640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4328e-04.\n",
      "/*** EPOCH : 282/1000 ***/\n",
      "TRAIN - 11499.5595703125, nan\n",
      "TEST - 23398.84765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4206e-04.\n",
      "/*** EPOCH : 283/1000 ***/\n",
      "TRAIN - 10360.818359375, nan\n",
      "TEST - 11694.5322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4085e-04.\n",
      "/*** EPOCH : 284/1000 ***/\n",
      "TRAIN - 8446.1484375, nan\n",
      "TEST - 8504.662109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3965e-04.\n",
      "/*** EPOCH : 285/1000 ***/\n",
      "TRAIN - 11647.341796875, nan\n",
      "TEST - 15297.2314453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3845e-04.\n",
      "/*** EPOCH : 286/1000 ***/\n",
      "TRAIN - 9233.75, nan\n",
      "TEST - 9719.208984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3726e-04.\n",
      "/*** EPOCH : 287/1000 ***/\n",
      "TRAIN - 20683.197265625, nan\n",
      "TEST - 13519.705078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3607e-04.\n",
      "/*** EPOCH : 288/1000 ***/\n",
      "TRAIN - 9146.0498046875, nan\n",
      "TEST - 5597.28271484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3489e-04.\n",
      "/*** EPOCH : 289/1000 ***/\n",
      "TRAIN - 10183.9609375, nan\n",
      "TEST - 21696.29296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3372e-04.\n",
      "/*** EPOCH : 290/1000 ***/\n",
      "TRAIN - 9253.8134765625, nan\n",
      "TEST - 6154.51904296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3255e-04.\n",
      "/*** EPOCH : 291/1000 ***/\n",
      "TRAIN - 8219.84765625, nan\n",
      "TEST - 5358.80859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3139e-04.\n",
      "/*** EPOCH : 292/1000 ***/\n",
      "TRAIN - 13671.4453125, nan\n",
      "TEST - 5607.30517578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3023e-04.\n",
      "/*** EPOCH : 293/1000 ***/\n",
      "TRAIN - 14984.24609375, nan\n",
      "TEST - 4441.01171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2908e-04.\n",
      "/*** EPOCH : 294/1000 ***/\n",
      "TRAIN - 7897.12939453125, nan\n",
      "TEST - 4564.7119140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2793e-04.\n",
      "/*** EPOCH : 295/1000 ***/\n",
      "TRAIN - 8595.4716796875, nan\n",
      "TEST - 7425.69384765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2679e-04.\n",
      "/*** EPOCH : 296/1000 ***/\n",
      "TRAIN - 7444.28466796875, nan\n",
      "TEST - 6495.15869140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2566e-04.\n",
      "/*** EPOCH : 297/1000 ***/\n",
      "TRAIN - 7251.2080078125, nan\n",
      "TEST - 4426.859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2453e-04.\n",
      "/*** EPOCH : 298/1000 ***/\n",
      "TRAIN - 15377.18359375, nan\n",
      "TEST - 12197.037109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2341e-04.\n",
      "/*** EPOCH : 299/1000 ***/\n",
      "TRAIN - 7931.798828125, nan\n",
      "TEST - 4884.7158203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2229e-04.\n",
      "/*** EPOCH : 300/1000 ***/\n",
      "TRAIN - 7027.50146484375, nan\n",
      "TEST - 6550.630859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2118e-04.\n",
      "/*** EPOCH : 301/1000 ***/\n",
      "TRAIN - 7927.57421875, nan\n",
      "TEST - 11782.955078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2007e-04.\n",
      "/*** EPOCH : 302/1000 ***/\n",
      "TRAIN - 20882.427734375, nan\n",
      "TEST - 14845.6923828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1897e-04.\n",
      "/*** EPOCH : 303/1000 ***/\n",
      "TRAIN - 10116.9638671875, nan\n",
      "TEST - 18408.91796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1788e-04.\n",
      "/*** EPOCH : 304/1000 ***/\n",
      "TRAIN - 6668.3134765625, nan\n",
      "TEST - 5848.33837890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1679e-04.\n",
      "/*** EPOCH : 305/1000 ***/\n",
      "TRAIN - 7713.20751953125, nan\n",
      "TEST - 5759.24560546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1571e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*** EPOCH : 306/1000 ***/\n",
      "TRAIN - 8164.02734375, nan\n",
      "TEST - 8182.890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1463e-04.\n",
      "/*** EPOCH : 307/1000 ***/\n",
      "TRAIN - 8929.7587890625, nan\n",
      "TEST - 9128.3828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1355e-04.\n",
      "/*** EPOCH : 308/1000 ***/\n",
      "TRAIN - 10446.8837890625, nan\n",
      "TEST - 13491.5029296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1249e-04.\n",
      "/*** EPOCH : 309/1000 ***/\n",
      "TRAIN - 12348.7529296875, nan\n",
      "TEST - 13157.658203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1142e-04.\n",
      "/*** EPOCH : 310/1000 ***/\n",
      "TRAIN - 7278.76513671875, nan\n",
      "TEST - 6617.59228515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.1037e-04.\n",
      "/*** EPOCH : 311/1000 ***/\n",
      "TRAIN - 6313.33740234375, nan\n",
      "TEST - 5077.59814453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0932e-04.\n",
      "/*** EPOCH : 312/1000 ***/\n",
      "TRAIN - 8443.5732421875, nan\n",
      "TEST - 6428.70654296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0827e-04.\n",
      "/*** EPOCH : 313/1000 ***/\n",
      "TRAIN - 8550.6025390625, nan\n",
      "TEST - 17854.142578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0723e-04.\n",
      "/*** EPOCH : 314/1000 ***/\n",
      "TRAIN - 24993.28125, nan\n",
      "TEST - 15257.9384765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0619e-04.\n",
      "/*** EPOCH : 315/1000 ***/\n",
      "TRAIN - 6239.88134765625, nan\n",
      "TEST - 6373.33642578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0516e-04.\n",
      "/*** EPOCH : 316/1000 ***/\n",
      "TRAIN - 8090.42529296875, nan\n",
      "TEST - 15804.123046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0413e-04.\n",
      "/*** EPOCH : 317/1000 ***/\n",
      "TRAIN - 8518.7568359375, nan\n",
      "TEST - 5727.29736328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0311e-04.\n",
      "/*** EPOCH : 318/1000 ***/\n",
      "TRAIN - 6893.240234375, nan\n",
      "TEST - 5620.90966796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0210e-04.\n",
      "/*** EPOCH : 319/1000 ***/\n",
      "TRAIN - 6557.19091796875, nan\n",
      "TEST - 8816.0693359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0109e-04.\n",
      "/*** EPOCH : 320/1000 ***/\n",
      "TRAIN - 6280.90234375, nan\n",
      "TEST - 5226.66015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.0008e-04.\n",
      "/*** EPOCH : 321/1000 ***/\n",
      "TRAIN - 5500.5546875, nan\n",
      "TEST - 5035.06201171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9908e-04.\n",
      "/*** EPOCH : 322/1000 ***/\n",
      "TRAIN - 6397.4423828125, nan\n",
      "TEST - 4954.70263671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9809e-04.\n",
      "/*** EPOCH : 323/1000 ***/\n",
      "TRAIN - 6598.46142578125, nan\n",
      "TEST - 7828.5126953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9710e-04.\n",
      "/*** EPOCH : 324/1000 ***/\n",
      "TRAIN - 7047.8173828125, nan\n",
      "TEST - 4896.439453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9611e-04.\n",
      "/*** EPOCH : 325/1000 ***/\n",
      "TRAIN - 5964.57470703125, nan\n",
      "TEST - 7203.6259765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9513e-04.\n",
      "/*** EPOCH : 326/1000 ***/\n",
      "TRAIN - 7183.845703125, nan\n",
      "TEST - 6037.146484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9415e-04.\n",
      "/*** EPOCH : 327/1000 ***/\n",
      "TRAIN - 6200.79931640625, nan\n",
      "TEST - 5004.642578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9318e-04.\n",
      "/*** EPOCH : 328/1000 ***/\n",
      "TRAIN - 5480.85595703125, nan\n",
      "TEST - 5110.142578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9222e-04.\n",
      "/*** EPOCH : 329/1000 ***/\n",
      "TRAIN - 7004.1025390625, nan\n",
      "TEST - 9166.0068359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9126e-04.\n",
      "/*** EPOCH : 330/1000 ***/\n",
      "TRAIN - 6541.3837890625, nan\n",
      "TEST - 5545.99365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.9030e-04.\n",
      "/*** EPOCH : 331/1000 ***/\n",
      "TRAIN - 9232.080078125, nan\n",
      "TEST - 4365.78857421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8935e-04.\n",
      "/*** EPOCH : 332/1000 ***/\n",
      "TRAIN - 6887.677734375, nan\n",
      "TEST - 5636.34765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8840e-04.\n",
      "/*** EPOCH : 333/1000 ***/\n",
      "TRAIN - 5990.068359375, nan\n",
      "TEST - 5219.40966796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8746e-04.\n",
      "/*** EPOCH : 334/1000 ***/\n",
      "TRAIN - 5150.05517578125, nan\n",
      "TEST - 10447.42578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8652e-04.\n",
      "/*** EPOCH : 335/1000 ***/\n",
      "TRAIN - 6711.3056640625, nan\n",
      "TEST - 3799.286376953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8559e-04.\n",
      "/*** EPOCH : 336/1000 ***/\n",
      "TRAIN - 4910.84423828125, nan\n",
      "TEST - 4698.2373046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8466e-04.\n",
      "/*** EPOCH : 337/1000 ***/\n",
      "TRAIN - 6432.1630859375, nan\n",
      "TEST - 8957.1669921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8374e-04.\n",
      "/*** EPOCH : 338/1000 ***/\n",
      "TRAIN - 6148.10986328125, nan\n",
      "TEST - 6477.44482421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8282e-04.\n",
      "/*** EPOCH : 339/1000 ***/\n",
      "TRAIN - 5760.64404296875, nan\n",
      "TEST - 5025.8759765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8191e-04.\n",
      "/*** EPOCH : 340/1000 ***/\n",
      "TRAIN - 4917.12548828125, nan\n",
      "TEST - 4426.599609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8100e-04.\n",
      "/*** EPOCH : 341/1000 ***/\n",
      "TRAIN - 5004.4345703125, nan\n",
      "TEST - 4729.88134765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.8009e-04.\n",
      "/*** EPOCH : 342/1000 ***/\n",
      "TRAIN - 5721.197265625, nan\n",
      "TEST - 5497.86767578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7919e-04.\n",
      "/*** EPOCH : 343/1000 ***/\n",
      "TRAIN - 5378.4296875, nan\n",
      "TEST - 6943.3369140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7830e-04.\n",
      "/*** EPOCH : 344/1000 ***/\n",
      "TRAIN - 5373.1767578125, nan\n",
      "TEST - 4097.498046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7740e-04.\n",
      "/*** EPOCH : 345/1000 ***/\n",
      "TRAIN - 6217.18115234375, nan\n",
      "TEST - 3583.380859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7652e-04.\n",
      "/*** EPOCH : 346/1000 ***/\n",
      "TRAIN - 4895.884765625, nan\n",
      "TEST - 4628.93212890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7563e-04.\n",
      "/*** EPOCH : 347/1000 ***/\n",
      "TRAIN - 4532.8740234375, nan\n",
      "TEST - 4932.70361328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7476e-04.\n",
      "/*** EPOCH : 348/1000 ***/\n",
      "TRAIN - 5071.7587890625, nan\n",
      "TEST - 4257.740234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7388e-04.\n",
      "/*** EPOCH : 349/1000 ***/\n",
      "TRAIN - 4886.22216796875, nan\n",
      "TEST - 6231.5234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7301e-04.\n",
      "/*** EPOCH : 350/1000 ***/\n",
      "TRAIN - 5115.92236328125, nan\n",
      "TEST - 3665.64599609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7215e-04.\n",
      "/*** EPOCH : 351/1000 ***/\n",
      "TRAIN - 5259.39404296875, nan\n",
      "TEST - 3836.638427734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7129e-04.\n",
      "/*** EPOCH : 352/1000 ***/\n",
      "TRAIN - 4733.35498046875, nan\n",
      "TEST - 4690.763671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.7043e-04.\n",
      "/*** EPOCH : 353/1000 ***/\n",
      "TRAIN - 4411.4560546875, nan\n",
      "TEST - 4273.82763671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6958e-04.\n",
      "/*** EPOCH : 354/1000 ***/\n",
      "TRAIN - 4403.15185546875, nan\n",
      "TEST - 3492.099609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6873e-04.\n",
      "/*** EPOCH : 355/1000 ***/\n",
      "TRAIN - 5613.48388671875, nan\n",
      "TEST - 3613.398193359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6789e-04.\n",
      "/*** EPOCH : 356/1000 ***/\n",
      "TRAIN - 4520.1220703125, nan\n",
      "TEST - 3945.8466796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6705e-04.\n",
      "/*** EPOCH : 357/1000 ***/\n",
      "TRAIN - 4444.9765625, nan\n",
      "TEST - 5101.56640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6621e-04.\n",
      "/*** EPOCH : 358/1000 ***/\n",
      "TRAIN - 4957.37451171875, nan\n",
      "TEST - 4247.5341796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6538e-04.\n",
      "/*** EPOCH : 359/1000 ***/\n",
      "TRAIN - 4854.96484375, nan\n",
      "TEST - 4702.21240234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6455e-04.\n",
      "/*** EPOCH : 360/1000 ***/\n",
      "TRAIN - 4415.13525390625, nan\n",
      "TEST - 5412.69873046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6373e-04.\n",
      "/*** EPOCH : 361/1000 ***/\n",
      "TRAIN - 4457.0322265625, nan\n",
      "TEST - 3429.86083984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6291e-04.\n",
      "/*** EPOCH : 362/1000 ***/\n",
      "TRAIN - 4579.974609375, nan\n",
      "TEST - 4045.492431640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6210e-04.\n",
      "/*** EPOCH : 363/1000 ***/\n",
      "TRAIN - 4338.951171875, nan\n",
      "TEST - 4508.181640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6129e-04.\n",
      "/*** EPOCH : 364/1000 ***/\n",
      "TRAIN - 4080.416748046875, nan\n",
      "TEST - 3995.575927734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.6048e-04.\n",
      "/*** EPOCH : 365/1000 ***/\n",
      "TRAIN - 4623.6220703125, nan\n",
      "TEST - 4083.1240234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5968e-04.\n",
      "/*** EPOCH : 366/1000 ***/\n",
      "TRAIN - 4094.03857421875, nan\n",
      "TEST - 5267.5244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5888e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*** EPOCH : 367/1000 ***/\n",
      "TRAIN - 4164.80517578125, nan\n",
      "TEST - 3284.213623046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5809e-04.\n",
      "/*** EPOCH : 368/1000 ***/\n",
      "TRAIN - 4047.408935546875, nan\n",
      "TEST - 3948.954833984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5730e-04.\n",
      "/*** EPOCH : 369/1000 ***/\n",
      "TRAIN - 4110.11279296875, nan\n",
      "TEST - 3733.738525390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5651e-04.\n",
      "/*** EPOCH : 370/1000 ***/\n",
      "TRAIN - 3965.3310546875, nan\n",
      "TEST - 4362.11669921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5573e-04.\n",
      "/*** EPOCH : 371/1000 ***/\n",
      "TRAIN - 4309.4208984375, nan\n",
      "TEST - 3653.08251953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5495e-04.\n",
      "/*** EPOCH : 372/1000 ***/\n",
      "TRAIN - 4203.36083984375, nan\n",
      "TEST - 3394.59765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5417e-04.\n",
      "/*** EPOCH : 373/1000 ***/\n",
      "TRAIN - 3968.348876953125, nan\n",
      "TEST - 5533.5625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5340e-04.\n",
      "/*** EPOCH : 374/1000 ***/\n",
      "TRAIN - 4175.5771484375, nan\n",
      "TEST - 4093.17626953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5264e-04.\n",
      "/*** EPOCH : 375/1000 ***/\n",
      "TRAIN - 4252.22509765625, nan\n",
      "TEST - 4079.573974609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5187e-04.\n",
      "/*** EPOCH : 376/1000 ***/\n",
      "TRAIN - 4243.66162109375, nan\n",
      "TEST - 4874.39794921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5111e-04.\n",
      "/*** EPOCH : 377/1000 ***/\n",
      "TRAIN - 4370.42919921875, nan\n",
      "TEST - 3769.50634765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.5036e-04.\n",
      "/*** EPOCH : 378/1000 ***/\n",
      "TRAIN - 4449.67529296875, nan\n",
      "TEST - 3663.122314453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4961e-04.\n",
      "/*** EPOCH : 379/1000 ***/\n",
      "TRAIN - 4068.205810546875, nan\n",
      "TEST - 4030.83544921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4886e-04.\n",
      "/*** EPOCH : 380/1000 ***/\n",
      "TRAIN - 4585.8642578125, nan\n",
      "TEST - 4868.693359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4811e-04.\n",
      "/*** EPOCH : 381/1000 ***/\n",
      "TRAIN - 4716.1591796875, nan\n",
      "TEST - 3855.974365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4737e-04.\n",
      "/*** EPOCH : 382/1000 ***/\n",
      "TRAIN - 4086.90234375, nan\n",
      "TEST - 4231.3505859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4664e-04.\n",
      "/*** EPOCH : 383/1000 ***/\n",
      "TRAIN - 4322.77197265625, nan\n",
      "TEST - 3717.81591796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4590e-04.\n",
      "/*** EPOCH : 384/1000 ***/\n",
      "TRAIN - 4850.86669921875, nan\n",
      "TEST - 3754.27783203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4517e-04.\n",
      "/*** EPOCH : 385/1000 ***/\n",
      "TRAIN - 4033.619384765625, nan\n",
      "TEST - 4203.505859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4445e-04.\n",
      "/*** EPOCH : 386/1000 ***/\n",
      "TRAIN - 4473.7822265625, nan\n",
      "TEST - 3848.08154296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4372e-04.\n",
      "/*** EPOCH : 387/1000 ***/\n",
      "TRAIN - 4005.6416015625, nan\n",
      "TEST - 3918.492919921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4301e-04.\n",
      "/*** EPOCH : 388/1000 ***/\n",
      "TRAIN - 4050.6953125, nan\n",
      "TEST - 3720.734130859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4229e-04.\n",
      "/*** EPOCH : 389/1000 ***/\n",
      "TRAIN - 4397.69140625, nan\n",
      "TEST - 3519.041015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4158e-04.\n",
      "/*** EPOCH : 390/1000 ***/\n",
      "TRAIN - 3880.54833984375, nan\n",
      "TEST - 3756.453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4087e-04.\n",
      "/*** EPOCH : 391/1000 ***/\n",
      "TRAIN - 3748.885498046875, nan\n",
      "TEST - 3196.39453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.4017e-04.\n",
      "/*** EPOCH : 392/1000 ***/\n",
      "TRAIN - 3819.475830078125, nan\n",
      "TEST - 3353.1259765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3947e-04.\n",
      "/*** EPOCH : 393/1000 ***/\n",
      "TRAIN - 3978.19384765625, nan\n",
      "TEST - 3945.486572265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3877e-04.\n",
      "/*** EPOCH : 394/1000 ***/\n",
      "TRAIN - 4186.88232421875, nan\n",
      "TEST - 5660.45751953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3808e-04.\n",
      "/*** EPOCH : 395/1000 ***/\n",
      "TRAIN - 4177.10302734375, nan\n",
      "TEST - 3933.605712890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3739e-04.\n",
      "/*** EPOCH : 396/1000 ***/\n",
      "TRAIN - 5181.7724609375, nan\n",
      "TEST - 7470.87255859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3670e-04.\n",
      "/*** EPOCH : 397/1000 ***/\n",
      "TRAIN - 4771.6826171875, nan\n",
      "TEST - 6999.9833984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3601e-04.\n",
      "/*** EPOCH : 398/1000 ***/\n",
      "TRAIN - 4203.2451171875, nan\n",
      "TEST - 3807.51123046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3533e-04.\n",
      "/*** EPOCH : 399/1000 ***/\n",
      "TRAIN - 4121.8056640625, nan\n",
      "TEST - 3281.632080078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3466e-04.\n",
      "/*** EPOCH : 400/1000 ***/\n",
      "TRAIN - 3948.423095703125, nan\n",
      "TEST - 3841.6572265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3398e-04.\n",
      "/*** EPOCH : 401/1000 ***/\n",
      "TRAIN - 4164.810546875, nan\n",
      "TEST - 3496.0458984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3331e-04.\n",
      "/*** EPOCH : 402/1000 ***/\n",
      "TRAIN - 3854.779541015625, nan\n",
      "TEST - 4176.044921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3265e-04.\n",
      "/*** EPOCH : 403/1000 ***/\n",
      "TRAIN - 3992.53515625, nan\n",
      "TEST - 3397.930908203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3199e-04.\n",
      "/*** EPOCH : 404/1000 ***/\n",
      "TRAIN - 4131.14892578125, nan\n",
      "TEST - 6370.16015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3133e-04.\n",
      "/*** EPOCH : 405/1000 ***/\n",
      "TRAIN - 5209.73291015625, nan\n",
      "TEST - 4039.957275390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3067e-04.\n",
      "/*** EPOCH : 406/1000 ***/\n",
      "TRAIN - 4147.13330078125, nan\n",
      "TEST - 3435.223876953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.3002e-04.\n",
      "/*** EPOCH : 407/1000 ***/\n",
      "TRAIN - 3986.311767578125, nan\n",
      "TEST - 4079.424560546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2937e-04.\n",
      "/*** EPOCH : 408/1000 ***/\n",
      "TRAIN - 3882.42724609375, nan\n",
      "TEST - 3295.695068359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2872e-04.\n",
      "/*** EPOCH : 409/1000 ***/\n",
      "TRAIN - 3827.5595703125, nan\n",
      "TEST - 3868.12353515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2807e-04.\n",
      "/*** EPOCH : 410/1000 ***/\n",
      "TRAIN - 4038.206298828125, nan\n",
      "TEST - 4119.34814453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2743e-04.\n",
      "/*** EPOCH : 411/1000 ***/\n",
      "TRAIN - 4383.54345703125, nan\n",
      "TEST - 4218.02978515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2680e-04.\n",
      "/*** EPOCH : 412/1000 ***/\n",
      "TRAIN - 4012.755126953125, nan\n",
      "TEST - 3978.223876953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2616e-04.\n",
      "/*** EPOCH : 413/1000 ***/\n",
      "TRAIN - 4123.5712890625, nan\n",
      "TEST - 3250.309326171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2553e-04.\n",
      "/*** EPOCH : 414/1000 ***/\n",
      "TRAIN - 3770.7001953125, nan\n",
      "TEST - 3762.93603515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2490e-04.\n",
      "/*** EPOCH : 415/1000 ***/\n",
      "TRAIN - 4001.564453125, nan\n",
      "TEST - 4080.078369140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2428e-04.\n",
      "/*** EPOCH : 416/1000 ***/\n",
      "TRAIN - 3921.88623046875, nan\n",
      "TEST - 3960.32275390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2366e-04.\n",
      "/*** EPOCH : 417/1000 ***/\n",
      "TRAIN - 3905.632080078125, nan\n",
      "TEST - 3539.880126953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2304e-04.\n",
      "/*** EPOCH : 418/1000 ***/\n",
      "TRAIN - 3737.343017578125, nan\n",
      "TEST - 3440.008544921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2243e-04.\n",
      "/*** EPOCH : 419/1000 ***/\n",
      "TRAIN - 4057.197509765625, nan\n",
      "TEST - 3496.9287109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2181e-04.\n",
      "/*** EPOCH : 420/1000 ***/\n",
      "TRAIN - 3926.75048828125, nan\n",
      "TEST - 3498.40087890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2120e-04.\n",
      "/*** EPOCH : 421/1000 ***/\n",
      "TRAIN - 4240.60498046875, nan\n",
      "TEST - 3789.282470703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2060e-04.\n",
      "/*** EPOCH : 422/1000 ***/\n",
      "TRAIN - 3892.353271484375, nan\n",
      "TEST - 3736.319091796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.2000e-04.\n",
      "/*** EPOCH : 423/1000 ***/\n",
      "TRAIN - 3660.191162109375, nan\n",
      "TEST - 3385.580322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1940e-04.\n",
      "/*** EPOCH : 424/1000 ***/\n",
      "TRAIN - 3827.720458984375, nan\n",
      "TEST - 3303.637451171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1880e-04.\n",
      "/*** EPOCH : 425/1000 ***/\n",
      "TRAIN - 3770.61572265625, nan\n",
      "TEST - 3202.348876953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1820e-04.\n",
      "/*** EPOCH : 426/1000 ***/\n",
      "TRAIN - 3822.560302734375, nan\n",
      "TEST - 3341.534423828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1761e-04.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*** EPOCH : 427/1000 ***/\n",
      "TRAIN - 3648.376953125, nan\n",
      "TEST - 3268.657958984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1702e-04.\n",
      "/*** EPOCH : 428/1000 ***/\n",
      "TRAIN - 3762.812255859375, nan\n",
      "TEST - 3690.646484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1644e-04.\n",
      "/*** EPOCH : 429/1000 ***/\n",
      "TRAIN - 3832.865234375, nan\n",
      "TEST - 3361.31689453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1586e-04.\n",
      "/*** EPOCH : 430/1000 ***/\n",
      "TRAIN - 3587.15966796875, nan\n",
      "TEST - 3139.538330078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1528e-04.\n",
      "/*** EPOCH : 431/1000 ***/\n",
      "TRAIN - 3736.987548828125, nan\n",
      "TEST - 3451.779541015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1470e-04.\n",
      "/*** EPOCH : 432/1000 ***/\n",
      "TRAIN - 3833.44189453125, nan\n",
      "TEST - 3384.043701171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1413e-04.\n",
      "/*** EPOCH : 433/1000 ***/\n",
      "TRAIN - 3710.341064453125, nan\n",
      "TEST - 3193.86962890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1356e-04.\n",
      "/*** EPOCH : 434/1000 ***/\n",
      "TRAIN - 242114352.0, nan\n",
      "TEST - 146931696.0, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1299e-04.\n",
      "/*** EPOCH : 435/1000 ***/\n",
      "TRAIN - 11553602.0, nan\n",
      "TEST - 54220.35546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1243e-04.\n",
      "/*** EPOCH : 436/1000 ***/\n",
      "TRAIN - 21111.251953125, nan\n",
      "TEST - 9052.802734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1186e-04.\n",
      "/*** EPOCH : 437/1000 ***/\n",
      "TRAIN - 6987.44140625, nan\n",
      "TEST - 4956.2431640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1130e-04.\n",
      "/*** EPOCH : 438/1000 ***/\n",
      "TRAIN - 4863.98779296875, nan\n",
      "TEST - 4189.38427734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1075e-04.\n",
      "/*** EPOCH : 439/1000 ***/\n",
      "TRAIN - 4238.130859375, nan\n",
      "TEST - 3897.52978515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.1019e-04.\n",
      "/*** EPOCH : 440/1000 ***/\n",
      "TRAIN - 4036.600830078125, nan\n",
      "TEST - 3805.342529296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0964e-04.\n",
      "/*** EPOCH : 441/1000 ***/\n",
      "TRAIN - 4076.690185546875, nan\n",
      "TEST - 3658.442626953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0909e-04.\n",
      "/*** EPOCH : 442/1000 ***/\n",
      "TRAIN - 4077.223388671875, nan\n",
      "TEST - 3846.2138671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0855e-04.\n",
      "/*** EPOCH : 443/1000 ***/\n",
      "TRAIN - 4229.43896484375, nan\n",
      "TEST - 3704.090576171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0801e-04.\n",
      "/*** EPOCH : 444/1000 ***/\n",
      "TRAIN - 4156.07861328125, nan\n",
      "TEST - 3871.520263671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0747e-04.\n",
      "/*** EPOCH : 445/1000 ***/\n",
      "TRAIN - 4188.779296875, nan\n",
      "TEST - 3809.7265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0693e-04.\n",
      "/*** EPOCH : 446/1000 ***/\n",
      "TRAIN - 4157.7841796875, nan\n",
      "TEST - 3707.02734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0639e-04.\n",
      "/*** EPOCH : 447/1000 ***/\n",
      "TRAIN - 4166.72314453125, nan\n",
      "TEST - 3639.526611328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0586e-04.\n",
      "/*** EPOCH : 448/1000 ***/\n",
      "TRAIN - 4066.60595703125, nan\n",
      "TEST - 3822.10498046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0533e-04.\n",
      "/*** EPOCH : 449/1000 ***/\n",
      "TRAIN - 3935.384521484375, nan\n",
      "TEST - 4009.061767578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0481e-04.\n",
      "/*** EPOCH : 450/1000 ***/\n",
      "TRAIN - 4018.20458984375, nan\n",
      "TEST - 4148.32373046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0428e-04.\n",
      "/*** EPOCH : 451/1000 ***/\n",
      "TRAIN - 4033.944580078125, nan\n",
      "TEST - 3954.185546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0376e-04.\n",
      "/*** EPOCH : 452/1000 ***/\n",
      "TRAIN - 3947.91064453125, nan\n",
      "TEST - 3731.961181640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0324e-04.\n",
      "/*** EPOCH : 453/1000 ***/\n",
      "TRAIN - 3887.33642578125, nan\n",
      "TEST - 3945.78515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0273e-04.\n",
      "/*** EPOCH : 454/1000 ***/\n",
      "TRAIN - 4109.44775390625, nan\n",
      "TEST - 3572.287353515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0221e-04.\n",
      "/*** EPOCH : 455/1000 ***/\n",
      "TRAIN - 3926.845703125, nan\n",
      "TEST - 3730.583740234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0170e-04.\n",
      "/*** EPOCH : 456/1000 ***/\n",
      "TRAIN - 4153.3427734375, nan\n",
      "TEST - 3908.91845703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0119e-04.\n",
      "/*** EPOCH : 457/1000 ***/\n",
      "TRAIN - 4085.6513671875, nan\n",
      "TEST - 4845.9140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0069e-04.\n",
      "/*** EPOCH : 458/1000 ***/\n",
      "TRAIN - 4416.88037109375, nan\n",
      "TEST - 3911.009521484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 1.0018e-04.\n",
      "/*** EPOCH : 459/1000 ***/\n",
      "TRAIN - 3978.74169921875, nan\n",
      "TEST - 3719.81005859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9682e-05.\n",
      "/*** EPOCH : 460/1000 ***/\n",
      "TRAIN - 4146.16455078125, nan\n",
      "TEST - 3623.175048828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.9184e-05.\n",
      "/*** EPOCH : 461/1000 ***/\n",
      "TRAIN - 3925.00341796875, nan\n",
      "TEST - 3665.385986328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8688e-05.\n",
      "/*** EPOCH : 462/1000 ***/\n",
      "TRAIN - 4017.69580078125, nan\n",
      "TEST - 3580.583740234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.8194e-05.\n",
      "/*** EPOCH : 463/1000 ***/\n",
      "TRAIN - 3980.81591796875, nan\n",
      "TEST - 3900.961181640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.7703e-05.\n",
      "/*** EPOCH : 464/1000 ***/\n",
      "TRAIN - 3955.978759765625, nan\n",
      "TEST - 3595.20458984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.7215e-05.\n",
      "/*** EPOCH : 465/1000 ***/\n",
      "TRAIN - 4089.74609375, nan\n",
      "TEST - 3599.655029296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.6729e-05.\n",
      "/*** EPOCH : 466/1000 ***/\n",
      "TRAIN - 4093.183349609375, nan\n",
      "TEST - 3694.14892578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.6245e-05.\n",
      "/*** EPOCH : 467/1000 ***/\n",
      "TRAIN - 3952.487548828125, nan\n",
      "TEST - 4461.185546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5764e-05.\n",
      "/*** EPOCH : 468/1000 ***/\n",
      "TRAIN - 3978.923095703125, nan\n",
      "TEST - 3492.705322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.5285e-05.\n",
      "/*** EPOCH : 469/1000 ***/\n",
      "TRAIN - 4074.903076171875, nan\n",
      "TEST - 3541.62548828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.4809e-05.\n",
      "/*** EPOCH : 470/1000 ***/\n",
      "TRAIN - 3874.460693359375, nan\n",
      "TEST - 3594.690185546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.4335e-05.\n",
      "/*** EPOCH : 471/1000 ***/\n",
      "TRAIN - 3822.76611328125, nan\n",
      "TEST - 3637.218017578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3863e-05.\n",
      "/*** EPOCH : 472/1000 ***/\n",
      "TRAIN - 4116.1982421875, nan\n",
      "TEST - 4320.42822265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.3394e-05.\n",
      "/*** EPOCH : 473/1000 ***/\n",
      "TRAIN - 3801.0087890625, nan\n",
      "TEST - 3958.998779296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.2927e-05.\n",
      "/*** EPOCH : 474/1000 ***/\n",
      "TRAIN - 3997.40673828125, nan\n",
      "TEST - 3463.2197265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.2462e-05.\n",
      "/*** EPOCH : 475/1000 ***/\n",
      "TRAIN - 4172.00048828125, nan\n",
      "TEST - 4390.17431640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.2000e-05.\n",
      "/*** EPOCH : 476/1000 ***/\n",
      "TRAIN - 4095.184326171875, nan\n",
      "TEST - 3599.168701171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.1540e-05.\n",
      "/*** EPOCH : 477/1000 ***/\n",
      "TRAIN - 3843.091064453125, nan\n",
      "TEST - 3821.949951171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.1082e-05.\n",
      "/*** EPOCH : 478/1000 ***/\n",
      "TRAIN - 4014.2255859375, nan\n",
      "TEST - 4231.603515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0627e-05.\n",
      "/*** EPOCH : 479/1000 ***/\n",
      "TRAIN - 3984.261474609375, nan\n",
      "TEST - 3746.94580078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 9.0173e-05.\n",
      "/*** EPOCH : 480/1000 ***/\n",
      "TRAIN - 4151.83349609375, nan\n",
      "TEST - 3579.33837890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.9723e-05.\n",
      "/*** EPOCH : 481/1000 ***/\n",
      "TRAIN - 4026.981689453125, nan\n",
      "TEST - 3933.72265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.9274e-05.\n",
      "/*** EPOCH : 482/1000 ***/\n",
      "TRAIN - 3943.737548828125, nan\n",
      "TEST - 3487.766845703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.8828e-05.\n",
      "/*** EPOCH : 483/1000 ***/\n",
      "TRAIN - 4047.53466796875, nan\n",
      "TEST - 3592.373779296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.8383e-05.\n",
      "/*** EPOCH : 484/1000 ***/\n",
      "TRAIN - 4044.444091796875, nan\n",
      "TEST - 3610.8505859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7942e-05.\n",
      "/*** EPOCH : 485/1000 ***/\n",
      "TRAIN - 4148.21240234375, nan\n",
      "TEST - 3835.67138671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7502e-05.\n",
      "/*** EPOCH : 486/1000 ***/\n",
      "TRAIN - 4052.050537109375, nan\n",
      "TEST - 4040.016845703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.7064e-05.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/*** EPOCH : 487/1000 ***/\n",
      "TRAIN - 4163.07373046875, nan\n",
      "TEST - 4004.947265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.6629e-05.\n",
      "/*** EPOCH : 488/1000 ***/\n",
      "TRAIN - 4651.58984375, nan\n",
      "TEST - 4265.2294921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.6196e-05.\n",
      "/*** EPOCH : 489/1000 ***/\n",
      "TRAIN - 4176.65478515625, nan\n",
      "TEST - 3661.3564453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5765e-05.\n",
      "/*** EPOCH : 490/1000 ***/\n",
      "TRAIN - 4042.6474609375, nan\n",
      "TEST - 3903.298095703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.5336e-05.\n",
      "/*** EPOCH : 491/1000 ***/\n",
      "TRAIN - 3932.77392578125, nan\n",
      "TEST - 3670.807861328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4909e-05.\n",
      "/*** EPOCH : 492/1000 ***/\n",
      "TRAIN - 4349.5341796875, nan\n",
      "TEST - 3535.700439453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4485e-05.\n",
      "/*** EPOCH : 493/1000 ***/\n",
      "TRAIN - 4126.47119140625, nan\n",
      "TEST - 4156.2431640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.4062e-05.\n",
      "/*** EPOCH : 494/1000 ***/\n",
      "TRAIN - 4155.69189453125, nan\n",
      "TEST - 4129.80419921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.3642e-05.\n",
      "/*** EPOCH : 495/1000 ***/\n",
      "TRAIN - 4306.7119140625, nan\n",
      "TEST - 5741.96923828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.3224e-05.\n",
      "/*** EPOCH : 496/1000 ***/\n",
      "TRAIN - 4361.53857421875, nan\n",
      "TEST - 5700.107421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.2808e-05.\n",
      "/*** EPOCH : 497/1000 ***/\n",
      "TRAIN - 4954.2626953125, nan\n",
      "TEST - 3818.300537109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.2394e-05.\n",
      "/*** EPOCH : 498/1000 ***/\n",
      "TRAIN - 4354.08447265625, nan\n",
      "TEST - 4146.7529296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1982e-05.\n",
      "/*** EPOCH : 499/1000 ***/\n",
      "TRAIN - 4499.1826171875, nan\n",
      "TEST - 3961.95751953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1572e-05.\n",
      "/*** EPOCH : 500/1000 ***/\n",
      "TRAIN - 4828.38427734375, nan\n",
      "TEST - 5638.3251953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.1164e-05.\n",
      "/*** EPOCH : 501/1000 ***/\n",
      "TRAIN - 5214.31201171875, nan\n",
      "TEST - 3497.377685546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.0758e-05.\n",
      "/*** EPOCH : 502/1000 ***/\n",
      "TRAIN - 4178.6689453125, nan\n",
      "TEST - 3983.58251953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 8.0354e-05.\n",
      "/*** EPOCH : 503/1000 ***/\n",
      "TRAIN - 4524.90380859375, nan\n",
      "TEST - 3752.72265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9953e-05.\n",
      "/*** EPOCH : 504/1000 ***/\n",
      "TRAIN - 4502.70703125, nan\n",
      "TEST - 3976.546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9553e-05.\n",
      "/*** EPOCH : 505/1000 ***/\n",
      "TRAIN - 4669.35693359375, nan\n",
      "TEST - 4188.56591796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.9155e-05.\n",
      "/*** EPOCH : 506/1000 ***/\n",
      "TRAIN - 4182.37939453125, nan\n",
      "TEST - 3457.64111328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8759e-05.\n",
      "/*** EPOCH : 507/1000 ***/\n",
      "TRAIN - 4290.37451171875, nan\n",
      "TEST - 4294.87890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.8366e-05.\n",
      "/*** EPOCH : 508/1000 ***/\n",
      "TRAIN - 4613.5888671875, nan\n",
      "TEST - 4061.166015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7974e-05.\n",
      "/*** EPOCH : 509/1000 ***/\n",
      "TRAIN - 4652.9794921875, nan\n",
      "TEST - 3618.677978515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7584e-05.\n",
      "/*** EPOCH : 510/1000 ***/\n",
      "TRAIN - 4672.2734375, nan\n",
      "TEST - 5014.61279296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.7196e-05.\n",
      "/*** EPOCH : 511/1000 ***/\n",
      "TRAIN - 4735.89111328125, nan\n",
      "TEST - 3777.2939453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6810e-05.\n",
      "/*** EPOCH : 512/1000 ***/\n",
      "TRAIN - 5127.646484375, nan\n",
      "TEST - 4384.8330078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6426e-05.\n",
      "/*** EPOCH : 513/1000 ***/\n",
      "TRAIN - 6267.390625, nan\n",
      "TEST - 3414.168212890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.6044e-05.\n",
      "/*** EPOCH : 514/1000 ***/\n",
      "TRAIN - 4317.99853515625, nan\n",
      "TEST - 3604.859619140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.5664e-05.\n",
      "/*** EPOCH : 515/1000 ***/\n",
      "TRAIN - 5311.7421875, nan\n",
      "TEST - 4300.080078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.5285e-05.\n",
      "/*** EPOCH : 516/1000 ***/\n",
      "TRAIN - 4701.7255859375, nan\n",
      "TEST - 5634.74365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4909e-05.\n",
      "/*** EPOCH : 517/1000 ***/\n",
      "TRAIN - 4661.70556640625, nan\n",
      "TEST - 3599.59423828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4534e-05.\n",
      "/*** EPOCH : 518/1000 ***/\n",
      "TRAIN - 4427.9482421875, nan\n",
      "TEST - 3761.983642578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.4162e-05.\n",
      "/*** EPOCH : 519/1000 ***/\n",
      "TRAIN - 4920.5810546875, nan\n",
      "TEST - 4218.2255859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3791e-05.\n",
      "/*** EPOCH : 520/1000 ***/\n",
      "TRAIN - 4303.13330078125, nan\n",
      "TEST - 4523.41357421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3422e-05.\n",
      "/*** EPOCH : 521/1000 ***/\n",
      "TRAIN - 5574.2783203125, nan\n",
      "TEST - 4286.43017578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.3055e-05.\n",
      "/*** EPOCH : 522/1000 ***/\n",
      "TRAIN - 5293.0546875, nan\n",
      "TEST - 4862.87841796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.2689e-05.\n",
      "/*** EPOCH : 523/1000 ***/\n",
      "TRAIN - 5174.3515625, nan\n",
      "TEST - 4575.0771484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.2326e-05.\n",
      "/*** EPOCH : 524/1000 ***/\n",
      "TRAIN - 4436.22216796875, nan\n",
      "TEST - 3709.478515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1964e-05.\n",
      "/*** EPOCH : 525/1000 ***/\n",
      "TRAIN - 4209.12841796875, nan\n",
      "TEST - 3942.23046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1605e-05.\n",
      "/*** EPOCH : 526/1000 ***/\n",
      "TRAIN - 4576.59765625, nan\n",
      "TEST - 4561.740234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.1247e-05.\n",
      "/*** EPOCH : 527/1000 ***/\n",
      "TRAIN - 5260.25390625, nan\n",
      "TEST - 4772.6796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0890e-05.\n",
      "/*** EPOCH : 528/1000 ***/\n",
      "TRAIN - 4869.54638671875, nan\n",
      "TEST - 3600.82470703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0536e-05.\n",
      "/*** EPOCH : 529/1000 ***/\n",
      "TRAIN - 5548.69482421875, nan\n",
      "TEST - 4814.833984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 7.0183e-05.\n",
      "/*** EPOCH : 530/1000 ***/\n",
      "TRAIN - 4888.75537109375, nan\n",
      "TEST - 4202.60400390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9832e-05.\n",
      "/*** EPOCH : 531/1000 ***/\n",
      "TRAIN - 4900.8974609375, nan\n",
      "TEST - 3854.36767578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9483e-05.\n",
      "/*** EPOCH : 532/1000 ***/\n",
      "TRAIN - 4501.53271484375, nan\n",
      "TEST - 4467.46435546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.9136e-05.\n",
      "/*** EPOCH : 533/1000 ***/\n",
      "TRAIN - 5602.49853515625, nan\n",
      "TEST - 3663.841796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.8790e-05.\n",
      "/*** EPOCH : 534/1000 ***/\n",
      "TRAIN - 4969.1826171875, nan\n",
      "TEST - 5845.08740234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.8446e-05.\n",
      "/*** EPOCH : 535/1000 ***/\n",
      "TRAIN - 5530.55908203125, nan\n",
      "TEST - 3996.20068359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.8104e-05.\n",
      "/*** EPOCH : 536/1000 ***/\n",
      "TRAIN - 4771.79345703125, nan\n",
      "TEST - 6086.67041015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7763e-05.\n",
      "/*** EPOCH : 537/1000 ***/\n",
      "TRAIN - 5436.98876953125, nan\n",
      "TEST - 3530.771728515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7424e-05.\n",
      "/*** EPOCH : 538/1000 ***/\n",
      "TRAIN - 4658.17822265625, nan\n",
      "TEST - 4297.00537109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.7087e-05.\n",
      "/*** EPOCH : 539/1000 ***/\n",
      "TRAIN - 4426.5908203125, nan\n",
      "TEST - 4248.74365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6752e-05.\n",
      "/*** EPOCH : 540/1000 ***/\n",
      "TRAIN - 4638.515625, nan\n",
      "TEST - 4128.0244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6418e-05.\n",
      "/*** EPOCH : 541/1000 ***/\n",
      "TRAIN - 4948.98583984375, nan\n",
      "TEST - 4580.37646484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.6086e-05.\n",
      "/*** EPOCH : 542/1000 ***/\n",
      "TRAIN - 5004.158203125, nan\n",
      "TEST - 4402.00390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5756e-05.\n",
      "/*** EPOCH : 543/1000 ***/\n",
      "TRAIN - 4466.1611328125, nan\n",
      "TEST - 5653.7275390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5427e-05.\n",
      "/*** EPOCH : 544/1000 ***/\n",
      "TRAIN - 5201.69775390625, nan\n",
      "TEST - 4642.80322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.5100e-05.\n",
      "/*** EPOCH : 545/1000 ***/\n",
      "TRAIN - 5301.43603515625, nan\n",
      "TEST - 4358.61962890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.4774e-05.\n",
      "/*** EPOCH : 546/1000 ***/\n",
      "TRAIN - 5882.705078125, nan\n",
      "TEST - 4123.43310546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.4450e-05.\n",
      "/*** EPOCH : 547/1000 ***/\n",
      "TRAIN - 4925.05078125, nan\n",
      "TEST - 6086.6708984375, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 6.4128e-05.\n",
      "/*** EPOCH : 548/1000 ***/\n",
      "TRAIN - 4971.24951171875, nan\n",
      "TEST - 4447.13623046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3807e-05.\n",
      "/*** EPOCH : 549/1000 ***/\n",
      "TRAIN - 5020.53125, nan\n",
      "TEST - 4435.2685546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3488e-05.\n",
      "/*** EPOCH : 550/1000 ***/\n",
      "TRAIN - 5109.4814453125, nan\n",
      "TEST - 5052.55517578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.3171e-05.\n",
      "/*** EPOCH : 551/1000 ***/\n",
      "TRAIN - 5713.83740234375, nan\n",
      "TEST - 3338.558837890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2855e-05.\n",
      "/*** EPOCH : 552/1000 ***/\n",
      "TRAIN - 4743.51318359375, nan\n",
      "TEST - 3900.708740234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2541e-05.\n",
      "/*** EPOCH : 553/1000 ***/\n",
      "TRAIN - 4673.341796875, nan\n",
      "TEST - 5354.322265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.2228e-05.\n",
      "/*** EPOCH : 554/1000 ***/\n",
      "TRAIN - 4574.2255859375, nan\n",
      "TEST - 3418.257568359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.1917e-05.\n",
      "/*** EPOCH : 555/1000 ***/\n",
      "TRAIN - 4110.75244140625, nan\n",
      "TEST - 3728.107666015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.1607e-05.\n",
      "/*** EPOCH : 556/1000 ***/\n",
      "TRAIN - 4341.830078125, nan\n",
      "TEST - 3273.220703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.1299e-05.\n",
      "/*** EPOCH : 557/1000 ***/\n",
      "TRAIN - 4329.43994140625, nan\n",
      "TEST - 3877.727783203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0993e-05.\n",
      "/*** EPOCH : 558/1000 ***/\n",
      "TRAIN - 4502.8037109375, nan\n",
      "TEST - 4359.32861328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0688e-05.\n",
      "/*** EPOCH : 559/1000 ***/\n",
      "TRAIN - 4860.7529296875, nan\n",
      "TEST - 4062.94970703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0384e-05.\n",
      "/*** EPOCH : 560/1000 ***/\n",
      "TRAIN - 4444.6669921875, nan\n",
      "TEST - 4294.75048828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 6.0083e-05.\n",
      "/*** EPOCH : 561/1000 ***/\n",
      "TRAIN - 4530.369140625, nan\n",
      "TEST - 4471.1787109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9782e-05.\n",
      "/*** EPOCH : 562/1000 ***/\n",
      "TRAIN - 4779.36767578125, nan\n",
      "TEST - 4628.4580078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9483e-05.\n",
      "/*** EPOCH : 563/1000 ***/\n",
      "TRAIN - 4692.24853515625, nan\n",
      "TEST - 4423.078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.9186e-05.\n",
      "/*** EPOCH : 564/1000 ***/\n",
      "TRAIN - 5168.82763671875, nan\n",
      "TEST - 6797.0244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8890e-05.\n",
      "/*** EPOCH : 565/1000 ***/\n",
      "TRAIN - 5328.1162109375, nan\n",
      "TEST - 6782.11328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8595e-05.\n",
      "/*** EPOCH : 566/1000 ***/\n",
      "TRAIN - 4156.1640625, nan\n",
      "TEST - 3320.799072265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8302e-05.\n",
      "/*** EPOCH : 567/1000 ***/\n",
      "TRAIN - 4688.71044921875, nan\n",
      "TEST - 4008.79443359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.8011e-05.\n",
      "/*** EPOCH : 568/1000 ***/\n",
      "TRAIN - 4694.96142578125, nan\n",
      "TEST - 3421.56396484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7721e-05.\n",
      "/*** EPOCH : 569/1000 ***/\n",
      "TRAIN - 4140.9677734375, nan\n",
      "TEST - 4088.12646484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7432e-05.\n",
      "/*** EPOCH : 570/1000 ***/\n",
      "TRAIN - 4219.52734375, nan\n",
      "TEST - 6235.75244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.7145e-05.\n",
      "/*** EPOCH : 571/1000 ***/\n",
      "TRAIN - 4454.14794921875, nan\n",
      "TEST - 3757.84375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6859e-05.\n",
      "/*** EPOCH : 572/1000 ***/\n",
      "TRAIN - 4384.3056640625, nan\n",
      "TEST - 4276.75244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6575e-05.\n",
      "/*** EPOCH : 573/1000 ***/\n",
      "TRAIN - 4365.09814453125, nan\n",
      "TEST - 4980.2578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6292e-05.\n",
      "/*** EPOCH : 574/1000 ***/\n",
      "TRAIN - 4838.75048828125, nan\n",
      "TEST - 4473.22216796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.6011e-05.\n",
      "/*** EPOCH : 575/1000 ***/\n",
      "TRAIN - 4582.80615234375, nan\n",
      "TEST - 4723.458984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5731e-05.\n",
      "/*** EPOCH : 576/1000 ***/\n",
      "TRAIN - 4476.046875, nan\n",
      "TEST - 3444.743408203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5452e-05.\n",
      "/*** EPOCH : 577/1000 ***/\n",
      "TRAIN - 4214.41357421875, nan\n",
      "TEST - 4126.10693359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.5175e-05.\n",
      "/*** EPOCH : 578/1000 ***/\n",
      "TRAIN - 4330.59716796875, nan\n",
      "TEST - 3623.64892578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4899e-05.\n",
      "/*** EPOCH : 579/1000 ***/\n",
      "TRAIN - 4153.3134765625, nan\n",
      "TEST - 4507.96337890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4624e-05.\n",
      "/*** EPOCH : 580/1000 ***/\n",
      "TRAIN - 4404.626953125, nan\n",
      "TEST - 4770.70703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4351e-05.\n",
      "/*** EPOCH : 581/1000 ***/\n",
      "TRAIN - 4371.8505859375, nan\n",
      "TEST - 4865.873046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.4080e-05.\n",
      "/*** EPOCH : 582/1000 ***/\n",
      "TRAIN - 4712.630859375, nan\n",
      "TEST - 4262.51123046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3809e-05.\n",
      "/*** EPOCH : 583/1000 ***/\n",
      "TRAIN - 4479.32080078125, nan\n",
      "TEST - 4258.23486328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3540e-05.\n",
      "/*** EPOCH : 584/1000 ***/\n",
      "TRAIN - 4560.90185546875, nan\n",
      "TEST - 4793.455078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3272e-05.\n",
      "/*** EPOCH : 585/1000 ***/\n",
      "TRAIN - 4377.162109375, nan\n",
      "TEST - 4979.62890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.3006e-05.\n",
      "/*** EPOCH : 586/1000 ***/\n",
      "TRAIN - 4348.91455078125, nan\n",
      "TEST - 4884.5341796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2741e-05.\n",
      "/*** EPOCH : 587/1000 ***/\n",
      "TRAIN - 4557.380859375, nan\n",
      "TEST - 5075.26611328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2477e-05.\n",
      "/*** EPOCH : 588/1000 ***/\n",
      "TRAIN - 4749.23974609375, nan\n",
      "TEST - 3622.955078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.2215e-05.\n",
      "/*** EPOCH : 589/1000 ***/\n",
      "TRAIN - 4677.36865234375, nan\n",
      "TEST - 4576.3447265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1954e-05.\n",
      "/*** EPOCH : 590/1000 ***/\n",
      "TRAIN - 4636.18115234375, nan\n",
      "TEST - 4914.36767578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1694e-05.\n",
      "/*** EPOCH : 591/1000 ***/\n",
      "TRAIN - 4390.220703125, nan\n",
      "TEST - 3655.301513671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1436e-05.\n",
      "/*** EPOCH : 592/1000 ***/\n",
      "TRAIN - 4265.43359375, nan\n",
      "TEST - 4117.60546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.1178e-05.\n",
      "/*** EPOCH : 593/1000 ***/\n",
      "TRAIN - 4679.6875, nan\n",
      "TEST - 3749.71728515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0923e-05.\n",
      "/*** EPOCH : 594/1000 ***/\n",
      "TRAIN - 4709.64990234375, nan\n",
      "TEST - 5220.3056640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0668e-05.\n",
      "/*** EPOCH : 595/1000 ***/\n",
      "TRAIN - 4579.75146484375, nan\n",
      "TEST - 5533.54931640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0415e-05.\n",
      "/*** EPOCH : 596/1000 ***/\n",
      "TRAIN - 4726.92822265625, nan\n",
      "TEST - 4049.786376953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 5.0163e-05.\n",
      "/*** EPOCH : 597/1000 ***/\n",
      "TRAIN - 4190.72509765625, nan\n",
      "TEST - 3582.944580078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9912e-05.\n",
      "/*** EPOCH : 598/1000 ***/\n",
      "TRAIN - 4759.96044921875, nan\n",
      "TEST - 4201.4267578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9662e-05.\n",
      "/*** EPOCH : 599/1000 ***/\n",
      "TRAIN - 4714.5361328125, nan\n",
      "TEST - 4166.97802734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9414e-05.\n",
      "/*** EPOCH : 600/1000 ***/\n",
      "TRAIN - 4396.73291015625, nan\n",
      "TEST - 3275.499267578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.9167e-05.\n",
      "/*** EPOCH : 601/1000 ***/\n",
      "TRAIN - 4202.978515625, nan\n",
      "TEST - 4769.302734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8921e-05.\n",
      "/*** EPOCH : 602/1000 ***/\n",
      "TRAIN - 4325.3896484375, nan\n",
      "TEST - 3676.494140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8676e-05.\n",
      "/*** EPOCH : 603/1000 ***/\n",
      "TRAIN - 4446.72705078125, nan\n",
      "TEST - 4540.9375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8433e-05.\n",
      "/*** EPOCH : 604/1000 ***/\n",
      "TRAIN - 4299.498046875, nan\n",
      "TEST - 3816.26513671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.8191e-05.\n",
      "/*** EPOCH : 605/1000 ***/\n",
      "TRAIN - 4288.40771484375, nan\n",
      "TEST - 3882.21630859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7950e-05.\n",
      "/*** EPOCH : 606/1000 ***/\n",
      "TRAIN - 4443.69775390625, nan\n",
      "TEST - 3720.5673828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7710e-05.\n",
      "/*** EPOCH : 607/1000 ***/\n",
      "TRAIN - 4478.7841796875, nan\n",
      "TEST - 3671.451904296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.7472e-05.\n",
      "/*** EPOCH : 608/1000 ***/\n",
      "TRAIN - 3903.814453125, nan\n",
      "TEST - 3942.47265625, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 4.7234e-05.\n",
      "/*** EPOCH : 609/1000 ***/\n",
      "TRAIN - 4229.3076171875, nan\n",
      "TEST - 6198.2607421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6998e-05.\n",
      "/*** EPOCH : 610/1000 ***/\n",
      "TRAIN - 5274.68505859375, nan\n",
      "TEST - 4557.3876953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6763e-05.\n",
      "/*** EPOCH : 611/1000 ***/\n",
      "TRAIN - 4770.66796875, nan\n",
      "TEST - 3700.466796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6529e-05.\n",
      "/*** EPOCH : 612/1000 ***/\n",
      "TRAIN - 4233.67431640625, nan\n",
      "TEST - 4236.296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6297e-05.\n",
      "/*** EPOCH : 613/1000 ***/\n",
      "TRAIN - 4389.77685546875, nan\n",
      "TEST - 3672.994140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.6065e-05.\n",
      "/*** EPOCH : 614/1000 ***/\n",
      "TRAIN - 4293.82421875, nan\n",
      "TEST - 3735.795654296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5835e-05.\n",
      "/*** EPOCH : 615/1000 ***/\n",
      "TRAIN - 3991.078369140625, nan\n",
      "TEST - 3710.95263671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5606e-05.\n",
      "/*** EPOCH : 616/1000 ***/\n",
      "TRAIN - 4163.3017578125, nan\n",
      "TEST - 3472.107421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5378e-05.\n",
      "/*** EPOCH : 617/1000 ***/\n",
      "TRAIN - 4415.89208984375, nan\n",
      "TEST - 3734.524658203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.5151e-05.\n",
      "/*** EPOCH : 618/1000 ***/\n",
      "TRAIN - 4337.5810546875, nan\n",
      "TEST - 4765.89697265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4925e-05.\n",
      "/*** EPOCH : 619/1000 ***/\n",
      "TRAIN - 4398.72021484375, nan\n",
      "TEST - 3590.0244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4700e-05.\n",
      "/*** EPOCH : 620/1000 ***/\n",
      "TRAIN - 4223.41064453125, nan\n",
      "TEST - 3380.53857421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4477e-05.\n",
      "/*** EPOCH : 621/1000 ***/\n",
      "TRAIN - 3991.647216796875, nan\n",
      "TEST - 3418.10400390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4254e-05.\n",
      "/*** EPOCH : 622/1000 ***/\n",
      "TRAIN - 3942.294189453125, nan\n",
      "TEST - 4232.45263671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.4033e-05.\n",
      "/*** EPOCH : 623/1000 ***/\n",
      "TRAIN - 3977.820556640625, nan\n",
      "TEST - 3426.53076171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3813e-05.\n",
      "/*** EPOCH : 624/1000 ***/\n",
      "TRAIN - 3855.315185546875, nan\n",
      "TEST - 4473.4482421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3594e-05.\n",
      "/*** EPOCH : 625/1000 ***/\n",
      "TRAIN - 4080.710205078125, nan\n",
      "TEST - 4480.60498046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3376e-05.\n",
      "/*** EPOCH : 626/1000 ***/\n",
      "TRAIN - 4160.31103515625, nan\n",
      "TEST - 4211.80615234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.3159e-05.\n",
      "/*** EPOCH : 627/1000 ***/\n",
      "TRAIN - 4157.650390625, nan\n",
      "TEST - 3525.08349609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2943e-05.\n",
      "/*** EPOCH : 628/1000 ***/\n",
      "TRAIN - 3869.62646484375, nan\n",
      "TEST - 3622.2255859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2729e-05.\n",
      "/*** EPOCH : 629/1000 ***/\n",
      "TRAIN - 3740.30322265625, nan\n",
      "TEST - 3783.623291015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2515e-05.\n",
      "/*** EPOCH : 630/1000 ***/\n",
      "TRAIN - 3757.6708984375, nan\n",
      "TEST - 3879.763916015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2302e-05.\n",
      "/*** EPOCH : 631/1000 ***/\n",
      "TRAIN - 3858.023681640625, nan\n",
      "TEST - 4412.81103515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.2091e-05.\n",
      "/*** EPOCH : 632/1000 ***/\n",
      "TRAIN - 3932.054443359375, nan\n",
      "TEST - 4083.655517578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1880e-05.\n",
      "/*** EPOCH : 633/1000 ***/\n",
      "TRAIN - 3653.174560546875, nan\n",
      "TEST - 3199.384033203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1671e-05.\n",
      "/*** EPOCH : 634/1000 ***/\n",
      "TRAIN - 3859.873779296875, nan\n",
      "TEST - 4907.8125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1463e-05.\n",
      "/*** EPOCH : 635/1000 ***/\n",
      "TRAIN - 3825.283203125, nan\n",
      "TEST - 3158.92919921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1255e-05.\n",
      "/*** EPOCH : 636/1000 ***/\n",
      "TRAIN - 3631.073974609375, nan\n",
      "TEST - 3604.76953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.1049e-05.\n",
      "/*** EPOCH : 637/1000 ***/\n",
      "TRAIN - 3866.073486328125, nan\n",
      "TEST - 3662.1103515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0844e-05.\n",
      "/*** EPOCH : 638/1000 ***/\n",
      "TRAIN - 4015.729736328125, nan\n",
      "TEST - 3206.266357421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0640e-05.\n",
      "/*** EPOCH : 639/1000 ***/\n",
      "TRAIN - 3710.185791015625, nan\n",
      "TEST - 3873.94091796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0436e-05.\n",
      "/*** EPOCH : 640/1000 ***/\n",
      "TRAIN - 3848.794921875, nan\n",
      "TEST - 3303.195556640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0234e-05.\n",
      "/*** EPOCH : 641/1000 ***/\n",
      "TRAIN - 3590.751708984375, nan\n",
      "TEST - 3136.957763671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 4.0033e-05.\n",
      "/*** EPOCH : 642/1000 ***/\n",
      "TRAIN - 3874.97021484375, nan\n",
      "TEST - 4566.220703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9833e-05.\n",
      "/*** EPOCH : 643/1000 ***/\n",
      "TRAIN - 3992.603271484375, nan\n",
      "TEST - 3082.278076171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9634e-05.\n",
      "/*** EPOCH : 644/1000 ***/\n",
      "TRAIN - 3604.541748046875, nan\n",
      "TEST - 3206.981201171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9435e-05.\n",
      "/*** EPOCH : 645/1000 ***/\n",
      "TRAIN - 3823.065185546875, nan\n",
      "TEST - 3663.742919921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9238e-05.\n",
      "/*** EPOCH : 646/1000 ***/\n",
      "TRAIN - 3607.016845703125, nan\n",
      "TEST - 3300.061767578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.9042e-05.\n",
      "/*** EPOCH : 647/1000 ***/\n",
      "TRAIN - 3600.870849609375, nan\n",
      "TEST - 3301.68505859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8847e-05.\n",
      "/*** EPOCH : 648/1000 ***/\n",
      "TRAIN - 3797.927734375, nan\n",
      "TEST - 3252.260498046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8653e-05.\n",
      "/*** EPOCH : 649/1000 ***/\n",
      "TRAIN - 3583.23388671875, nan\n",
      "TEST - 3020.0361328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8459e-05.\n",
      "/*** EPOCH : 650/1000 ***/\n",
      "TRAIN - 3546.845947265625, nan\n",
      "TEST - 3060.857666015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8267e-05.\n",
      "/*** EPOCH : 651/1000 ***/\n",
      "TRAIN - 3565.12548828125, nan\n",
      "TEST - 3399.634521484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.8076e-05.\n",
      "/*** EPOCH : 652/1000 ***/\n",
      "TRAIN - 3564.931396484375, nan\n",
      "TEST - 3304.110595703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7885e-05.\n",
      "/*** EPOCH : 653/1000 ***/\n",
      "TRAIN - 3444.472412109375, nan\n",
      "TEST - 3334.183349609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7696e-05.\n",
      "/*** EPOCH : 654/1000 ***/\n",
      "TRAIN - 3527.00732421875, nan\n",
      "TEST - 3555.638916015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7507e-05.\n",
      "/*** EPOCH : 655/1000 ***/\n",
      "TRAIN - 3708.489990234375, nan\n",
      "TEST - 3497.281982421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7320e-05.\n",
      "/*** EPOCH : 656/1000 ***/\n",
      "TRAIN - 3502.5234375, nan\n",
      "TEST - 3495.040771484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.7133e-05.\n",
      "/*** EPOCH : 657/1000 ***/\n",
      "TRAIN - 3435.860595703125, nan\n",
      "TEST - 3293.83447265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6948e-05.\n",
      "/*** EPOCH : 658/1000 ***/\n",
      "TRAIN - 3620.999755859375, nan\n",
      "TEST - 3358.168212890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6763e-05.\n",
      "/*** EPOCH : 659/1000 ***/\n",
      "TRAIN - 3526.418701171875, nan\n",
      "TEST - 3609.05615234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6579e-05.\n",
      "/*** EPOCH : 660/1000 ***/\n",
      "TRAIN - 3648.78564453125, nan\n",
      "TEST - 3252.31396484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6396e-05.\n",
      "/*** EPOCH : 661/1000 ***/\n",
      "TRAIN - 3519.716064453125, nan\n",
      "TEST - 3460.8994140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6214e-05.\n",
      "/*** EPOCH : 662/1000 ***/\n",
      "TRAIN - 3371.352783203125, nan\n",
      "TEST - 3105.95068359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.6033e-05.\n",
      "/*** EPOCH : 663/1000 ***/\n",
      "TRAIN - 3390.9794921875, nan\n",
      "TEST - 3032.64013671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5853e-05.\n",
      "/*** EPOCH : 664/1000 ***/\n",
      "TRAIN - 3548.46875, nan\n",
      "TEST - 3474.250244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5674e-05.\n",
      "/*** EPOCH : 665/1000 ***/\n",
      "TRAIN - 3455.2060546875, nan\n",
      "TEST - 3684.84814453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5495e-05.\n",
      "/*** EPOCH : 666/1000 ***/\n",
      "TRAIN - 3497.089599609375, nan\n",
      "TEST - 3149.62548828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5318e-05.\n",
      "/*** EPOCH : 667/1000 ***/\n",
      "TRAIN - 3408.24169921875, nan\n",
      "TEST - 3681.567138671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.5141e-05.\n",
      "/*** EPOCH : 668/1000 ***/\n",
      "TRAIN - 3596.020263671875, nan\n",
      "TEST - 2988.89208984375, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 3.4966e-05.\n",
      "/*** EPOCH : 669/1000 ***/\n",
      "TRAIN - 3334.141357421875, nan\n",
      "TEST - 3097.84130859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4791e-05.\n",
      "/*** EPOCH : 670/1000 ***/\n",
      "TRAIN - 3381.64404296875, nan\n",
      "TEST - 3228.86669921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4617e-05.\n",
      "/*** EPOCH : 671/1000 ***/\n",
      "TRAIN - 3352.41015625, nan\n",
      "TEST - 3169.917724609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4444e-05.\n",
      "/*** EPOCH : 672/1000 ***/\n",
      "TRAIN - 3508.906982421875, nan\n",
      "TEST - 3409.79443359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4272e-05.\n",
      "/*** EPOCH : 673/1000 ***/\n",
      "TRAIN - 3733.4912109375, nan\n",
      "TEST - 3583.68017578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.4100e-05.\n",
      "/*** EPOCH : 674/1000 ***/\n",
      "TRAIN - 3460.921875, nan\n",
      "TEST - 3167.718017578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3930e-05.\n",
      "/*** EPOCH : 675/1000 ***/\n",
      "TRAIN - 3466.9462890625, nan\n",
      "TEST - 3266.625244140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3760e-05.\n",
      "/*** EPOCH : 676/1000 ***/\n",
      "TRAIN - 3577.7294921875, nan\n",
      "TEST - 3115.83154296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3591e-05.\n",
      "/*** EPOCH : 677/1000 ***/\n",
      "TRAIN - 3413.4052734375, nan\n",
      "TEST - 3357.083251953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3423e-05.\n",
      "/*** EPOCH : 678/1000 ***/\n",
      "TRAIN - 3469.15087890625, nan\n",
      "TEST - 3162.597412109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3256e-05.\n",
      "/*** EPOCH : 679/1000 ***/\n",
      "TRAIN - 3330.059814453125, nan\n",
      "TEST - 3020.166259765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.3090e-05.\n",
      "/*** EPOCH : 680/1000 ***/\n",
      "TRAIN - 3314.089599609375, nan\n",
      "TEST - 3199.85595703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2924e-05.\n",
      "/*** EPOCH : 681/1000 ***/\n",
      "TRAIN - 3395.25, nan\n",
      "TEST - 3016.2626953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2760e-05.\n",
      "/*** EPOCH : 682/1000 ***/\n",
      "TRAIN - 3332.451904296875, nan\n",
      "TEST - 2969.423095703125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2596e-05.\n",
      "/*** EPOCH : 683/1000 ***/\n",
      "TRAIN - 3336.450439453125, nan\n",
      "TEST - 3052.7353515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2433e-05.\n",
      "/*** EPOCH : 684/1000 ***/\n",
      "TRAIN - 3295.85546875, nan\n",
      "TEST - 2834.28662109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2271e-05.\n",
      "/*** EPOCH : 685/1000 ***/\n",
      "TRAIN - 3354.98828125, nan\n",
      "TEST - 2904.76025390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.2109e-05.\n",
      "/*** EPOCH : 686/1000 ***/\n",
      "TRAIN - 3361.89501953125, nan\n",
      "TEST - 3067.16552734375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1949e-05.\n",
      "/*** EPOCH : 687/1000 ***/\n",
      "TRAIN - 3283.1630859375, nan\n",
      "TEST - 3205.692138671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1789e-05.\n",
      "/*** EPOCH : 688/1000 ***/\n",
      "TRAIN - 3374.01318359375, nan\n",
      "TEST - 3328.49658203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1630e-05.\n",
      "/*** EPOCH : 689/1000 ***/\n",
      "TRAIN - 3472.37548828125, nan\n",
      "TEST - 3123.798583984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1472e-05.\n",
      "/*** EPOCH : 690/1000 ***/\n",
      "TRAIN - 3527.5439453125, nan\n",
      "TEST - 3029.65966796875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1315e-05.\n",
      "/*** EPOCH : 691/1000 ***/\n",
      "TRAIN - 3463.339599609375, nan\n",
      "TEST - 3949.566162109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1158e-05.\n",
      "/*** EPOCH : 692/1000 ***/\n",
      "TRAIN - 3349.42822265625, nan\n",
      "TEST - 2954.911865234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.1002e-05.\n",
      "/*** EPOCH : 693/1000 ***/\n",
      "TRAIN - 3313.040283203125, nan\n",
      "TEST - 2903.88623046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0847e-05.\n",
      "/*** EPOCH : 694/1000 ***/\n",
      "TRAIN - 3301.08154296875, nan\n",
      "TEST - 3043.990478515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0693e-05.\n",
      "/*** EPOCH : 695/1000 ***/\n",
      "TRAIN - 3358.343017578125, nan\n",
      "TEST - 2978.083984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0540e-05.\n",
      "/*** EPOCH : 696/1000 ***/\n",
      "TRAIN - 3282.906005859375, nan\n",
      "TEST - 2916.2705078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0387e-05.\n",
      "/*** EPOCH : 697/1000 ***/\n",
      "TRAIN - 3317.21484375, nan\n",
      "TEST - 2825.744873046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0235e-05.\n",
      "/*** EPOCH : 698/1000 ***/\n",
      "TRAIN - 3285.18505859375, nan\n",
      "TEST - 2821.7275390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 3.0084e-05.\n",
      "/*** EPOCH : 699/1000 ***/\n",
      "TRAIN - 3265.761474609375, nan\n",
      "TEST - 3064.5771484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9933e-05.\n",
      "/*** EPOCH : 700/1000 ***/\n",
      "TRAIN - 3348.048583984375, nan\n",
      "TEST - 3296.31640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9784e-05.\n",
      "/*** EPOCH : 701/1000 ***/\n",
      "TRAIN - 3275.7373046875, nan\n",
      "TEST - 2916.260986328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9635e-05.\n",
      "/*** EPOCH : 702/1000 ***/\n",
      "TRAIN - 3452.87744140625, nan\n",
      "TEST - 3313.568603515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9487e-05.\n",
      "/*** EPOCH : 703/1000 ***/\n",
      "TRAIN - 3523.305908203125, nan\n",
      "TEST - 3466.935546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9339e-05.\n",
      "/*** EPOCH : 704/1000 ***/\n",
      "TRAIN - 3449.466064453125, nan\n",
      "TEST - 3414.74365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9193e-05.\n",
      "/*** EPOCH : 705/1000 ***/\n",
      "TRAIN - 3409.73046875, nan\n",
      "TEST - 3011.123779296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.9047e-05.\n",
      "/*** EPOCH : 706/1000 ***/\n",
      "TRAIN - 3276.963134765625, nan\n",
      "TEST - 3011.66455078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8901e-05.\n",
      "/*** EPOCH : 707/1000 ***/\n",
      "TRAIN - 3329.39306640625, nan\n",
      "TEST - 2940.54931640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8757e-05.\n",
      "/*** EPOCH : 708/1000 ***/\n",
      "TRAIN - 3280.455810546875, nan\n",
      "TEST - 2815.52294921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8613e-05.\n",
      "/*** EPOCH : 709/1000 ***/\n",
      "TRAIN - 3336.249755859375, nan\n",
      "TEST - 3263.244873046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8470e-05.\n",
      "/*** EPOCH : 710/1000 ***/\n",
      "TRAIN - 3252.097900390625, nan\n",
      "TEST - 2996.471435546875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8328e-05.\n",
      "/*** EPOCH : 711/1000 ***/\n",
      "TRAIN - 3408.497802734375, nan\n",
      "TEST - 3032.599365234375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8186e-05.\n",
      "/*** EPOCH : 712/1000 ***/\n",
      "TRAIN - 3237.103271484375, nan\n",
      "TEST - 3043.03564453125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.8045e-05.\n",
      "/*** EPOCH : 713/1000 ***/\n",
      "TRAIN - 3306.544921875, nan\n",
      "TEST - 3195.195068359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7905e-05.\n",
      "/*** EPOCH : 714/1000 ***/\n",
      "TRAIN - 3272.110107421875, nan\n",
      "TEST - 4410.97900390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7765e-05.\n",
      "/*** EPOCH : 715/1000 ***/\n",
      "TRAIN - 3385.18408203125, nan\n",
      "TEST - 2947.11572265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7626e-05.\n",
      "/*** EPOCH : 716/1000 ***/\n",
      "TRAIN - 3268.801513671875, nan\n",
      "TEST - 3062.05126953125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7488e-05.\n",
      "/*** EPOCH : 717/1000 ***/\n",
      "TRAIN - 3333.5888671875, nan\n",
      "TEST - 3896.6962890625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7351e-05.\n",
      "/*** EPOCH : 718/1000 ***/\n",
      "TRAIN - 3304.572265625, nan\n",
      "TEST - 2822.1708984375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7214e-05.\n",
      "/*** EPOCH : 719/1000 ***/\n",
      "TRAIN - 3303.431640625, nan\n",
      "TEST - 3188.125732421875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.7078e-05.\n",
      "/*** EPOCH : 720/1000 ***/\n",
      "TRAIN - 3229.254638671875, nan\n",
      "TEST - 2964.707275390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6943e-05.\n",
      "/*** EPOCH : 721/1000 ***/\n",
      "TRAIN - 3307.764892578125, nan\n",
      "TEST - 2913.6806640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6808e-05.\n",
      "/*** EPOCH : 722/1000 ***/\n",
      "TRAIN - 3277.880615234375, nan\n",
      "TEST - 2952.244873046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6674e-05.\n",
      "/*** EPOCH : 723/1000 ***/\n",
      "TRAIN - 3235.60107421875, nan\n",
      "TEST - 2841.229248046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6541e-05.\n",
      "/*** EPOCH : 724/1000 ***/\n",
      "TRAIN - 3256.049560546875, nan\n",
      "TEST - 2957.60986328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6408e-05.\n",
      "/*** EPOCH : 725/1000 ***/\n",
      "TRAIN - 3242.74072265625, nan\n",
      "TEST - 3080.270263671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6276e-05.\n",
      "/*** EPOCH : 726/1000 ***/\n",
      "TRAIN - 3173.468994140625, nan\n",
      "TEST - 3058.67578125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6144e-05.\n",
      "/*** EPOCH : 727/1000 ***/\n",
      "TRAIN - 3401.220458984375, nan\n",
      "TEST - 3493.021728515625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.6014e-05.\n",
      "/*** EPOCH : 728/1000 ***/\n",
      "TRAIN - 3504.62353515625, nan\n",
      "TEST - 2978.88525390625, nan\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 2.5884e-05.\n",
      "/*** EPOCH : 729/1000 ***/\n",
      "TRAIN - 3225.83642578125, nan\n",
      "TEST - 2897.697265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5754e-05.\n",
      "/*** EPOCH : 730/1000 ***/\n",
      "TRAIN - 3277.150146484375, nan\n",
      "TEST - 2753.004638671875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5625e-05.\n",
      "/*** EPOCH : 731/1000 ***/\n",
      "TRAIN - 3150.907958984375, nan\n",
      "TEST - 2937.513916015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5497e-05.\n",
      "/*** EPOCH : 732/1000 ***/\n",
      "TRAIN - 3150.22412109375, nan\n",
      "TEST - 2806.3271484375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5370e-05.\n",
      "/*** EPOCH : 733/1000 ***/\n",
      "TRAIN - 3272.019775390625, nan\n",
      "TEST - 3026.712158203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5243e-05.\n",
      "/*** EPOCH : 734/1000 ***/\n",
      "TRAIN - 3184.8701171875, nan\n",
      "TEST - 2997.859375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.5117e-05.\n",
      "/*** EPOCH : 735/1000 ***/\n",
      "TRAIN - 3188.008544921875, nan\n",
      "TEST - 3291.1123046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4991e-05.\n",
      "/*** EPOCH : 736/1000 ***/\n",
      "TRAIN - 3427.8115234375, nan\n",
      "TEST - 3073.81787109375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4866e-05.\n",
      "/*** EPOCH : 737/1000 ***/\n",
      "TRAIN - 3161.41357421875, nan\n",
      "TEST - 2913.63330078125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4742e-05.\n",
      "/*** EPOCH : 738/1000 ***/\n",
      "TRAIN - 3127.049072265625, nan\n",
      "TEST - 2947.6279296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4618e-05.\n",
      "/*** EPOCH : 739/1000 ***/\n",
      "TRAIN - 3331.512939453125, nan\n",
      "TEST - 3314.214111328125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4495e-05.\n",
      "/*** EPOCH : 740/1000 ***/\n",
      "TRAIN - 3355.561279296875, nan\n",
      "TEST - 3060.220947265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4373e-05.\n",
      "/*** EPOCH : 741/1000 ***/\n",
      "TRAIN - 3168.25927734375, nan\n",
      "TEST - 3609.471923828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4251e-05.\n",
      "/*** EPOCH : 742/1000 ***/\n",
      "TRAIN - 3375.328125, nan\n",
      "TEST - 2762.41650390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4130e-05.\n",
      "/*** EPOCH : 743/1000 ***/\n",
      "TRAIN - 3374.46337890625, nan\n",
      "TEST - 3027.129150390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.4009e-05.\n",
      "/*** EPOCH : 744/1000 ***/\n",
      "TRAIN - 3216.7802734375, nan\n",
      "TEST - 2936.886474609375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3889e-05.\n",
      "/*** EPOCH : 745/1000 ***/\n",
      "TRAIN - 3167.582763671875, nan\n",
      "TEST - 2863.467529296875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3769e-05.\n",
      "/*** EPOCH : 746/1000 ***/\n",
      "TRAIN - 3095.776611328125, nan\n",
      "TEST - 2767.640869140625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3651e-05.\n",
      "/*** EPOCH : 747/1000 ***/\n",
      "TRAIN - 3153.1376953125, nan\n",
      "TEST - 2915.385498046875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3532e-05.\n",
      "/*** EPOCH : 748/1000 ***/\n",
      "TRAIN - 3171.58447265625, nan\n",
      "TEST - 3007.617431640625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3415e-05.\n",
      "/*** EPOCH : 749/1000 ***/\n",
      "TRAIN - 3113.87646484375, nan\n",
      "TEST - 2853.1650390625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3298e-05.\n",
      "/*** EPOCH : 750/1000 ***/\n",
      "TRAIN - 3098.19970703125, nan\n",
      "TEST - 2917.884765625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3181e-05.\n",
      "/*** EPOCH : 751/1000 ***/\n",
      "TRAIN - 3231.880615234375, nan\n",
      "TEST - 3137.793701171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.3065e-05.\n",
      "/*** EPOCH : 752/1000 ***/\n",
      "TRAIN - 3226.4140625, nan\n",
      "TEST - 2844.696044921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2950e-05.\n",
      "/*** EPOCH : 753/1000 ***/\n",
      "TRAIN - 3234.292236328125, nan\n",
      "TEST - 2707.576416015625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2835e-05.\n",
      "/*** EPOCH : 754/1000 ***/\n",
      "TRAIN - 3143.8837890625, nan\n",
      "TEST - 2740.283447265625, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2721e-05.\n",
      "/*** EPOCH : 755/1000 ***/\n",
      "TRAIN - 3157.025390625, nan\n",
      "TEST - 2831.8173828125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2607e-05.\n",
      "/*** EPOCH : 756/1000 ***/\n",
      "TRAIN - 3164.052978515625, nan\n",
      "TEST - 2985.08544921875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2494e-05.\n",
      "/*** EPOCH : 757/1000 ***/\n",
      "TRAIN - 3169.269775390625, nan\n",
      "TEST - 2743.574951171875, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2382e-05.\n",
      "/*** EPOCH : 758/1000 ***/\n",
      "TRAIN - 3100.128173828125, nan\n",
      "TEST - 2891.868408203125, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2270e-05.\n",
      "/*** EPOCH : 759/1000 ***/\n",
      "TRAIN - 3150.417236328125, nan\n",
      "TEST - 2783.429443359375, nan\n",
      "\n",
      "Adjusting learning rate of group 0 to 2.2159e-05.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-4fe3d1215df1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCH_NUM\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_meas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_meas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-6ca94d6ef215>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mground\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmeas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_score_np\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mground\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-25b08aae8992>\u001b[0m in \u001b[0;36mcheck_score_np\u001b[1;34m(predict, target)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalc_haversine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-34e4e3724105>\u001b[0m in \u001b[0;36mcalc_haversine\u001b[1;34m(lat1, lon1, lat2, lon2)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mdlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdlon\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlat\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdlon\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcsin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpi\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = []\n",
    "train_loss, train_meas = 0,0\n",
    "test_loss, test_meas = 0,0\n",
    "\n",
    "check_meas = np.inf\n",
    "check_loss = np.inf\n",
    "check_epoch = 0\n",
    "\n",
    "for epoch in range(EPOCH_NUM+1):\n",
    "    if epoch != 0:\n",
    "        train_loss, train_meas = train(epoch)\n",
    "    test_loss, test_meas = test()\n",
    "    \n",
    "    history.append({'epoch':epoch, 'train_loss':train_loss, 'train_meas':train_meas, 'test_loss':test_loss, 'test_meas':test_meas})\n",
    "    \n",
    "    if (test_meas < check_meas):\n",
    "        print(\"\")\n",
    "        print(f\"/***CHECK_POINT***/ \")\n",
    "        print(f\"TRAIN - {train_loss}, {train_meas}\")\n",
    "        print(f\"TEST - {test_loss}, {test_meas}\")\n",
    "        print(\"\")\n",
    "        check_meas = test_meas\n",
    "        check_loss = test_loss\n",
    "        check_epoch = epoch\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    \n",
    "    print(f\"/*** EPOCH : {epoch}/{EPOCH_NUM} ***/\")\n",
    "    print(f\"TRAIN - {train_loss}, {train_meas}\")\n",
    "    print(f\"TEST - {test_loss}, {test_meas}\")\n",
    "    print(\"\")\n",
    "    \n",
    "df_history = pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T09:58:17.220129Z",
     "start_time": "2021-06-23T09:58:16.926131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x21588eb3b38>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_history = pd.DataFrame(history)\n",
    "\n",
    "fig, axes = plt.subplots(2,1,figsize = (8,12))\n",
    "\n",
    "axes[0].plot(df_history['epoch'], df_history['train_loss'])\n",
    "axes[0].plot(df_history['epoch'], df_history['test_loss'])\n",
    "axes[0].axvline(x = check_epoch, ymin = 0, ymax = df_history['test_loss'].max(), color = 'r')\n",
    "axes[0].axhline(y = default_loss, xmin = 0, xmax = df_history['epoch'].max(), color = 'k')\n",
    "axes[0].set_ylim(0, 20000)\n",
    "\n",
    "axes[1].plot(df_history['epoch'], df_history['train_meas'])\n",
    "axes[1].plot(df_history['epoch'], df_history['test_meas'])\n",
    "axes[1].axvline(x = check_epoch, ymin = 0, ymax = df_history['test_meas'].max(), color = 'r')\n",
    "axes[1].axhline(y = default_meas, xmin = 0, xmax = df_history['epoch'].max(), color = 'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T08:39:11.653259Z",
     "start_time": "2021-06-23T08:31:56.690Z"
    }
   },
   "outputs": [],
   "source": [
    "del X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T09:58:24.663883Z",
     "start_time": "2021-06-23T09:58:24.206078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91486, 102)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>phoneName</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>latDeg</th>\n",
       "      <th>lngDeg</th>\n",
       "      <th>heightAboveWgs84EllipsoidM</th>\n",
       "      <th>phone</th>\n",
       "      <th>utcTimeMillis_x</th>\n",
       "      <th>elapsedRealtimeNanos_x</th>\n",
       "      <th>UncalGyroXRadPerSec</th>\n",
       "      <th>...</th>\n",
       "      <th>xSatVelMps</th>\n",
       "      <th>ySatVelMps</th>\n",
       "      <th>zSatVelMps</th>\n",
       "      <th>satClkBiasM</th>\n",
       "      <th>satClkDriftMps</th>\n",
       "      <th>rawPrM</th>\n",
       "      <th>rawPrUncM</th>\n",
       "      <th>isrbM</th>\n",
       "      <th>ionoDelayM</th>\n",
       "      <th>tropoDelayM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4XL</td>\n",
       "      <td>1273608752446</td>\n",
       "      <td>37.416623</td>\n",
       "      <td>-122.082055</td>\n",
       "      <td>-24.21</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4XL</td>\n",
       "      <td>1.589574e+12</td>\n",
       "      <td>8.826378e+12</td>\n",
       "      <td>-0.005630</td>\n",
       "      <td>...</td>\n",
       "      <td>292.938</td>\n",
       "      <td>-62.944</td>\n",
       "      <td>3162.107</td>\n",
       "      <td>-136834.317</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.177887e+07</td>\n",
       "      <td>4.197</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.810</td>\n",
       "      <td>3.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4XL</td>\n",
       "      <td>1273608753446</td>\n",
       "      <td>37.416590</td>\n",
       "      <td>-122.082073</td>\n",
       "      <td>-29.97</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4XL</td>\n",
       "      <td>1.589574e+12</td>\n",
       "      <td>8.827378e+12</td>\n",
       "      <td>-0.009253</td>\n",
       "      <td>...</td>\n",
       "      <td>1255.685</td>\n",
       "      <td>1388.784</td>\n",
       "      <td>2026.329</td>\n",
       "      <td>167809.434</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.333124e+07</td>\n",
       "      <td>0.899</td>\n",
       "      <td>-2345.215</td>\n",
       "      <td>6.541</td>\n",
       "      <td>2.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4XL</td>\n",
       "      <td>1273608754446</td>\n",
       "      <td>37.416593</td>\n",
       "      <td>-122.082084</td>\n",
       "      <td>-29.85</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4XL</td>\n",
       "      <td>1.589574e+12</td>\n",
       "      <td>8.828377e+12</td>\n",
       "      <td>-0.000794</td>\n",
       "      <td>...</td>\n",
       "      <td>1255.940</td>\n",
       "      <td>1388.826</td>\n",
       "      <td>2026.043</td>\n",
       "      <td>167809.433</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.333131e+07</td>\n",
       "      <td>0.600</td>\n",
       "      <td>-2344.516</td>\n",
       "      <td>6.541</td>\n",
       "      <td>2.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4XL</td>\n",
       "      <td>1273608755446</td>\n",
       "      <td>37.416580</td>\n",
       "      <td>-122.082067</td>\n",
       "      <td>-28.53</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4XL</td>\n",
       "      <td>1.589574e+12</td>\n",
       "      <td>8.829377e+12</td>\n",
       "      <td>0.036793</td>\n",
       "      <td>...</td>\n",
       "      <td>2808.676</td>\n",
       "      <td>317.171</td>\n",
       "      <td>370.156</td>\n",
       "      <td>-47469.410</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.082429e+07</td>\n",
       "      <td>3.298</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4.010</td>\n",
       "      <td>3.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-15-US-MTV-1</td>\n",
       "      <td>Pixel4XL</td>\n",
       "      <td>1273608756446</td>\n",
       "      <td>37.416594</td>\n",
       "      <td>-122.082065</td>\n",
       "      <td>-27.70</td>\n",
       "      <td>2020-05-15-US-MTV-1_Pixel4XL</td>\n",
       "      <td>1.589574e+12</td>\n",
       "      <td>8.830376e+12</td>\n",
       "      <td>-0.030948</td>\n",
       "      <td>...</td>\n",
       "      <td>813.076</td>\n",
       "      <td>1060.450</td>\n",
       "      <td>2833.855</td>\n",
       "      <td>-81574.962</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>2.087243e+07</td>\n",
       "      <td>2.099</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.948</td>\n",
       "      <td>2.855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        collectionName phoneName  millisSinceGpsEpoch     latDeg      lngDeg  \\\n",
       "0  2020-05-15-US-MTV-1  Pixel4XL        1273608752446  37.416623 -122.082055   \n",
       "1  2020-05-15-US-MTV-1  Pixel4XL        1273608753446  37.416590 -122.082073   \n",
       "2  2020-05-15-US-MTV-1  Pixel4XL        1273608754446  37.416593 -122.082084   \n",
       "3  2020-05-15-US-MTV-1  Pixel4XL        1273608755446  37.416580 -122.082067   \n",
       "4  2020-05-15-US-MTV-1  Pixel4XL        1273608756446  37.416594 -122.082065   \n",
       "\n",
       "   heightAboveWgs84EllipsoidM                         phone  utcTimeMillis_x  \\\n",
       "0                      -24.21  2020-05-15-US-MTV-1_Pixel4XL     1.589574e+12   \n",
       "1                      -29.97  2020-05-15-US-MTV-1_Pixel4XL     1.589574e+12   \n",
       "2                      -29.85  2020-05-15-US-MTV-1_Pixel4XL     1.589574e+12   \n",
       "3                      -28.53  2020-05-15-US-MTV-1_Pixel4XL     1.589574e+12   \n",
       "4                      -27.70  2020-05-15-US-MTV-1_Pixel4XL     1.589574e+12   \n",
       "\n",
       "   elapsedRealtimeNanos_x  UncalGyroXRadPerSec  ...  xSatVelMps  ySatVelMps  \\\n",
       "0            8.826378e+12            -0.005630  ...     292.938     -62.944   \n",
       "1            8.827378e+12            -0.009253  ...    1255.685    1388.784   \n",
       "2            8.828377e+12            -0.000794  ...    1255.940    1388.826   \n",
       "3            8.829377e+12             0.036793  ...    2808.676     317.171   \n",
       "4            8.830376e+12            -0.030948  ...     813.076    1060.450   \n",
       "\n",
       "  zSatVelMps  satClkBiasM  satClkDriftMps        rawPrM  rawPrUncM     isrbM  \\\n",
       "0   3162.107  -136834.317          -0.002  2.177887e+07      4.197     0.000   \n",
       "1   2026.329   167809.434          -0.002  2.333124e+07      0.899 -2345.215   \n",
       "2   2026.043   167809.433          -0.002  2.333131e+07      0.600 -2344.516   \n",
       "3    370.156   -47469.410           0.001  2.082429e+07      3.298     0.000   \n",
       "4   2833.855   -81574.962          -0.002  2.087243e+07      2.099     0.000   \n",
       "\n",
       "   ionoDelayM  tropoDelayM  \n",
       "0       4.810        3.462  \n",
       "1       6.541        2.641  \n",
       "2       6.541        2.647  \n",
       "3       4.010        3.005  \n",
       "4       3.948        2.855  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_pickle(str(data_dir / \"gsdc_test.pkl.gzip\"))\n",
    "\n",
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:00:25.057950Z",
     "start_time": "2021-06-23T10:00:24.622649Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(checkpoint_path))\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:02:24.099765Z",
     "start_time": "2021-06-23T10:02:23.966766Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91486, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load submission sample\n",
    "submission = pd.read_csv(str(data_dir / \"sample_submission.csv\"))\n",
    "print(submission.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.128633Z",
     "start_time": "2021-06-23T10:04:23.115635Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SimpleNetwork' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-5038c3e09ccc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSimpleNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimpleNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "model = SimpleNetwork(X.shape[1] * X.shape[2], y.shape[1])\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.177637Z",
     "start_time": "2021-06-23T09:58:26.115Z"
    }
   },
   "outputs": [],
   "source": [
    "X, _ = extract_features(df_test, train = False)\n",
    "\n",
    "X = torch.Tensor(X)\n",
    "\n",
    "loader_test = DataLoader(X, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.220636Z",
     "start_time": "2021-06-23T09:58:26.283Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()  # 신경망을 추론 모드로 전환\n",
    "\n",
    "# 데이터로더에서 미니배치를 하나씩 꺼내 추론을 수행\n",
    "predict = []\n",
    "with torch.no_grad():  # 추론 과정에는 미분이 필요없음\n",
    "    for data in loader_test:\n",
    "        data = data.to(device)\n",
    "\n",
    "        outputs = model(data)  # 데이터를 입력하고 출력을 계산\n",
    "        predict.append(outputs)\n",
    "predict = torch.cat(predict, axis = 0).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.260634Z",
     "start_time": "2021-06-23T09:58:26.443Z"
    }
   },
   "outputs": [],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.306634Z",
     "start_time": "2021-06-23T09:58:26.628Z"
    }
   },
   "outputs": [],
   "source": [
    "print(submission.shape)\n",
    "submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.350636Z",
     "start_time": "2021-06-23T09:58:26.955Z"
    }
   },
   "outputs": [],
   "source": [
    "submission['latDeg'] = predict[:,1]\n",
    "submission['lngDeg'] = predict[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:04:23.355636Z",
     "start_time": "2021-06-23T09:58:27.140Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f\"./models/{notebookName}/{num_files} - result.csv\", index = False)\n",
    "pd.DataFrame([]).to_csv(dummy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-19T01:57:01.692286Z",
     "start_time": "2021-06-19T01:56:30.624Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.078px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
